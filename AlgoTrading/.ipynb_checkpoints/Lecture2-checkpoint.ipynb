{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzEMgWjGxzsT"
   },
   "source": [
    "<a ><img src=\"https://cdn.tuinvest.de/assets/logos/TUInvest_Logo-353d42494757660b8381a31c9f99a6ca.png\"  width=\"200\" align=\"left\"> </a>\n",
    "<div style=\"text-align: right\"> <h3><span style=\"color:gray\"> INTERNAL USE ONLY </span> </h3> </div>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a ><img src=\"Pictures/QSeries.png\" Width=\"300\" align=\"center\"> </a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<h1><center>AlgoTrading 101 — A hands-on Introduction</center></h1>\n",
    "<h2><center> <span style=\"font-weight:normal\"><font color='#022F73'> Lecture 2: Model Selection and Discussion </font>  </span></center></h2>\n",
    "\n",
    "\n",
    "<h3><center><font color='gray'>JONAS GOTTAL</font></center></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO2hJc3wxzsW"
   },
   "source": [
    "<h4>About this Notebook</h4>\n",
    "The Objective of this Lecture is a comprehensible Introduction to Algo Trading <br>\n",
    "for the members of TU Invest, to raise curiosity and resurrect Alternative Strategies/Assets.\n",
    "\n",
    "Although the material showed is not fit to  *understand*  for beginners, with easier strategies <br>\n",
    "there won't be a profitable among them. Thus the math and stats behind the following stratgies <br>\n",
    "might be hard to understand but not to implement. And I hope this will lead some curious <br>\n",
    "minds to further study the concepts more thoroughly. <br>\n",
    "*Therefore the sole Momentum and Pair Trading Strategies will be very short.*\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<span style=\"color:gray\"> * *To limit our time spent per section, basics in Python and Statistics are welcomed. <br> If not, there will be links to a <a href=\"#11\"> Backup Section</a> with additional code and explanations.* </span>\n",
    "<br>\n",
    "<br>\n",
    "___\n",
    "___\n",
    "<a><span style=\"color:black\"> <b> Legend:</b></span> </a><a> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; </a> <a><span style=\"color:black\"> <b>|</b></span> </a> <a> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; </a><a><span style=\"color:#022F73\"> UNDERSTAND ME</span> </a> <a> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; </a><a><span style=\"color:black\"> <b>|</b></span> </a> <a> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; </a><a><span style=\"color:black\"> REMEMBER ME</span> </a><a> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; </a><a><span style=\"color:black\"> <b>|</b></span> </a> <a> &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; </a><a><span style=\"color:gray\"> READ ME</span> </a>\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqQx4LXuxzsY"
   },
   "source": [
    "<div style=\"text-align: center\"> <h3><span style=\"color:red\"> THIS IS A WORKING DRAFT TO BE SPLIT IN LECTURES WHEN FINISHED </span> </h3> </div>\n",
    "\n",
    "<div style=\"text-align: center\"> <h3><span style=\"color:red\"> <em> Many parts will be cut or at least reduced </em></span> </h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI5wU5naxzsa"
   },
   "source": [
    "<h1>Table of contents</h1>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"text-decoration:none; margin-top: 30px; background-color:#F2F2F2; border-color:#022F73\">\n",
    "    <span style=\"color:#022F73\">\n",
    "     <ol>\n",
    "       <li><a href=\"#13\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >The two Basic Strategies as Foundation</span> </a></li> \n",
    "       <ol>\n",
    "       <li><a href=\"#17\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Trend Based: Mean Reversion and Momentum</span> </a></li>\n",
    "       <li><a href=\"#18\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Pairs Trading</span> </a></li>    \n",
    "       </ol>   \n",
    "       <li><a href=\"#13\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Advanced Manipulation to gain an Edge</span> </a></li> \n",
    "       <ol>\n",
    "       <li><a href=\"#18\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Augmented-Dickey Fuller </span> </a></li> \n",
    "       <li><a href=\"#16\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Hurst Exponents </span> </a></li>\n",
    "       <li><a href=\"#18\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Ornstein-Uhlenbeck </span> </a></li>\n",
    "       <li><a href=\"#15\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Kalman Filter </span> </a></li>    \n",
    "       <li><a href=\"#18\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Haar Transformation </span> </a></li>\n",
    "       <li><a href=\"#17\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Exponential Smoothing </span> </a></li> \n",
    "       </ol>\n",
    "       <li><a href=\"#20\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Artificial Intelligence</span> </a></li>\n",
    "       <ol>\n",
    "       <li><a href=\"#20\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Deep Neural Networks (DNN)</span> </a></li>\n",
    "       <li><a href=\"#20\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Gradient-Boosted-Trees (GBT)</span> </a></li>\n",
    "       <li><a href=\"#20\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Random Forests (RAF)</span> </a></li>\n",
    "       <li><a href=\"#20\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Reinforcement Learning (RL)</span> </a></li>\n",
    "       </ol>\n",
    "       <li><a href=\"#20\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Positions</span> </a></li>\n",
    "       <ol>\n",
    "        <li><a href=\"#20\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Thresholds for Entry and Exit</span> </a></li>\n",
    "       <li><a href=\"#20\"> <span style=\"color:#022F73;text-decoration:underline;text-decoration-color:#F2F2F2\" \n",
    "       >Position Sizing</span> </a></li>\n",
    "       </ol>\n",
    "   </ol>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bq5rk3lDxzsg"
   },
   "outputs": [],
   "source": [
    "# !pip install auquan_toolbox\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import backtester\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import sys\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "LTEzfzJ9xzxj"
   },
   "source": [
    "# The two Basic Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ig4G37BNxzxj"
   },
   "source": [
    "Later Including:\n",
    "\n",
    "Augmented-Dickey Fuller test\n",
    "\n",
    "Hurst exponents\n",
    "\n",
    "Ornstein–Uhlenbeck process\n",
    "\n",
    "Kalman filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "0fkmv52hxzxk"
   },
   "source": [
    "## Mean reversion Models\n",
    "\n",
    "Mean-reversion strategies work on the assumption that the price of an asset is prone to random fluctuation around an underlying stable trend. Therefore, values deviating far from the trend or observed mean will tend to reverse direction and revert to the mean. If the value is unusually high, we expect it to go back down and go up if it is unusually low. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "ptYRGMrLxzxk"
   },
   "source": [
    "### Single-stock mean reversion\n",
    "\n",
    "Mean reversion in the context of a stock price implies that periods of the price being far below the mean are followed by periods of the price going up, and vice versa. We can take advantage of this by buying the stock to go long when the price is lower than expected, and selling to go short when the price is higher than expected. We can plot the price of a stock along with the mean of the prices up to each day to see whether the price reverts to the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Avb5Jgybxzxl"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import auquanToolbox.dataloader as dl\n",
    "\n",
    "# Load the prices data for a stock\n",
    "start = '2013-06-01'\n",
    "end = '2016-12-31'\n",
    "m= 'PG'\n",
    "data = dl.load_data_nologs('nasdaq', [m], start, end)\n",
    "prices = data['ADJ CLOSE']\n",
    "\n",
    "# Compute the cumulative moving average of the price\n",
    "prices['mu'] = [prices[m][:i].mean() for i in range(len(prices))]\n",
    "# Plot the price and the moving average\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(prices[m])\n",
    "plt.plot(prices['mu']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "bKmRg4l9xzxr"
   },
   "source": [
    "Note that since we are computing the running average, \"reverting to the mean\" does not necessarily mean going as high or as low as it did before.\n",
    "\n",
    "In order to trade using this strategy, we need to quantify what it means for the price to be higher or lower than expected. It's useful to compute the z-score of the price on each day, which tells us how many standard deviations away from the mean a value is:\n",
    "\n",
    " $$ z=\\frac{x-\\mu}{\\sigma} $$\n",
    "\n",
    "where $x$ is the value, $\\mu$ is the mean of the data set, and $\\sigma$ is its standard deviation. So a price with a z-score $> 1$ is more than one standard deviation above the mean, and we will sell short when this happens. If the price on a day has a z-score $< 1$, we will buy long. If the price is within half a standard deviation of the mean, we will clear all positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "tZwOm5izxzxs"
   },
   "outputs": [],
   "source": [
    "# Compute the z-scores for each day using the historical data up to that day\n",
    "zscores = [(prices[m][i] - prices['mu'][i]) / np.std(prices[m][:i]) for i in range(len(prices))]\n",
    "\n",
    "# Start with no money and no positions\n",
    "money = 0\n",
    "count = 0\n",
    "for i in range(len(prices)):\n",
    "    # Sell short if the z-score is > 1\n",
    "    if zscores[i] > 1:\n",
    "        money += prices[m][i]\n",
    "        count -= 1\n",
    "    # Buy long if the z-score is < 1\n",
    "    elif zscores[i] < -1:\n",
    "        money -= prices[m][i]\n",
    "        count += 1\n",
    "    # Clear positions if the z-score between -.5 and .5\n",
    "    elif abs(zscores[i]) < 0.5:\n",
    "        money += count*prices[m][i]\n",
    "        count = 0\n",
    "print money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WkYC_U4cxzxu"
   },
   "source": [
    "The danger of applying mean reversion to a single stock is that it exposes us to the movement of the market and the success or failure of the individual company, among other factors. If there is a persistent trend affecting the price of the security, we will find ourselves consitently undervaluing (if the price is moving steadily upward) or overvaluing (if the price is falling) the asset. Below we discuss two strategies that mitigate this risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "CtSC004Uxzxu"
   },
   "source": [
    "### Mean reversion portfolio\n",
    "\n",
    "Instead of taking the mean of the historical returns on an asset, we can look at the mean of the returns on all of the stocks in, say, the S&P 500. Hypothesizing that the worst-performing stocks last period will do better this period (that is, they are likely to be undervalued) and vice versa, we go long in stocks that performed poorly and short in stocks that performed well.\n",
    "\n",
    "This approach has the advantage of being market-neutral, so that we do not treat stocks as undervalued just because the market as a whole is falling, or overvalued when the market is rising. Furthermore, by including a large number of securities in portfolio, we are likely to encounter many cases where our prediction is correct.\n",
    "\n",
    "To construct a portfolio which takes advantage of mean reversion, we first select a universe, such as all S&P 500 stocks or the top-traded stocks on the NYSE. From this universe, we rebalance our portfolio every period (say, every week) by going short in the stocks in the bottom 20% of returns over the last period and long in the stocks in the top 20% of returns. If a stock is in neither of those quintiles, we do not include it in our portfolio.\n",
    "\n",
    "We can construct a toy example using sector ETFs instead of a large basket of stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "M1RXKVjAxzxv"
   },
   "outputs": [],
   "source": [
    "# Fetch prices data for 10 stocks from different sectors and plot returns\n",
    "start = '2016-12-01'\n",
    "end = '2016-12-31'\n",
    "assets = ['AAPL', 'AIG', 'C', 'T', 'PG', 'JNJ', 'EOG', 'MET', 'DOW', 'AMGN']\n",
    "data = dl.load_data_nologs('nasdaq', assets, start, end)\n",
    "prices = data['ADJ CLOSE']\n",
    "returns = prices/prices.shift(-1) -1\n",
    "returns.plot(figsize=(15,7), color=['r', 'g', 'b', 'k', 'c', 'm', 'orange',\n",
    "                                     'chartreuse', 'slateblue', 'silver'])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Returns')\n",
    "\n",
    "# Convert to numpy array to make manipulation easier\n",
    "data = np.array(prices);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "U9O5FTw7xzxx"
   },
   "source": [
    "We hypothesize that the stocks which do well for the first week will regress after another month, while those which do poorly at first will appreciate in value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "VKuD2qg6xzxy"
   },
   "outputs": [],
   "source": [
    "# For each security, take the return for the first week\n",
    "wreturns = (data[4] - data[0])/data[0]\n",
    "# Rank securities by return, with 0 being the lowest return\n",
    "order = wreturns.argsort()\n",
    "ranks = order.argsort()\n",
    "\n",
    "# For each security, take the return for the month following the first week\n",
    "# Normalization for the time period doesn't matter since we're only using the returns to rank them\n",
    "mreturns = (data[-1] - data[5])/data[5]\n",
    "order2 = mreturns.argsort()\n",
    "ranks2 = order2.argsort()\n",
    "\n",
    "# Plot the returns for the first week vs returns for the next month to visualize them\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(wreturns, mreturns)\n",
    "plt.xlabel('Returns for the first week')\n",
    "plt.ylabel('Returns for the following month');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "v7hodXM1xzx0"
   },
   "source": [
    "The returns look like they could be anticorrelated, but what would have happened if we had followed the mean-reversion strategy when we examined the past week's returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "SWjhCytWxzx0"
   },
   "outputs": [],
   "source": [
    "# Go long (by one share each) in the bottom 20% of securities and short in the top 20%\n",
    "longs = np.array([int(x < 2)for x in ranks])\n",
    "shorts = np.array([int(x > 7) for x in ranks])\n",
    "print 'Going long in:', [assets[i] for i in range(len(assets)) if longs[i]]\n",
    "print 'Going short in:', [assets[i] for i in range(len(assets)) if shorts[i]]\n",
    "\n",
    "# Resolve all positions and calculate how much we would have earned\n",
    "print 'Yield:', sum((data[-1] - data[4])*(longs - shorts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "EoSaFjAvxzx6"
   },
   "source": [
    "## Pairs trading\n",
    "\n",
    "In pairs trading, the quantity we are examining is the distance between two securities, which we expect to revert back to its mean. For this to be a reasonable assumption, we need the two securities to be statistically <i>cointegrated</i>. In practice, two companies whose products are substitutes for each other are often cointegrated. That is, they generally move together due to shifts in the market and in their specific industry, and move little relative to each other.\n",
    "\n",
    "How do we incorporate the prediction about their difference into our portfolio? Suppose we are looking at two securities X and Y. Then we go long in X and short in Y when the two are closer together than expected, and short in X and long in Y when the two are far apart. In this way we remain neutral to the market, industry, and other shifts that cause X and Y to move together, while making money on their difference reverting to the mean. We can quantify \"closer than expected\" as the difference having a z-score of less than -1, and \"farther apart than expected\" as a z-score greater than 1. This is easier to picture if X's price is higher than Y's, but the end result is the same in either case.\n",
    "\n",
    "Using the `coint` function from `statsmodels`, let's check whether HP and Microsoft stock prices are cointegrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "hBkZ4Z0axzx8"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import coint\n",
    "start = '2012-01-01'\n",
    "end = '2016-12-31'\n",
    "# Load prices data for HP and Microsoft\n",
    "data = dl.load_data_nologs('nasdaq', ['MSFT', 'HP'], start, end)\n",
    "X = data['ADJ CLOSE']['MSFT']\n",
    "Y = data['ADJ CLOSE']['HP']\n",
    "# Compute the p-value for the cointegration of the two series\n",
    "_, pvalue, _ = coint(X,Y)\n",
    "print pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "UM3uMLtwxzx-"
   },
   "source": [
    "The p-value is low, so the two series are cointegrated. Next we need to find the mean of the difference. We'll compute the cumulative moving average - that is, the average of all the values up to each day - as though we were looking at the data every day without knowing the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "n7CpY7P_xzx-"
   },
   "outputs": [],
   "source": [
    "# Plot their difference and the cumulative moving average of their difference\n",
    "val = pd.DataFrame(index = X.index, columns=['diff','mu'])\n",
    "val['diff'] = X - Y\n",
    "val['mu']= [val['diff'][:i].mean() for i in range(len(val['diff']))]\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(val['diff'])\n",
    "plt.plot(val['mu'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Fn6NUBCExzyA"
   },
   "source": [
    "In some cases, we may instead want our mean to refer only to the moving average, excluding data from too long ago. Below we can see the difference between the cumulative moving average and the 60-day running average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "09MDKkj_xzyA"
   },
   "outputs": [],
   "source": [
    "mu_60d = pd.rolling_mean(val['diff'], window=90)\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(val['diff'], label='X-Y')\n",
    "plt.plot(val['mu'], label='CMA')\n",
    "plt.plot(mu_60d, label='60d MA')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "_Y8BUGRAxzyC"
   },
   "source": [
    "From here our trading strategy is identical to that for a single security, where we replace the asset with the spread X-Y. When we short the spread, we buy Y and sell X, and vice versa for going long. We'll be using the CMA for the mean, but you can easily change it to see the difference. Keep in mind, however, that what works well with this data may not be suited for other situations, and each definition of the mean will sometimes outperform the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "IqRynz7SxzyC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the z-score of the difference on each day\n",
    "zscores = [(val['diff'][i] - val['mu'][i]) / np.std(val['diff'][:i]) for i in range(len(val['diff']))]\n",
    "\n",
    "# Start with no money and no positions\n",
    "money = 0\n",
    "count = 0\n",
    "for i in range(len(val['diff'])):\n",
    "    # Sell short if the z-score is > 1\n",
    "    if zscores[i] > 1:\n",
    "        money += val['diff'][i]\n",
    "        count -= 1\n",
    "    # Buy long if the z-score is < 1\n",
    "    elif zscores[i] < -1:\n",
    "        money -= val['diff'][i]\n",
    "        count += 1\n",
    "    # Clear positions if the z-score between -.5 and .5\n",
    "    elif abs(zscores[i]) < 0.5:\n",
    "        money += count*val['diff'][i]\n",
    "        count = 0\n",
    "        \n",
    "print money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "vwqAHz82xzyE"
   },
   "source": [
    "## Alternative approaches\n",
    "\n",
    "Mean-reversion strategies assume that trends tend to reverse direction. On the opposite end of the spectrum are trend-following or momentum-based strategies. These hypothesize that prices will, despite fluctuations, generally move in the direction they were moving in before. They can also take into account how quickly a price is moving, and anticipate changes in the direction of movement when it slows down. These are covered in more detail in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "m6dfpLO6xzyF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Cbll3bYrxzyH"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "-QY51nj-xzyH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "pC5fPNIYxzyN"
   },
   "source": [
    "# Trend Based Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "4Kjzjpn_xzyO"
   },
   "source": [
    "## Momentum Strategies\n",
    "\n",
    "---\n",
    "Momentum trading refers to a general class of strategies which extrapolate from existing trends. They assume that stocks which are going up will continue to go up and stocks which are going down will continue going down, and buy and sell accordingly. This is in contrast to mean-reversion strategies, which rely on trends reversing direction.\n",
    "\n",
    "For instance, below we see the price of an asset fluctuating but overall going up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "hHHjkGIvxzyO"
   },
   "source": [
    "## Momentum and Auto-Correlation\n",
    "\n",
    "Many things in finance are autocorrelated. An intuitive explanation for this is that prices are determined by traders, which take into account past prices when determining new ones. The formula might be\n",
    "\n",
    "$$P_t = T_t + \\epsilon$$\n",
    "$$T_t = X + P_{1, t-1}$$\n",
    "$$P_t = X + P_{1, t-1} + \\epsilon$$\n",
    "\n",
    "Where X covers all the other factors traders consider and $\\epsilon$ is random noise. This is the definition of an autocorrelated series, in which the value at time $t$ depends on previous values.\n",
    "\n",
    "Some forms of autocorrelation will not exhibit momentum behavior. For instance, a very simple autocorrelation relation could be as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "4huQJmwSxzyO"
   },
   "outputs": [],
   "source": [
    "def generate_autocorrelated_values(N):\n",
    "    X = np.zeros(N)\n",
    "    for i in range(N-1):\n",
    "        X[i+1] = X[i] + np.random.normal(0, 1)\n",
    "    return X\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "for i in range(10):\n",
    "    X = generate_autocorrelated_values(100)\n",
    "    plt.plot(X)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$X_t$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "vNb0cz6OxzyP"
   },
   "source": [
    "These series will not exhibit momentum behavior, as the amount they go up and down each timestep is purely random. However, if the series' returns are autocorrelated, then we will see momentum behavior. We can simulate this as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "RcP6Zo-KxzyP"
   },
   "outputs": [],
   "source": [
    "def generate_autocorrelated_values(N):\n",
    "    X = np.zeros(N)\n",
    "    for i in range(1, N-1):\n",
    "        # Do the past returns 'look good' to investors\n",
    "        past_returns = X[i] - X[i-1]\n",
    "        # Investors hypothesize that future returns will be equal to past returns and buy at that price\n",
    "        X[i+1] = X[i] + past_returns + np.random.normal(0, 1)\n",
    "    return X\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "for i in range(10):\n",
    "    X = generate_autocorrelated_values(10)\n",
    "    plt.plot(X)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$X_t$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "EyH-8nAkxzyQ"
   },
   "source": [
    "It's now clear to see that if investors incorporate information about past returns into the future price, we will see momentum behavior. Obviously in real data this will be far more noisy and difficult to observe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "4Sad2tOLxzyR"
   },
   "source": [
    "### Testing for Autocorrelation\n",
    "\n",
    "We can test for autocorrelation in a few ways. One is by checking for a unit root. If the series has a unit root, we should be worried that there is autocorrelation present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "UtB-tQU0xzyR"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "X1 = generate_autocorrelated_values(100)\n",
    "X2 = np.random.normal(0, 1, 100)\n",
    "\n",
    "# Compute the p-value of the Dickey-Fuller statistic to test the null hypothesis that yw has a unit root\n",
    "print 'X1'\n",
    "_, pvalue, _, _, _, _ = adfuller(X1)\n",
    "if pvalue > 0.05:\n",
    "    print 'We cannot reject the null hypothesis that the series has a unit root.'\n",
    "else:\n",
    "    print 'We reject the null hypothesis that the series has a unit root.'\n",
    "print 'X2'\n",
    "_, pvalue, _, _, _, _ = adfuller(X2)\n",
    "if pvalue > 0.05:\n",
    "    print 'We cannot reject the null hypothesis that the series has a unit root.'\n",
    "else:\n",
    "    print 'We reject the null hypothesis that the series has a unit root.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "aeJ8e1-ZxzyS"
   },
   "source": [
    "## Momentum vs. Mean Reversion\n",
    "\n",
    "Momentum and mean reversion are in a sense opposite strategies. In a momentum model one hypothesizes that past upwards movement is indicative of future upwards movement. In a mean reversion model one hypothesizes that past upward trends are simply temporary overvaluings and the price will return to normal. Both are important models that work in different cases.\n",
    "\n",
    "It is important to check for which kind of behavior might be present in your data before you actually try developing a strategy based on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "8p31g4vWxzyS"
   },
   "source": [
    "### Time Frame is Important\n",
    "\n",
    "Momentum behavior and mean reversion behavior can both occur in the same asset. Take for example AAPL again. We can see a trend upwards, but there is also movement around that trend. One approach could be to buy an hold AAPL and attempt to make money on the longer timeframe. Another approach would be to buy AAPL whenever it went under the trendline and sell it whenever it was beneath. This strategy would work on shorter timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "fYdWc-uIxzyT"
   },
   "outputs": [],
   "source": [
    "# Load pricing data for an asset\n",
    "start = '2016-03-01'\n",
    "end = '2017-01-01'\n",
    "data = dl.load_data_nologs('nasdaq', ['AAPL'], start, end)\n",
    "prices = data['ADJ CLOSE']\n",
    "dates = prices.index\n",
    "\n",
    "# Plot the price of the asset over time\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(prices['AAPL'])\n",
    "\n",
    "# Find the line of best fit to illustrate the trend\n",
    "X = np.arange(len(dates))\n",
    "x = sm.add_constant(X) # Add a column of ones so that line can have a y-intercept\n",
    "model = regression.linear_model.OLS(prices['AAPL'], x).fit()\n",
    "a = model.params[0] # Get coefficients of line\n",
    "b = model.params[1]\n",
    "prices['Y_hat'] = X * b + a\n",
    "plt.plot(prices['Y_hat'], 'r', alpha=0.9);\n",
    "plt.ylabel('Price')\n",
    "plt.legend(['AAPL', 'Trendline']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "jxedvN1yxzyU"
   },
   "source": [
    "To see how a mean reversion signal might look, let's look at the difference between the asset and the prediction. Sure enough, looks like some good opportunity for mean reversion as the price difference crosses the zero line many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "PCDOVMdwxzyV"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot((prices['AAPL'] - prices['Y_hat']).values)\n",
    "plt.hlines(np.mean(prices['AAPL'] - prices['Y_hat']), 0, len(dates), colors='r')\n",
    "plt.hlines(np.std(prices['AAPL'] - prices['Y_hat']), 0, len(dates), colors='r', linestyles='dashed')\n",
    "plt.hlines(-np.std(prices['AAPL'] - prices['Y_hat']), 0, len(dates), colors='r', linestyles='dashed')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Dollar Difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "gGBhOJXbxzyX"
   },
   "source": [
    "### Time Frame is Important for Predictive Capacity\n",
    "\n",
    "Each momentum measure will be predictive over different time horizons. Some over years and some over days. This will also be true of different asset classes. Some asset classes have momentum over years and some over days. It is important, when constructing a momentum model, to keep in mind what time frame makes sense. That time frame should be roughly the time frame on which you rebalance/exit the trade. It should also be the time frame you use when measuring predictive capacity of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "85kWN06QxzyX"
   },
   "source": [
    "### IMPORTANT: Model Selection\n",
    "\n",
    "It is important not to fall prey to statistical biases by throwing a lot of models at a dataset and seeing which fit. To understand why this is true, see The Dangers of Overfitting. In short, if you throw a lot of models at a dataset, one will likely happen to look good based on random chance. This model will not have predictive power on any new data, just the data you've already seen.\n",
    "\n",
    "A better approach is to let your model creation be driven by underlying things you know to be true about your data. For instance, here is a good development path:\n",
    "1. Hypothesize that based on investor psychology, certain stocks should exhibit momentum behavior.\n",
    "2. Construct a mathemtical model that follows this hypothesis.\n",
    "3. Test your hypothesis by seeing if that model fits your data well.\n",
    "4. Test your model out of sample on new data you've never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "kZshnfhKxzyY"
   },
   "source": [
    "## Trading on Momentum\n",
    "\n",
    "### Measuring Momentum\n",
    "\n",
    "To trade on momentum, we must first be able to measure it. For information on how to measure momentum, please see the Measuring Momentum notebook. Various ways to quantify momentum will be discussed there. We will discuss what you might do once you have developed a measure of momentum here.\n",
    "\n",
    "All following examples will assume that a good measure of momentum $p$, has been developed. The notation $p(A_t)$ will denote the momentum of asset $A$ and time $t$.\n",
    "\n",
    "### Entry and Exit Signals\n",
    "\n",
    "One way to use momentum is to have cutoffs and enter a position when momentum is significantly high, and leave it when momentum is significantly low. The can be done for shorting stocks as well if momentum is in the negative direction. Good examples of this would be moving average crossover strategies, as discussed in the Measuing Momentum.\n",
    "\n",
    "### Ranking Stocks for Long-Short Baskets\n",
    "\n",
    "Another approach is to use momentum as a factor for ranking stocks. The general approach and its benefits are descrbed in the Long-Short Equity and Ranking Universes by Factors. In short, you make a bet that stocks with higher momentum will outperform those with lower momentum. This tends to be more market neutral and robust. Momentum could also be used as one of many factors in a ranking scheme.\n",
    "\n",
    "#### Cross-Sectional Momentum\n",
    "\n",
    "Cross sectional momentum is when rather than looking at absolute momentum, you look at momentum of every stock relative to every other stock. This has the advantage of providing a relative scale, rather than a somewhat meaningless absolute measure of momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "LunqiErYxzyY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "kLrTwm-Qxzyd"
   },
   "source": [
    "## Measures of Momentum From Physics\n",
    "\n",
    "Here we present some measures of momentum taken from physics. The paper describing these measures can be found here http://arxiv.org/pdf/1208.2775.pdf. The authors define 4 different measures, called $p^{(1)}$, $p^{(0)}$, $p^{(2)}$, and $p^{(3)}$.\n",
    "\n",
    "Their approach is based in physics, where the momentum is defined as $p = mv$, the product of the mass and the velocity. First, they define $x(t)$ to be the log of the price of the security. Conveniently, the return on the security is then the derivative of $x(t)$, which is called the velocity $v(t)$. Then they suggest a number of different definitions of mass $m(t)$; in the examples below, we'll use the inverse of standard deviation and turnover rate as mass. This works with our analogy because the more volatile or the less liquid an asset (the smaller its mass), the easier it is to move its price (i.e. change its position). The different momenta are then defined (for a lookback window $k$) as:\n",
    "$$p^{(0)}(t) = \\sum_{i=0}^{k-1} v(t-i)$$\n",
    "$$p^{(1)}(t) = \\sum_{i=0}^{k-1} m(t-i) v(t-i)$$\n",
    "$$p^{(2)}(t) = \\frac{\\sum_{i=0}^{k-1} m(t-i) v(t-i)}{\\sum_{i=0}^{k-1} m(t-i)}$$\n",
    "$$p^{(3)}(t) = \\frac{\\mu(v(t-k+1),\\ldots, v(t))}{\\sigma(v(t-k+1),\\ldots, v(t))} $$\n",
    "```js\n",
    "p0 = v.rolling(window=k, center=False).sum()\n",
    "p1 = m*v.rolling(window=k, center=False).sum()\n",
    "p2 = p1/m.rolling(window=k, center=False).sum()\n",
    "p3 = v.rolling(window=k, center=False).mean()/v.rolling(window=k, center=False).std()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "_W6HiWVwxzyd"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "NyHUSYS0xzye"
   },
   "source": [
    "# Pairs Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "VCcyGo7hxzye"
   },
   "source": [
    "\n",
    "\n",
    "Pairs trading is a nice example of a strategy based on mathematical analysis. \n",
    "\n",
    "The principle is as follows:\n",
    "Let's say you have a pair of securities X and Y that have some underlying economic link. An example might be two companies that manufacture the same product, for example Pepsi and Coca Cola. You expect the spread (ratio or difference in prices) between these two to remain constant with time. However, from time to time, there might be a divergence in the spread between these two pairs. The divergence within a pair can be caused by temporary supply/demand changes, large buy/sell orders for one security, reaction for important news about one of the companies, and so on. When there is a temporary divergence between the two securities, i.e. one stock moves up while the other moves down, the pairs trade would be to short the outperforming stock and to long the underperforming one, betting that the \"spread\" between the two would eventually converge.\n",
    "\n",
    "Pairs trading is a market neutral trading strategy enabling traders to profit from virtually any market conditions: uptrend, downtrend, or sideways movement.\n",
    "\n",
    "We'll start by constructing an artificial example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XorIRuqyxzyf"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorboardX \n",
    "#!pip install bs4\n",
    "#!pip install -U auquan_toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "7V4tcBQvxzyg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import coint\n",
    "# just set the seed for the random number generator\n",
    "np.random.seed(107)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "fpbblmwBxzyh"
   },
   "source": [
    "### Explaining the Concept: We start by generating two fake securities.\n",
    "We model X's daily returns by drawing from a normal distribution. Then we perform a cumulative sum to get the value of X on each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OuE9JEZ7xzyh"
   },
   "outputs": [],
   "source": [
    "# Generate the daily returns\n",
    "Xreturns = np.random.normal(0, 1, 100) \n",
    "# sum them and shift all the prices up\n",
    "X = pd.Series(np.cumsum(Xreturns), name='X') + 50\n",
    "X.plot(figsize=(15,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "FmLQBJMNxzyj"
   },
   "source": [
    "Now we generate Y. Y is supposed to have a deep economic link to X, so the price of Y should vary pretty similarly. We model this by taking X, shifting it up and adding some random noise drawn from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "VjUOmwzxxzyj"
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, 100)\n",
    "Y = X + 5 + noise\n",
    "Y.name = 'Y'\n",
    "pd.concat([X, Y], axis=1).plot(figsize=(15,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Du06CzDHxzyl"
   },
   "source": [
    "### Cointegration\n",
    "Cointegration, very loosely speaking, is a \"different\" form of correlation. If two series are cointegrated, the ratio between them will vary around a mean.\n",
    "For pairs trading to work between two timeseries, the expected value of the ratio over time must converge to the mean, i.e. they should be cointegrated.\n",
    "The time series we constructued above are cointegrated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "MbuaclvMxzyl"
   },
   "outputs": [],
   "source": [
    "(Y/X).plot(figsize=(15,7)) \n",
    "plt.axhline((Y/X).mean(), color='red', linestyle='--') \n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Price Ratio', 'Mean'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "aI9N8Z01xzys"
   },
   "source": [
    "### Testing for Cointegration\n",
    "There is a convenient test that lives in statsmodels.tsa.stattools. We should see a very low p-value, as we've artificially created two series that are as cointegrated as physically possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "mm1aeSBrxzyt"
   },
   "outputs": [],
   "source": [
    "# compute the p-value of the cointegration test\n",
    "# will inform us as to whether the ratio between the 2 timeseries is stationary\n",
    "# around its mean\n",
    "score, pvalue, _ = coint(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "BMT9_3Nfxzyx"
   },
   "source": [
    "### How to make a pairs trade?\n",
    "Because two cointegrated time series (such as X and Y above) drift towards and apart from each other, there will be times when the spread is high and times when the spread is low. We make a pairs trade by buying one security and selling another. This way, if both securities go down together or go up together, we neither make nor lose money — we are market neutral.\n",
    "\n",
    "Going back to X and Y above that follow Y = ⍺ X + e, such that ratio (Y/X) moves around it’s mean value ⍺, we make money on the ratio of the two reverting to the mean. In order to do this we’ll watch for when X and Y are far apart, i.e ⍺ is too high or too low:\n",
    "\n",
    "* Going Long the Ratio This is when the ratio ⍺ is smaller than usual and we expect it to increase. In the above example, we place a bet on this by buying Y and selling X.\n",
    "* Going Short the Ratio This is when the ratio ⍺ is large and we expect it to become smaller. In the above example, we place a bet on this by selling Y and buying X.\n",
    "\n",
    "<b>Note </b> that we always have a “hedged position”: a short position makes money if the security sold loses value, and a long position will make money if a security gains value, so we’re immune to overall market movement. We only make or lose money if securities X and Y move relative to each other.\n",
    "\n",
    "### Using Data to find securities that behave like this\n",
    "The best way to do this is to start with securities you suspect may be cointegrated and perform a statistical test. If you just run statistical tests over all pairs, you’ll fall prey to multiple comparison bias.\n",
    "\n",
    "<b>Multiple comparisons bias </b> is simply the fact that there is an increased chance to incorrectly generate a significant p-value when many tests are run, because we are running a lot of tests. If 100 tests are run on random data, we should expect to see 5 p-values below 0.05. If you are comparing n securities for co-integration, you will perform n(n-1)/2 comparisons, and you should expect to see many incorrectly significant p-values, which will increase as you increase. To avoid this, pick a small number of pairs you have reason to suspect might be cointegrated and test each individually. This will result in less exposure to multiple comparisons bias.\n",
    "\n",
    "So let’s try to find some securities that display cointegration. Let’s work with a basket of US large cap tech stocks — in S&P 500. These stocks operate in a similar segment and could have cointegrated prices. We scan through a list of securities and test for cointegration between all pairs. It returns a cointegration test score matrix, a p-value matrix, and any pairs for which the p-value was less than 0.05. This method is prone to multiple comparison bias and in practice the securities should be subject to a second verification step. Let’s ignore this for the sake of this example.\n",
    "\n",
    "Note: We include the market benchmark (SPY) in our data — the market drives the movement of so many securities that often you might find two seemingly cointegrated securities; but in reality they are not cointegrated with each other but both cointegrated with the market. This is known as a confounding variable and it is important to check for market involvement in any relationship you find.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "lxak68VTxzyx"
   },
   "outputs": [],
   "source": [
    "def find_cointegrated_pairs(data):\n",
    "    n = data.shape[1]\n",
    "    score_matrix = np.zeros((n, n))\n",
    "    pvalue_matrix = np.ones((n, n))\n",
    "    keys = data.keys()\n",
    "    pairs = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            S1 = data[keys[i]]\n",
    "            S2 = data[keys[j]]\n",
    "            result = coint(S1, S2)\n",
    "            score = result[0]\n",
    "            pvalue = result[1]\n",
    "            score_matrix[i, j] = score\n",
    "            pvalue_matrix[i, j] = pvalue\n",
    "            if pvalue < 0.05:\n",
    "                pairs.append((keys[i], keys[j]))\n",
    "    return score_matrix, pvalue_matrix, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "yYgHCyBjxzyz"
   },
   "outputs": [],
   "source": [
    "from backtester.dataSource.yahoo_data_source import YahooStockDataSource\n",
    "from datetime import datetime\n",
    "\n",
    "startDateStr = '2007/12/01'\n",
    "endDateStr = '2017/12/01'\n",
    "cachedFolderName = 'yahooData/'\n",
    "dataSetId = 'testPairsTrading'\n",
    "instrumentIds = ['SPY','AAPL','ADBE','EBAY','MSFT','QCOM',\n",
    "                 'HPQ','JNPR','AMD','IBM']\n",
    "ds = YahooStockDataSource(cachedFolderName=cachedFolderName,\n",
    "                            dataSetId=dataSetId,\n",
    "                            instrumentIds=instrumentIds,\n",
    "                            startDateStr=startDateStr,\n",
    "                            endDateStr=endDateStr,\n",
    "                            event='history')\n",
    "data = ds.getBookDataByFeature()['adjClose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "KmmbzjhLxzy0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "aIfLrKN6xzy1"
   },
   "source": [
    "Lets  run our method on the list and see if any pairs are cointegrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "YeABsHOFxzy2"
   },
   "outputs": [],
   "source": [
    "# Heatmap to show the p-values of the cointegration test\n",
    "# between each pair of stocks\n",
    "\n",
    "scores, pvalues, pairs = find_cointegrated_pairs(data)\n",
    "import seaborn\n",
    "m = [0,0.2,0.4,0.6,0.8,1]\n",
    "seaborn.heatmap(pvalues, xticklabels=instrumentIds, \n",
    "                yticklabels=instrumentIds, cmap='RdYlGn_r' \n",
    "                , mask = (pvalues >= 0.98)\n",
    "                )\n",
    "plt.show()\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "dgJjFoj3xzy4"
   },
   "source": [
    "Looks like 'ADBE' and 'MSFT' are cointegrated. Let's take a look at the prices to make sure there's nothing weird going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "UG9SQxl2xzy5"
   },
   "outputs": [],
   "source": [
    "S1 = data['ADBE']\n",
    "S2 = data['MSFT']\n",
    "score, pvalue, _ = coint(S1, S2)\n",
    "print(pvalue)\n",
    "ratios = S1 / S2\n",
    "ratios.plot(figsize=(15,7))\n",
    "plt.axhline(ratios.mean())\n",
    "plt.legend(['Price Ratio'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WA0LmadUxzy-"
   },
   "source": [
    "The ratio does look like it moved around a stable mean.The absolute ratio isn’t very useful in statistical terms. It is more helpful to normalize our signal by treating it as a z-score. Z score is defined as:\n",
    "\n",
    "<i>Z Score (Value) = (Value — Mean) / Standard Deviation </i>\n",
    "\n",
    "<b>WARNING</b>\n",
    "In practice this is usually done to try to give some scale to the data, but this assumes an underlying distribution. Usually normal. However, much financial data is not normally distributed, and we must be very careful not to simply assume normality, or any specific distribution when generating statistics. The true distribution of ratios could be very fat-tailed and prone to extreme values messing up our model and resulting in large losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "8t728_ztxzy-"
   },
   "outputs": [],
   "source": [
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "4tKEaObfxzzA"
   },
   "outputs": [],
   "source": [
    "zscore(ratios).plot(figsize=(15,7))\n",
    "plt.axhline(zscore(ratios).mean(), color='black')\n",
    "plt.axhline(1.0, color='red', linestyle='--')\n",
    "plt.axhline(-1.0, color='green', linestyle='--')\n",
    "plt.legend(['Ratio z-score', 'Mean', '+1', '-1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "p3n0ut9GxzzB"
   },
   "source": [
    "### Simple Strategy:\n",
    "* Go \"Long\" the ratio whenever the z-score is below -1.0\n",
    "* Go \"Short\" the ratio when the z-score is above 1.0\n",
    "* Exit positions when the z-score approaches zero\n",
    "\n",
    "This is just the tip of the iceberg, and only a very simplistic example to illustrate the concepts.\n",
    "* In practice you would want to compute a more optimal weighting for how many shares to hold for S1 and S2\n",
    "* You would also want to trade using constantly updating statistics. \n",
    "\n",
    "In general taking a statistic over your whole sample size can be bad. For example, if the market is moving up, and both securities with it, then your average price over the last 3 years may not be representative of today. For this reason traders often use statistics that rely on rolling windows of the most recent data.\n",
    "\n",
    "Instead of using ratio values, let's use 5d Moving Average to compute to z score, and the 60d Moving Average and 60d Standard Deviation as the mean and standard deviation.\n",
    "\n",
    "First break the data into training set of 7 years and test set of 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "_JJjoPMyxzzC"
   },
   "outputs": [],
   "source": [
    "ratios = data['ADBE'] / data['MSFT']\n",
    "print(len(ratios))\n",
    "train = ratios[:1762]\n",
    "test = ratios[1762:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Zhm9SbIHxzzD"
   },
   "outputs": [],
   "source": [
    "ratios_mavg5 = train.rolling(window=5,\n",
    "                               center=False).mean()\n",
    "\n",
    "ratios_mavg60 = train.rolling(window=60,\n",
    "                               center=False).mean()\n",
    "\n",
    "std_60 = train.rolling(window=60,\n",
    "                        center=False).std()\n",
    "\n",
    "zscore_60_5 = (ratios_mavg5 - ratios_mavg60)/std_60\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(train.index, train.values)\n",
    "plt.plot(ratios_mavg5.index, ratios_mavg5.values)\n",
    "plt.plot(ratios_mavg60.index, ratios_mavg60.values)\n",
    "\n",
    "plt.legend(['Ratio','5d Ratio MA', '60d Ratio MA'])\n",
    "\n",
    "plt.ylabel('Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "7uZUEzmbxzzE"
   },
   "source": [
    "We can use the moving averages to compute the z-score of the ratio at each given time. This will tell us how extreme the ratio is and whether it's a good idea to enter a position at this time. Let's take a look at the z-score now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "eibMMg-IxzzE"
   },
   "outputs": [],
   "source": [
    "# Take a rolling 60 day standard deviation\n",
    "std_60 = train.rolling(window=60,center=False).std()\n",
    "std_60.name = 'std 60d'\n",
    "\n",
    "# Compute the z score for each day\n",
    "zscore_60_5 = (ratios_mavg5 - ratios_mavg60)/std_60\n",
    "zscore_60_5.name = 'z-score'\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "zscore_60_5.plot()\n",
    "plt.axhline(0, color='black')\n",
    "plt.axhline(1.0, color='red', linestyle='--')\n",
    "plt.axhline(-1.0, color='green', linestyle='--')\n",
    "plt.legend(['Rolling Ratio z-Score', 'Mean', '+1', '-1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "bd6W2zujxzzF"
   },
   "source": [
    "The z-score doesn't mean much out of context, let's plot it next to the prices to get an idea of what it looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "RbVRAH0HxzzF"
   },
   "outputs": [],
   "source": [
    "# Plot the ratios and buy and sell signals from z score\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "train[60:].plot()\n",
    "buy = train.copy()\n",
    "sell = train.copy()\n",
    "buy[zscore_60_5>-1] = 0\n",
    "sell[zscore_60_5<1] = 0\n",
    "buy[60:].plot(color='g', linestyle='None', marker='^')\n",
    "sell[60:].plot(color='r', linestyle='None', marker='^')\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis((x1,x2,ratios.min(),ratios.max()))\n",
    "plt.legend(['Ratio', 'Buy Signal', 'Sell Signal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "InJ0qbTrxzzG"
   },
   "source": [
    "What does that mean for actual stocks that we are trading? Let’s take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Q6k31tCGxzzG"
   },
   "outputs": [],
   "source": [
    "# Plot the prices and buy and sell signals from z score\n",
    "plt.figure(figsize=(18,9))\n",
    "S1 = data['ADBE'].iloc[:1762]\n",
    "S2 = data['MSFT'].iloc[:1762]\n",
    "\n",
    "S1[60:].plot(color='b')\n",
    "S2[60:].plot(color='c')\n",
    "buyR = 0*S1.copy()\n",
    "sellR = 0*S1.copy()\n",
    "\n",
    "# When buying the ratio, buy S1 and sell S2\n",
    "buyR[buy!=0] = S1[buy!=0]\n",
    "sellR[buy!=0] = S2[buy!=0]\n",
    "# When selling the ratio, sell S1 and buy S2 \n",
    "buyR[sell!=0] = S2[sell!=0]\n",
    "sellR[sell!=0] = S1[sell!=0]\n",
    "\n",
    "buyR[60:].plot(color='g', linestyle='None', marker='^')\n",
    "sellR[60:].plot(color='r', linestyle='None', marker='^')\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis((x1,x2,min(S1.min(),S2.min()),max(S1.max(),S2.max())))\n",
    "\n",
    "plt.legend(['ADBE','MSFT', 'Buy Signal', 'Sell Signal'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "_UOF6wIZxzzH"
   },
   "source": [
    "Notice how we sometimes make money on the short leg and sometimes on the long leg, and sometimes both.\n",
    "\n",
    "Let’s see what kind of profits this signal can generate. We write a simple backtester which buys 1 ratio (buy 1 ADBE stock and sell ratio x MSFT stock) when ratio is low, sell 1 ratio (sell 1 ADBE stock and buy ratio x MSFT stock) when it’s high and calculate PnL of these trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "WE4I0nb2xzzI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trade(S1, S2, window1, window2):\n",
    "    # If window length is 0, algorithm doesn't make sense, so exit\n",
    "    if (window1 == 0) or (window2 == 0):\n",
    "        return 0\n",
    "    # Compute rolling mean and rolling standard deviation\n",
    "    ratios = S1/S2\n",
    "    ma1 = ratios.rolling(window=window1,\n",
    "                               center=False).mean()\n",
    "    ma2 = ratios.rolling(window=window2,\n",
    "                               center=False).mean()\n",
    "    std = ratios.rolling(window=window2,\n",
    "                        center=False).std()\n",
    "    zscore = (ma1 - ma2)/std\n",
    "    # Simulate trading\n",
    "    # Start with no money and no positions\n",
    "    money = 0\n",
    "    countS1 = 0\n",
    "    countS2 = 0\n",
    "    for i in range(len(ratios)):\n",
    "        # Sell short if the z-score is > 1\n",
    "        if zscore[i] > 1:\n",
    "            money += S1[i] - S2[i] * ratios[i]\n",
    "            countS1 -= 1\n",
    "            countS2 += ratios[i]\n",
    "        # Buy long if the z-score is < 1\n",
    "        elif zscore[i] < -1:\n",
    "            money -= S1[i] - S2[i] * ratios[i]\n",
    "            countS1 += 1\n",
    "            countS2 -= ratios[i]\n",
    "        # Clear positions if the z-score between -.5 and .5\n",
    "        elif abs(zscore[i]) < 0.5:\n",
    "            money += countS1*S1[i] + S2[i] * countS2\n",
    "            countS1 = 0\n",
    "            countS2 = 0\n",
    "#         print('Z-score: '+ str(zscore[i]), countS1, countS2, S1[i] , S2[i])\n",
    "    return money\n",
    "\n",
    "\n",
    "trade(data['ADBE'].iloc[:1762], data['MSFT'].iloc[:1762], 5, 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "74xGGTzgxzzJ"
   },
   "source": [
    "The strategy seems profitable! Now we can optimize further by changing our moving average windows, by changing the thresholds for buy/sell and exit positions etc and check for performance improvements on validation data.\n",
    "We could also try more sophisticated models like Logistic Regression, SVM etc to make our 1/-1 predictions.\n",
    "\n",
    "Let's see how it does on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "wsdRr7RCxzzJ"
   },
   "outputs": [],
   "source": [
    "trade(data['ADBE'].iloc[1762:], data['MSFT'].iloc[1762:], 5, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "l7aiAdlVxzzP"
   },
   "source": [
    "### Profits again!\n",
    "\n",
    "### Avoid Overfitting\n",
    "\n",
    "Overfitting is the most dangerous pitfall of a trading strategy. In our model, we used rolling parameter estimates and may wish to optimize window length. We can simply iterate over all possible, reasonable window lengths and pick the length based on which our model performs the best . Below we write a simple loop to score window lengths based on pnl of training data and find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "-xmXfIqjxzzQ"
   },
   "outputs": [],
   "source": [
    "# Find the window length 0-254 \n",
    "# that gives the highest returns using this strategy\n",
    "length_scores = [trade(data['ADBE'].iloc[:1762], \n",
    "                data['MSFT'].iloc[:1762], 5, l) \n",
    "                for l in range(255)]\n",
    "best_length = np.argmax(length_scores)\n",
    "print ('Best window length:', best_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WmuSy8l5xzzR"
   },
   "source": [
    "Now we check the performance of our model on test data and we find that this window length is far from optimal! This is because our original choice was clearly overfitted to the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "6Dc3dI-WxzzR"
   },
   "outputs": [],
   "source": [
    "# Find the returns for test data\n",
    "# using what we think is the best window length\n",
    "length_scores2 = [trade(data['ADBE'].iloc[1762:], \n",
    "                  data['MSFT'].iloc[1762:],5, l) \n",
    "                  for l in range(255)]\n",
    "print (best_length, 'day window:', length_scores2[best_length])\n",
    "\n",
    "# Find the best window length based on this dataset, \n",
    "# and the returns using this window length\n",
    "best_length2 = np.argmax(length_scores2)\n",
    "print (best_length2, 'day window:', length_scores2[best_length2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "07s2KEv9xzzS"
   },
   "source": [
    "We can see this if we also plot Pnl by window length separately for traning and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "BOJ4liYexzzT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(length_scores)\n",
    "plt.plot(length_scores2)\n",
    "plt.xlabel('Window length')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(['Training', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ea0Xd65QxzzU"
   },
   "source": [
    "## Hedging\n",
    "Because you'd like to protect yourself from bad markets, often times short sales will be used to hedge long investments. Because a short sale makes money if the security sold loses value, and a long purchase will make money if a security gains value, one can long parts of the market and short others. That way if the entire market falls off a cliff, we'll still make money on the shorted securities and hopefully break even. In the case of two securities we'll call it a hedged position when we are long on one security and short on the other.\n",
    "\n",
    "## The Trick: Where it all comes together\n",
    "Because the securities drift towards and apart from each other, there will be times when the distance is high and times when the distance is low. The trick of pairs trading comes from maintaining a hedged position across X and Y. If both securities go down, we neither make nor lose money, and likewise if both go up. We make money on the spread of the two reverting to the mean. In order to do this we'll watch for when X and Y are far apart, then short Y and long X. Similarly we'll watch for when they're close together, and long Y and short X.\n",
    "\n",
    "### Going Long the Spread\n",
    "This is when the spread is small and we expect it to become larger. We place a bet on this by longing Y and shorting X.\n",
    "\n",
    "### Going Short the Spread\n",
    "This is when the spread is large and we expect it to become smaller. We place a bet on this by shorting Y and longing X.\n",
    "\n",
    "### Specific Bets\n",
    "One important concept here is that we are placing a bet on one specific thing, and trying to reduce our bet's dependency on other factors such as the market.\n",
    "\n",
    "## Finding real securities that behave like this\n",
    "The best way to do this is to start with securities you suspect may be cointegrated and perform a statistical test. If you just run statistical tests over all pairs, you'll fall prey to multiple comparison bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "JVN7rGkMxzzU"
   },
   "source": [
    "## Further Research\n",
    "This notebook contained some simple introductory approaches. In practice one should use more sophisticated statistics, some of which are listed here.\n",
    "\n",
    "* Augmented-Dickey Fuller test \n",
    "* Hurst exponent\n",
    "* Half-life of mean reversion inferred from an Ornstein–Uhlenbeck process\n",
    "* Kalman filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Dkosw9pkxzzU"
   },
   "source": [
    "[Another Example with Ratio instead of Spread and with Cryptos](https://www.reddit.com/r/algotrading/comments/ivi8sc/brief_guide_on_researching_strategies_and/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ApTeHD95xzzV"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "jm5oTP_NxzzV"
   },
   "source": [
    "# Long-Short Equity Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "EJb2Gb8YxzzV"
   },
   "source": [
    "Long-short equity refers to the fact that the strategy is both long and short in the equity market. This is a rather general statement, but has over time grown to mean a specific family of strategies. These strategies rank all stocks in the market using some model. The strategy then goes long (buys) the top $n$ equities of the ranking, and goes short on (sells) the bottom $n$ while maintaining equal dollar volume between the long and short positions. This has the advantage of being statistically robust, as by ranking stocks and entering hundreds or thousands of positions, you are making many bets on your ranking model rather than just a few risky bets. You are also betting purely on the quality of your ranking scheme, as the equal dollar volume long and short positions ensure that the strategy will remain market neutral (immune to market movements)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "id": "nPVI8pz7xzzV"
   },
   "source": [
    "##Ranking Scheme\n",
    "\n",
    "A ranking scheme is any model that can assign each stocks a number, where higher is better or worse. Examples could be value factors, technical indicators, pricing models, or a combination of all of the above. The Ranking Universes by Factors lecture will cover ranking schemes in more detail. Ranking schemes are the secret sauce of any long-short equity strategy, so developing them is nontrivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "OqMXxynPxzzV"
   },
   "source": [
    "##Making a Bet on the Ranking Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "uSR9PZ3GxzzW"
   },
   "source": [
    "Once we have determined a ranking scheme, we would like to be able to profit from it. We do this by investing an equal amount of money long into the top of the ranking, and short into the bottom. This ensures that the strategy will make money proportionally to the quality of the ranking only, and will be market neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "JM_vXTkOxzzW"
   },
   "source": [
    "###Long and Short Baskets\n",
    "\n",
    "If you are ranking $m$ equities, have $d$ dollars to invest, and your total target number of positions to hold is $2n$, then the long and short baskets are created as follows. For each equity in spots $1, \\dots, n$ in the ranking, sell $\\frac{1}{2n} * d$ dollars of that equity. For each equity in spots $m - n, \\dots, m$ in the ranking, buy $\\frac{1}{2n} * d$ dollars of that equity. \n",
    "\n",
    "####Friction Because of Prices\n",
    "\n",
    "Because equity prices will not always divide $\\frac{1}{2n} * d$ evenly, and equities must be bought in integer amounts, there will be some imprecision and the algorithm should get as close as it can to this number. Most algorithms will have access to some leverage during execution, so it is fine to buy slightly more than $\\frac{1}{2n} * d$ dollars per equity. This does, however, cause some friction at low capital amounts. For a strategy running $d = 100000$, and $n = 500$, we see that \n",
    "$$\\frac{1}{2n} * d = \\frac{1}{1000} * 100000 = 100$$\n",
    "This will cause big problems for expensive equities, and cause the algorithm to be overlevered. This is alleviated by trading fewer equities or increasing the capital, $d$. Luckily, long-short equity strategies tend to be very high capicity, so there is for most purposes no ceiling on the amount of money one can invest. For more information on algorithm capacities, refer to the algorithm capacity lecture when it is released."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "NH8dmn_HxzzW"
   },
   "source": [
    "###Returns Come From The Ranking Spread\n",
    "\n",
    "The returns of a long-short equity strategy are dependent on how well the ranking spreads out the high and low returns. To see how this works, consider this hypothetical example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "id": "LVezp7_LxzzW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "5EMDE068xzzY"
   },
   "outputs": [],
   "source": [
    "# We'll generate a random factor\n",
    "current_factor_values = np.random.normal(0, 1, 10000)\n",
    "equity_names = ['Equity ' + str(x) for x in range(10000)]\n",
    "# Put it into a dataframe\n",
    "factor_data = pd.Series(current_factor_values, index = equity_names)\n",
    "factor_data = pd.DataFrame(factor_data, columns=['Factor Value'])\n",
    "# Take a look at the dataframe\n",
    "factor_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "zy38Q1ycxzza"
   },
   "outputs": [],
   "source": [
    "# Now let's say our future returns are dependent on our factor values\n",
    "future_returns = current_factor_values + np.random.normal(0, 1, 10000)\n",
    "\n",
    "returns_data = pd.Series(future_returns, index=equity_names)\n",
    "returns_data = pd.DataFrame(returns_data, columns=['Returns'])\n",
    "# Put both the factor values and returns into one dataframe\n",
    "data = returns_data.join(factor_data)\n",
    "# Take a look\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "-JK3Dl2Lxzze"
   },
   "source": [
    "Now that we have factor values and returns, we can see what would happen if we ranked our equities based on factor values, and then entered the long and short positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ka7vHICyxzzf"
   },
   "outputs": [],
   "source": [
    "# Rank the equities\n",
    "ranked_data = data.sort('Factor Value')\n",
    "\n",
    "# Compute the returns of each basket\n",
    "# Baskets of size 500, so we create an empty array of shape (10000/500)\n",
    "number_of_baskets = 10000/500\n",
    "basket_returns = np.zeros(number_of_baskets)\n",
    "\n",
    "for i in range(number_of_baskets):\n",
    "    start = i * 500\n",
    "    end = i * 500 + 500 \n",
    "    basket_returns[i] = ranked_data[start:end]['Returns'].mean()\n",
    "\n",
    "# Plot the returns of each basket\n",
    "plt.bar(range(number_of_baskets), basket_returns)\n",
    "plt.ylabel('Returns')\n",
    "plt.xlabel('Basket')\n",
    "plt.legend(['Returns of Each Basket']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "6I8-TVXNxzzh"
   },
   "source": [
    "Let's compute the returns if we go long the top basket and short the bottom basket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "5uaJ25lVxzzh"
   },
   "outputs": [],
   "source": [
    "basket_returns[number_of_baskets-1] - basket_returns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "htLxwBZJxzzj"
   },
   "source": [
    "###Market Neutrality is Built-In\n",
    "\n",
    "The nice thing about making money based on the spread of the ranking is that it is unaffected by what the market does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "7KGYDTJkxzzj"
   },
   "outputs": [],
   "source": [
    "# We'll generate a random factor\n",
    "current_factor_values = np.random.normal(0, 1, 10000)\n",
    "equity_names = ['Equity ' + str(x) for x in range(10000)]\n",
    "# Put it into a dataframe\n",
    "factor_data = pd.Series(current_factor_values, index = equity_names)\n",
    "factor_data = pd.DataFrame(factor_data, columns=['Factor Value'])\n",
    "\n",
    "# Now let's say our future returns are dependent on our factor values\n",
    "future_returns = -10 + current_factor_values + np.random.normal(0, 1, 10000)\n",
    "\n",
    "returns_data = pd.Series(future_returns, index=equity_names)\n",
    "returns_data = pd.DataFrame(returns_data, columns=['Returns'])\n",
    "# Put both the factor values and returns into one dataframe\n",
    "data = returns_data.join(factor_data)\n",
    "\n",
    "# Rank the equities\n",
    "ranked_data = data.sort('Factor Value')\n",
    "\n",
    "# Compute the returns of each basket\n",
    "# Baskets of size 500, so we create an empty array of shape (10000/500\n",
    "number_of_baskets = 10000/500\n",
    "basket_returns = np.zeros(number_of_baskets)\n",
    "\n",
    "for i in range(number_of_baskets):\n",
    "    start = i * 500\n",
    "    end = i * 500 + 500 \n",
    "    basket_returns[i] = ranked_data[start:end]['Returns'].mean()\n",
    "\n",
    "basket_returns[number_of_baskets-1] - basket_returns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "FQ8oa6ihxzzk"
   },
   "source": [
    "##Choice and Evaluation of a Ranking Scheme\n",
    "\n",
    "The ranking scheme is where a long-short equity strategy gets its edge, and is the most crucial component. Choosing a good ranking scheme is the entire trick, and there is no easy answer. A good starting point is to pick existing known techniques, and see if you can modify them slightly to get increased returns. More information on ranking scheme construction can be found in the notebooks listed below.\n",
    "\n",
    "During research of your ranking scheme, it's important to determine whether or not your ranking scheme is actually predictive of future returns. This can be accomplished with spearman rank correlation\n",
    "\n",
    "Information on construction and evaluation of ranking schemes is available in the following lectures:\n",
    "* [Universe Selection](https://www.quantopian.com/lectures/universe-selection)\n",
    "* [Spearman Rank Correlation](https://www.quantopian.com/lectures/spearman-rank-correlation)\n",
    "* [Factor Analysis](https://www.quantopian.com/lectures/factor-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "eCYEgwk_xzzk"
   },
   "source": [
    "##Long-Short is a Modular Strategy\n",
    "\n",
    "To execute a long-short equity, you effectively only have to determine the ranking scheme. Everything after that is mechanical. Once you have one long-short equity strategy, you can swap in different ranking schemes and leave everything else in place. It's a very convenient way to quickly iterate over ideas you have without having to worry about tweaking code every time.\n",
    "\n",
    "The ranking schemes can come from pretty much any model as well. It doesn't have to be a value based factor model, it could be a machine learning technique that predicted returns one-month ahead and ranked based on that.\n",
    "\n",
    "We will be releasing sample long-short algorithms to go along with this notebook. Please stay tuned for those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "8izErYhbxzzk"
   },
   "source": [
    "##Additional Considerations\n",
    "\n",
    "###Rebalancing Frequency\n",
    "\n",
    "Every ranking system will be predictive of returns over a slightly different timeframe. A price-based mean reversion may be predictive over a few days, while a value-based factor model may be predictive over many months. It is important to determine the timeframe over which your model should be predictive, and statistically verify that before executing your strategy. You do want to overfit by trying to optimize the relabancing frequency, you will inevitably find one that is randomly better than others, but not necessary because of anything in your model.\n",
    "\n",
    "Once you have determined the timeframe on which your ranking scheme is predictive, try to rebalance at about that frequency so you're taking full advantage of your models.\n",
    "\n",
    "\n",
    "###Capital Capacity\n",
    "\n",
    "Every strategy has a minimum and maximum amount of capital it can trade before it stops being profitable. We will be releasing a full notebook discussing these concepts, but in the meantime consider the following.\n",
    "\n",
    "###Number of Equities Traded\n",
    "\n",
    "####Transaction Costs\n",
    "\n",
    "Trading many equities will result in high transaction costs. Say that you want to purchase $1000$ equities, you will incur thousands of dollars of costs per rebalance. Your capital base must be high enough that the transaction costs are a small percentage of the returns being generated by your strategy. Say that you are running $100,000$ dollars and making $1\\%$ per month, then the $1000$ dollars of transaction fees per month would take up your all of returns. You would need to be running the strategy on millions of dollars for it to be profitable over $1000$ equities.\n",
    "\n",
    "The minimum capacity is quite high as such, and dependent largely on the number of equities traded. However, the maximum capacity is also incredibly high, with long-short equity strategies capable of trading hundreds of millions of dollars without losing their edge. This is true because the strategy rebalances relatively infrequently, and the total dollar volume is divided by the number of equities traded. So if you turn over your entire portfolio of $100,000,000$ every month while running 1000 equities, you are only running $100,000$ dollar-volume per month through each equity, which isn't enough to be a significant market share for most securities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "X4kfAJNKxzzl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "kJX09lZvxzzm"
   },
   "source": [
    "# Kalman Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ltDdvtLGxzzm"
   },
   "source": [
    "In this section you will:\n",
    "\n",
    "- Estimate Moving Average\n",
    "- Use Kalman Filters to calculate the mean and covariance of our time series\n",
    "- Modify a Pairs trading function to make use of Kalman Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "FbW79lFPxzzm"
   },
   "source": [
    "## What is a Kalman Filter?\n",
    "\n",
    "The Kalman filter is an algorithm that uses noisy observations of a system over time to estimate the parameters of the system (some of which are unobservable) and predict future observations. At each time step, it makes a prediction, takes in a measurement, and updates itself based on how the prediction and measurement compare.\n",
    "\n",
    "The algorithm is as follows:\n",
    "1. Take as input a mathematical model of the system, i.e.\n",
    "  * the transition matrix, which tells us how the system evolves from one state to another. For instance, if we are modeling the movement of a car, then the next values of position and velocity can be computed from the previous ones using kinematic equations. Alternatively, if we have a system which is fairly stable, we might model its evolution as a random walk. If you want to read up on Kalman filters, note that this matrix is usually called $A$.\n",
    "  * the observation matrix, which tells us the next measurement we should expect given the predicted next state. If we are measuring the position of the car, we just extract the position values stored in the state. For a more complex example, consider estimating a linear regression model for the data. Then our state is the coefficients of the model, and we can predict the next measurement from the linear equation. This is denoted $H$.\n",
    "  * any control factors that affect the state transitions but are not part of the measurements. For instance, if our car were falling, gravity would be a control factor. If the noise does not have mean 0, it should be shifted over and the offset put into the control factors. The control factors are summarized in a matrix $B$ with time-varying control vector $u_t$, which give the offset $Bu_t$.\n",
    "  * covariance matrices of the transition noise (i.e. noise in the evolution of the system) and measurement noise, denoted $Q$ and $R$, respectively.\n",
    "2. Take as input an initial estimate of the state of the system and the error of the estimate, $\\mu_0$ and $\\sigma_0$.\n",
    "3. At each timestep:\n",
    "  * estimate the current state of the system $x_t$ using the transition matrix\n",
    "  * take as input new measurements $z_t$\n",
    "  * use the conditional probability of the measurements given the state, taking into account the uncertainties of the measurement and the state estimate, to update the estimated current state of the system $x_t$ and the covariance matrix of the estimate $P_t$\n",
    "\n",
    "[This graphic](https://upload.wikimedia.org/wikipedia/commons/a/a5/Basic_concept_of_Kalman_filtering.svg) illustrates the procedure followed by the algorithm. \n",
    "\n",
    "It's very important for the algorithm to keep track of the covariances of its estimates. This way, it can give us a more nuanced result than simply a point value when we ask for it, and it can use its confidence to decide how much to be influenced by new measurements during the update process. The more certain it is of its estimate of the state, the more skeptical it will be of measurements that disagree with the state.\n",
    "\n",
    "By default, the errors are assumed to be normally distributed, and this assumption allows the algorithm to calculate precise confidence intervals. It can, however, be implemented for non-normal errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "c82pVI3Uxzzm"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "GmQS6Widxzzm"
   },
   "outputs": [],
   "source": [
    "!pip install pykalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "wxffH8Lfxzzn"
   },
   "outputs": [],
   "source": [
    "!pip install qq-training-wheels auquan_toolbox --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Nc-rJIiFxzzo"
   },
   "outputs": [],
   "source": [
    "# Import a Kalman filter and other useful libraries\n",
    "from pykalman import KalmanFilter\n",
    "from scipy import poly1d\n",
    "\n",
    "from backtester.dataSource.yahoo_data_source import YahooStockDataSource\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "khM4BzdUxzzp"
   },
   "source": [
    "## Toy example: falling ball\n",
    "\n",
    "Imagine we have a falling ball whose motion we are tracking with a camera. The state of the ball consists of its position and velocity. We know that we have the relationship $x_t = x_{t-1} + v_{t-1}\\tau - \\frac{1}{2} g \\tau^2$, where $\\tau$ is the time (in seconds) elapsed between $t-1$ and $t$ and $g$ is gravitational acceleration. Meanwhile, our camera can tell us the position of the ball every second, but we know from the manufacturer that the camera accuracy, translated into the position of the ball, implies variance in the position estimate of about 3 meters.\n",
    "\n",
    "In order to use a Kalman filter, we need to give it transition and observation matrices, transition and observation covariance matrices, and the initial state. The state of the system is (position, velocity), so it follows the transition matrix\n",
    "$$ \\left( \\begin{array}{cc}\n",
    "1 & \\tau \\\\\n",
    "0 & 1 \\end{array} \\right) $$\n",
    "\n",
    "with offset $(-\\tau^2 \\cdot g/2, -\\tau\\cdot g)$. The observation matrix just extracts the position coordinate, (1  0), since we are measuring position. We know that the observation variance is 1, and transition covariance is 0 since we will be simulating the data the same way we specified our model. For the initial state, let's feed our model something bogus like (30, 10) and see how our system evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "bub_LIRGxzzp"
   },
   "outputs": [],
   "source": [
    "tau = 0.1\n",
    "\n",
    "# Set up the filter\n",
    "kf = KalmanFilter(n_dim_obs=1, n_dim_state=2, # position is 1-dimensional, (x,v) is 2-dimensional\n",
    "                  initial_state_mean=[30,10],\n",
    "                  initial_state_covariance=np.eye(2),\n",
    "                  transition_matrices=[[1,tau], [0,1]],\n",
    "                  observation_matrices=[[1,0]],\n",
    "                  observation_covariance=3,\n",
    "                  transition_covariance=np.zeros((2,2)),\n",
    "                  transition_offsets=[-4.9*tau**2, -9.8*tau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "izUzvXYFxzzq"
   },
   "outputs": [],
   "source": [
    "# Create a simulation of a ball falling for 40 units of time (each of length tau)\n",
    "times = np.arange(40)\n",
    "actual = -4.9*tau**2*times**2\n",
    "\n",
    "# Simulate the noisy camera data\n",
    "sim = actual + 3*np.random.randn(40)\n",
    "\n",
    "# Run filter on camera data\n",
    "state_means, state_covs = kf.filter(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "D2evPZLrxzzt"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(times, state_means[:,0])\n",
    "plt.plot(times, sim)\n",
    "plt.plot(times, actual)\n",
    "plt.legend(['Filter estimate', 'Camera data', 'Actual'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Height');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "tO1W5h9Vxzzv"
   },
   "source": [
    "At each point in time we plot the state estimate <i>after</i> accounting for the most recent measurement, which is why we are not at position 30 at time 0. The filter's attentiveness to the measurements allows it to correct for the initial bogus state we gave it. Then, by weighing its model and knowledge of the physical laws against new measurements, it is able to filter out much of the noise in the camera data. Meanwhile the confidence in the estimate increases with time, as shown by the graph below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "AQwxph_Mxzzw"
   },
   "outputs": [],
   "source": [
    "# Plot variances of x and v, extracting the appropriate values from the covariance matrix\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(times, state_covs[:,0,0])\n",
    "plt.plot(times, state_covs[:,1,1])\n",
    "plt.legend(['Var(x)', 'Var(v)'])\n",
    "plt.ylabel('Variance')\n",
    "plt.xlabel('Time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "n1A8e3cQxzzy"
   },
   "source": [
    "The Kalman filter can also do <i>smoothing</i>, which takes in all of the input data at once and then constructs its best guess for the state of the system in each period post factum. That is, it does not provide online, running estimates, but instead uses all of the data to estimate the historical state, which is useful if we only want to use the data after we have collected all of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "P2M8mdLixzzy"
   },
   "outputs": [],
   "source": [
    "# Use smoothing to estimate what the state of the system has been\n",
    "smoothed_state_means, _ = kf.smooth(sim)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(times, smoothed_state_means[:,0])\n",
    "plt.plot(times, sim)\n",
    "plt.plot(times, actual)\n",
    "plt.legend(['Smoothed estimate', 'Camera data', 'Actual'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Height');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "XG7ZOZhzxzzz"
   },
   "source": [
    "## Example: Estimating Moving Average\n",
    "\n",
    "Because the Kalman filter updates its estimates at every time step and tends to weigh recent observations more than older ones, it can be used to estimate rolling parameters of the data. When using a Kalman filter, there's no window length that we need to specify. This is useful for computing the moving average or for smoothing out estimates of other quantities.\n",
    "\n",
    "Below, we'll use both a Kalman filter and an n-day moving average to estimate the rolling mean of a dataset. We construct the inputs to the Kalman filter as follows:\n",
    "\n",
    "* The mean is the model's guess for the mean of the distribution from which measurements are drawn. This means our prediction of the next value is equal to our estimate of the mean. \n",
    "* Hopefully the mean describes our observations well, hence it shouldn't change significantly when we add an observation. This implies we can assume that it evolves as a random walk with a small error term. We set the transition matrix to 1 and transition covariance matrix is a small number.\n",
    "* We assume that the observations have variance 1 around the rolling mean (1 is chosen randomly). \n",
    "* Our initial guess for the mean is 0, but the filter realizes that that is incorrect and adjusts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "zlorhCMFxzzz"
   },
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "from backtester.dataSource.yahoo_data_source import YahooStockDataSource\n",
    "\n",
    "# Load pricing data for a security\n",
    "startDateStr = '2012/12/31'\n",
    "endDateStr = '2017/12/31'\n",
    "cachedFolderName = './yahooData/'\n",
    "dataSetId = 'testPairsTrading'\n",
    "instrumentIds = ['SPY','MSFT','ADBE']\n",
    "ds = YahooStockDataSource(cachedFolderName=cachedFolderName,\n",
    "                            dataSetId=dataSetId,\n",
    "                            instrumentIds=instrumentIds,\n",
    "                            startDateStr=startDateStr,\n",
    "                            endDateStr=endDateStr,\n",
    "                            event='history')\n",
    "\n",
    "# Get adjusted closing price\n",
    "data = ds.getBookDataByFeature()['adjClose']\n",
    "\n",
    "# Data for Adobe\n",
    "S1 = data['ADBE']\n",
    "# Data for Microsoft\n",
    "S2 = data['MSFT']\n",
    "\n",
    "# Take ratio of the adjusted closing prices\n",
    "x = S1/S2\n",
    "\n",
    "# Construct a Kalman filter\n",
    "kf = KalmanFilter(transition_matrices = [1],\n",
    "                  observation_matrices = [1],\n",
    "                  initial_state_mean = 0,\n",
    "                  initial_state_covariance = 1,\n",
    "                  observation_covariance=1,\n",
    "                  transition_covariance=.01)\n",
    "\n",
    "# Use the observed values of the price to get a rolling mean\n",
    "state_means, _ = kf.filter(x.values)\n",
    "state_means = pd.Series(state_means.flatten(), index=x.index)\n",
    "\n",
    "# Compute the rolling mean with various lookback windows\n",
    "mean30 = x.rolling(window = 10).mean()\n",
    "mean60 = x.rolling(window = 30).mean()\n",
    "mean90 = x.rolling(window = 60).mean()\n",
    "\n",
    "# Plot original data and estimated mean\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(state_means[60:], '-b', lw=2, )\n",
    "plt.plot(x[60:],'-g',lw=1.5)\n",
    "plt.plot(mean30[60:], 'm', lw=1)\n",
    "plt.plot(mean60[60:], 'y', lw=1)\n",
    "plt.plot(mean90[60:], 'c', lw=1)\n",
    "plt.title('Kalman filter estimate of average')\n",
    "plt.legend(['Kalman Estimate', 'X', '30-day Moving Average', '60-day Moving Average','90-day Moving Average'])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "N04m7dq1xzz0"
   },
   "source": [
    "### Observations\n",
    "\n",
    "As you can see, the estimate from Kalman Filter is usually somewhere between day 30 and day 60 moving average. This could be because the Filter updates its knowledge of the world based on the most recent data. The advantage of the Kalman filter is that we don't need to select a window length. It makes predictions based on the underlying model (that we set parameters for) and the data itself. We do open ourselves up to overfitting with some of the initialization parameters for the filter, but those are slightly easier to objectively define. There's no free lunch and we can't eliminate overfitting, but a Kalman Filter is more rigorous than a moving average and generally better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "bZgSkCiwxzz1"
   },
   "source": [
    "## Example: linear regression\n",
    "\n",
    "Let's try using a Kalman filter to find linear regression lines for a dataset. We'll be comparing a stock price with the S&P 500, so the result will be a sort of rolling alpha and beta for the stock, where $\\alpha$ and $\\beta$ are the parameters of the linear regression equation\n",
    "$$ y_t \\approx \\alpha + \\beta x_t $$\n",
    "\n",
    "Below we use colors to indicate the dates that the data points $(x_t, y_t)$ correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Tu7hl9lMxzz1"
   },
   "outputs": [],
   "source": [
    "# Load pricing data\n",
    "start = '2012-01-01'\n",
    "end = '2015-01-01'\n",
    "y = get_pricing('AMZN', fields='price', start_date=start, end_date=end)\n",
    "x = get_pricing('SPY', fields='price', start_date=start, end_date=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "P4xTKH9Pxzz2"
   },
   "outputs": [],
   "source": [
    "# Plot data and use colormap to indicate the date each point corresponds to\n",
    "cm = plt.get_cmap('jet')\n",
    "colors = np.linspace(0.1, 1, len(x))\n",
    "sc = plt.scatter(x, y, s=30, c=colors, cmap=cm, edgecolor='k', alpha=0.7)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.ax.set_yticklabels([str(p.date()) for p in x[::len(x)//9].index])\n",
    "plt.xlabel('SPY')\n",
    "plt.ylabel('AMZN');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "E6IhXF_7xzz3"
   },
   "source": [
    "Let's figure out the inputs to our Kalman filter. We'll say that the state of our system is the line that the observations are following, with parameters $\\alpha$ and $\\beta$. Our inital guesses for these parameters is (0,0), with a covariance matrix (which describes the error of our guess) of all ones. As in the example of the rolling mean, we assume that our parameters follow a random walk (transition matrix is the identity) with a small error term (transition covariance is a small number times the identity).\n",
    "\n",
    "To get from the state of our system to an observation, we dot the state $(\\beta, \\alpha)$ with $(x_i, 1)$ to get $\\beta x_i + \\alpha \\approx y_i$, so our observation matrix is just a column of 1s glued to $x$. We assume that the variance of our observations $y$ is 2. Now we are ready to use our observations of $y$ to evolve our estimates of the parameters $\\alpha$ and $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "M7x7Z9cVxzz3"
   },
   "outputs": [],
   "source": [
    "delta = 1e-3\n",
    "trans_cov = delta / (1 - delta) * np.eye(2) # How much random walk wiggles\n",
    "obs_mat = np.expand_dims(np.vstack([[x], [np.ones(len(x))]]).T, axis=1)\n",
    "\n",
    "kf = KalmanFilter(n_dim_obs=1, n_dim_state=2, # y is 1-dimensional, (alpha, beta) is 2-dimensional\n",
    "                  initial_state_mean=[0,0],\n",
    "                  initial_state_covariance=np.ones((2, 2)),\n",
    "                  transition_matrices=np.eye(2),\n",
    "                  observation_matrices=obs_mat,\n",
    "                  observation_covariance=2,\n",
    "                  transition_covariance=trans_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "NkbumKddxzz4"
   },
   "outputs": [],
   "source": [
    "# Use the observations y to get running estimates and errors for the state parameters\n",
    "state_means, state_covs = kf.filter(y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "XTSBPttdxzz5"
   },
   "source": [
    "Below we plot the means - that is, our best estimates - of $\\alpha$ and $\\beta$ over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "TnxM13Suxzz5"
   },
   "outputs": [],
   "source": [
    "_, axarr = plt.subplots(2, sharex=True)\n",
    "axarr[0].plot(x.index, state_means[:,0], label='slope')\n",
    "axarr[0].legend()\n",
    "axarr[1].plot(x.index, state_means[:,1], label='intercept')\n",
    "axarr[1].legend()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "QyRQN54-xzz-"
   },
   "source": [
    "Notice how much the parameters fluctuate over long periods of time. If we are basing a trading algorithm on this, such as something that involves beta hedging, it's important to have the best and most current estimate of the beta. To visualize how the system evolves through time, we plot every fifth state (linear model) below. For comparison, in black we have the line returned by using ordinary least-squares regression on the full dataset, which is very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ONpSAdSOxzz_"
   },
   "outputs": [],
   "source": [
    "# Plot data points using colormap\n",
    "sc = plt.scatter(x, y, s=30, c=colors, cmap=cm, edgecolor='k', alpha=0.7)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.ax.set_yticklabels([str(p.date()) for p in x[::len(x)//9].index])\n",
    "\n",
    "# Plot every fifth line\n",
    "step = 5\n",
    "xi = np.linspace(x.min()-5, x.max()+5, 2)\n",
    "colors_l = np.linspace(0.1, 1, len(state_means[::step]))\n",
    "for i, beta in enumerate(state_means[::step]):\n",
    "    plt.plot(xi, beta[0] * xi + beta[1], alpha=.2, lw=1, c=cm(colors_l[i]))\n",
    "    \n",
    "# Plot the OLS regression line\n",
    "plt.plot(xi, poly1d(np.polyfit(x, y, 1))(xi), '0.4')\n",
    "\n",
    "# Adjust axes for visibility\n",
    "plt.axis([125, 210, 150, 410])\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('SPY')\n",
    "plt.ylabel('AMZN');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "tPTgXk0-xz0B"
   },
   "source": [
    "Notice that although all of the state estimates take into account all previous observations, they fit the more recent data better than the older data. This allows the filter to adapt to structural changes in the data over time.\n",
    "\n",
    "Now, most of the time we care about correlation in returns more than correlation in prices, so let's quickly use the same linear regression structure on the returns data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "eo02y5BPxz0B",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get returns from pricing data\n",
    "x_r = x.pct_change()[1:]\n",
    "y_r = y.pct_change()[1:]\n",
    "\n",
    "# Run Kalman filter on returns data\n",
    "delta_r = 1e-2\n",
    "trans_cov_r = delta_r / (1 - delta_r) * np.eye(2) # How much random walk wiggles\n",
    "obs_mat_r = np.expand_dims(np.vstack([[x_r], [np.ones(len(x_r))]]).T, axis=1)\n",
    "kf_r = KalmanFilter(n_dim_obs=1, n_dim_state=2, # y_r is 1-dimensional, (alpha, beta) is 2-dimensional\n",
    "                  initial_state_mean=[0,0],\n",
    "                  initial_state_covariance=np.ones((2, 2)),\n",
    "                  transition_matrices=np.eye(2),\n",
    "                  observation_matrices=obs_mat_r,\n",
    "                  observation_covariance=.01,\n",
    "                  transition_covariance=trans_cov_r)\n",
    "state_means_r, _ = kf_r.filter(y_r.values)\n",
    "\n",
    "# Plot data points using colormap\n",
    "colors_r = np.linspace(0.1, 1, len(x_r))\n",
    "sc = plt.scatter(x_r, y_r, s=30, c=colors_r, cmap=cm, edgecolor='k', alpha=0.7)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.ax.set_yticklabels([str(p.date()) for p in x_r[::len(x_r)//9].index])\n",
    "\n",
    "# Plot every fifth line\n",
    "step = 5\n",
    "xi = np.linspace(x_r.min()-4, x_r.max()+4, 2)\n",
    "colors_l = np.linspace(0.1, 1, len(state_means_r[::step]))\n",
    "for i, beta in enumerate(state_means_r[::step]):\n",
    "    plt.plot(xi, beta[0] * xi + beta[1], alpha=.2, lw=1, c=cm(colors_l[i]))\n",
    "\n",
    "# Plot the OLS regression line\n",
    "plt.plot(xi, poly1d(np.polyfit(x_r, y_r, 1))(xi), '0.4')\n",
    "\n",
    "# Adjust axes for visibility\n",
    "plt.axis([-0.03,0.03,-0.11, 0.11])\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('SPY returns')\n",
    "plt.ylabel('AMZN returns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "2OEeoX1jxz0C"
   },
   "source": [
    "Although the raw data is much more jumbled here, we can see the regression line evolving, even swinging past the OLS regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "u8n8Prn1xz0D"
   },
   "source": [
    "We'll be using Kalman filters for Pairs trading the subsequent notebook. Make sure you try to run the examples given here with various hyperparameters for the underlying Kalman filter model to get comfortable with the same and developing a better understanding in the process. For example you can try out the following:\n",
    "1. Use multi dimensional transition matrices so as to use more of past information for making predictions at each point\n",
    "2. Try different values of observation and transition covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "omVv-72Cxz0D"
   },
   "source": [
    "## Example: Pairs Trading\n",
    "\n",
    "In the previous notebook we made use of 60 day window for calculating mean and standard deviation of our time series. Now we'll be replacing that with Kalman filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "qj_8Jf78xz0D"
   },
   "source": [
    "### Let's get the same data that we used in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "m06cOt3Lxz0D"
   },
   "outputs": [],
   "source": [
    "startDateStr = '2007/12/01'\n",
    "endDateStr = '2017/12/01'\n",
    "cachedFolderName = 'yahooData/'\n",
    "dataSetId = 'testPairsTrading2'\n",
    "instrumentIds = ['ADBE','MSFT']\n",
    "ds = YahooStockDataSource(cachedFolderName=cachedFolderName,\n",
    "                            dataSetId=dataSetId,\n",
    "                            instrumentIds=instrumentIds,\n",
    "                            startDateStr=startDateStr,\n",
    "                            endDateStr=endDateStr,\n",
    "                            event='history')\n",
    "data = ds.getBookDataByFeature()['adjClose']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "jcKHFMKDxz0E"
   },
   "source": [
    "### A quick visualization of error and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XKzGFNF5xz0F"
   },
   "outputs": [],
   "source": [
    "S1, S2 = data['ADBE'].iloc[:1762], data['MSFT'].iloc[:1762]\n",
    "ratios = S1/S2\n",
    "\n",
    "kf = KalmanFilter(transition_matrices = [1],\n",
    "              observation_matrices = [1],\n",
    "              initial_state_mean = 0,\n",
    "              initial_state_covariance = 1,\n",
    "              observation_covariance=1,\n",
    "              transition_covariance=.0001)\n",
    "\n",
    "state_means, state_cov = kf.filter(ratios.values)\n",
    "state_means, state_std = state_means.squeeze(), np.std(state_cov.squeeze())\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(ratios.values - state_means, 'm', lw=1)\n",
    "plt.plot(np.sqrt(state_cov.squeeze()), 'y', lw=1)\n",
    "plt.plot(-np.sqrt(state_cov.squeeze()), 'c', lw=1)\n",
    "plt.title('Kalman filter estimate')\n",
    "plt.legend(['Error: real_value - mean', 'std', '-std'])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Value');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "QDSj8ozIxz0G"
   },
   "source": [
    "We'll be using the z score in the same way as before. Our strategy is to go long or short only in the areas where the |error| is greater than one standard deviation. Since 1 day price could be noisy, we'll be using 5 day average for a particular day's price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "auW7_g6Cxz0G"
   },
   "source": [
    "#### Let's modify our trading function to make use of Kalman Filter while keeping the same logic for carrying out trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "tDcW4pWAxz0G"
   },
   "outputs": [],
   "source": [
    "def trade(S1, S2):\n",
    "    # Compute rolling mean and rolling standard deviation\n",
    "    ratios = S1/S2\n",
    "    \n",
    "    kf = KalmanFilter(transition_matrices = [1],\n",
    "                  observation_matrices = [1],\n",
    "                  initial_state_mean = 0,\n",
    "                  initial_state_covariance = 1,\n",
    "                  observation_covariance=1,\n",
    "                  transition_covariance=.001)\n",
    "    \n",
    "    state_means, state_cov = kf.filter(ratios.values)\n",
    "    state_means, state_std = state_means.squeeze(), np.std(state_cov.squeeze())\n",
    "    \n",
    "    window = 5\n",
    "    ma = ratios.rolling(window=window,\n",
    "                               center=False).mean()\n",
    "    zscore = (ma - state_means)/state_std\n",
    "    \n",
    "    # Simulate trading\n",
    "    # Start with no money and no positions\n",
    "    money = 0\n",
    "    countS1 = 0\n",
    "    countS2 = 0\n",
    "    for i in range(len(ratios)):\n",
    "        # Sell short if the z-score is > 1\n",
    "        if zscore[i] > 1:\n",
    "            money += S1[i] - S2[i] * ratios[i]\n",
    "            countS1 -= 1\n",
    "            countS2 += ratios[i]\n",
    "        # Buy long if the z-score is < 1\n",
    "        elif zscore[i] < -1:\n",
    "            money -= S1[i] - S2[i] * ratios[i]\n",
    "            countS1 += 1\n",
    "            countS2 -= ratios[i]\n",
    "        # Clear positions if the z-score between -.5 and .5\n",
    "        elif abs(zscore[i]) < 0.5:\n",
    "            money += countS1*S1[i] + S2[i] * countS2\n",
    "            countS1 = 0\n",
    "            countS2 = 0\n",
    "#         print('Z-score: '+ str(zscore[i]), countS1, countS2, S1[i] , S2[i])\n",
    "    return money\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ipu1k-hyxz0H"
   },
   "outputs": [],
   "source": [
    "trade(data['ADBE'].iloc[:1762], data['MSFT'].iloc[:1762])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "xm9jwAkoxz0J"
   },
   "source": [
    "The strategy is still profitable! You can try changing the hyperparameters of the Kalman Filter and see how it affects the PnL. The results might not be always better than the mean over moving window. You can try this with other instruments as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "o5kWmTC1xz0J"
   },
   "source": [
    "## Generalizations\n",
    "\n",
    "We can use a Kalman filter to model non-linear transition and observation functions, as well. For this purpose there exist extended and unscented Kalman filters, the latter of which is included in `pykalman`. These can even model situations where noise is not additive (for example, where noise is proportional to the size of the measurement). We can also specify non-Gaussian errors; this is useful in financial data, which tends to have heavy-tailed distributions.\n",
    "\n",
    "There are also algorithms for inferring some of the input parameters, such as the covariance matrices and initial state, from an initial set of data. This can be done with the `pykalman.em()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "bDMPV56pxz0J"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "4GCugxIkxz0J"
   },
   "source": [
    "# Hurst Exponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "BnCa3nHkxz0J"
   },
   "source": [
    "[incorporate as Intro](https://www.mql5.com/de/articles/2930)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "2Iaq-ZXSxz0K"
   },
   "source": [
    "In this notebook we'll implementing a strategy to trade on momentum. You'll be using the training wheels version of Auquan's toolbox to abstract out the details since the full version of toolbox is a bit comprehensive to get started with. \n",
    "\n",
    "We're providing you with a bare-bones version that shows you how to use 30 day momentum to trade on Apple, sometime between 2015 and 2017. This naive strategy loses money and that's to be expected. Your goal is to make use of Hurst exponent that you learnt in previous lessons to create a better strategy. \n",
    "\n",
    "This is an analytical method of momentum trading, but it is also to turn this into a machine learning problem. This is discussed at the end of the notebook, with a link to an extension exercise on the quant-quest website from Auquan for you to attempt this approach.\n",
    "\n",
    "**Goals**:\n",
    "1. Understand how the barebones momentum version is working and make yourself comfortable with it\n",
    "2. Use the Hurst exponent to create a money making strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XO6ZQUWRxz0K"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "5btoq8UYxz0L"
   },
   "source": [
    "Let's import everything we need to run our backtesting algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "pi6Tbkc7xz0L"
   },
   "outputs": [],
   "source": [
    "!pip install qq-training-wheels auquan_toolbox --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "NreU_-Fuxz0O"
   },
   "outputs": [],
   "source": [
    "from qq_training_wheels.momentum_trading import MomentumTradingParams\n",
    "from backtester.trading_system import TradingSystem\n",
    "from backtester.features.feature import Feature\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "HGP5JzVkxz0P"
   },
   "source": [
    "The class below implements all the logic you need to run the momentum backtester. Go through it and make sure you understand each part. You can run it first and make changes later to see if you made any improvements over the naive strategy.\n",
    "\n",
    "There are 6 functions within the class:\n",
    "\n",
    "- \\_\\_init\\_\\_\n",
    "- getSymbolsToTrade\n",
    "- getInstrumentFeatureConfigDicts\n",
    "- getPredictions\n",
    "- hurst_f\n",
    "- updateCount\n",
    "\n",
    "**__init__**\n",
    "\n",
    "Initializes the class\n",
    "\n",
    "**getSymbolsToTrade**\n",
    "\n",
    "This is where we can select which stocks we want to test our strategy on. Here we're using just AAPL is it is the only ticker returned\n",
    "\n",
    "**getInstrumentConfigDicts** \n",
    "\n",
    "This is the way that the toolbox creates features that we want to use in our logic. It's really important for resource optimisation at scale but can look a little daunting at first. We've created the features you'll need for you. If you're interested in learning more you can here: https://blog.quant-quest.com/toolbox-breakdown-getfeatureconfigdicts-function/\n",
    "\n",
    "**getPrediction**\n",
    "\n",
    "This again is fairly straight forward. We've included a few notes here, but for more detail: https://blog.quant-quest.com/toolbox-breakdown-getprediction-function/\n",
    "\n",
    "Once you've calculated the hurst exponent, this should contain the logic to use it and make profitable trades.\n",
    "\n",
    "**hurst_f**\n",
    "\n",
    "This is your time to shine! This is where you will need to implement the hurst exponent as shown in the previous lecture. There are several different ways of calculating the hurst exponent, so we recommend you use the method shown in the lecture to allow other people to easily help you - if needed!\n",
    "\n",
    "**updateCount**\n",
    "A counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "n2az3duMxz0P"
   },
   "outputs": [],
   "source": [
    "class MyTradingFunctions():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        # When to start trading\n",
    "        self.start_date = '2015/01/02'\n",
    "        # When to end trading\n",
    "        self.end_date = '2017/08/31'\n",
    "        self.params = {}\n",
    "\n",
    "    def getSymbolsToTrade(self):\n",
    "        '''\n",
    "        Specify the stock names that you want to trade.\n",
    "        '''\n",
    "        return ['AAPL']\n",
    "\n",
    "    def getInstrumentFeatureConfigDicts(self):\n",
    "        '''\n",
    "        Specify all Features you want to use by creating config dictionaries.\n",
    "        Create one dictionary per feature and return them in an array.\n",
    "\n",
    "        Feature config Dictionary have the following keys:\n",
    "\n",
    "        featureId: a str for the type of feature you want to use\n",
    "        featureKey: {optional} a str for the key you will use to call this feature\n",
    "                    If not present, will just use featureId\n",
    "        params: {optional} A dictionary with which contains other optional params if needed by the feature\n",
    "\n",
    "        msDict = {\n",
    "            'featureKey': 'ms_5',\n",
    "            'featureId': 'moving_sum',\n",
    "            'params': {\n",
    "                'period': 5,\n",
    "                'featureName': 'basis'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return [msDict]\n",
    "\n",
    "        You can now use this feature by in getPRediction() calling it's featureKey, 'ms_5'\n",
    "        '''\n",
    "\n",
    "        ma1Dict = {\n",
    "            'featureKey': 'ma_90',\n",
    "            'featureId': 'moving_average',\n",
    "            'params': {\n",
    "                'period': 90,\n",
    "                'featureName': 'adjClose'\n",
    "            }\n",
    "        }\n",
    "        mom30Dict = {\n",
    "            'featureKey': 'mom_30',\n",
    "            'featureId': 'momentum',\n",
    "            'params': {\n",
    "                'period': 30,\n",
    "                'featureName': 'adjClose'\n",
    "            }\n",
    "        }\n",
    "        mom10Dict = {\n",
    "            'featureKey': 'mom_10',\n",
    "            'featureId': 'momentum',\n",
    "            'params': {\n",
    "                'period': 10,\n",
    "                'featureName': 'adjClose'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return [ma1Dict, mom10Dict, mom30Dict]\n",
    "\n",
    "    def getPrediction(self, time, updateNum, instrumentManager, predictions):\n",
    "        '''\n",
    "        Combine all the features to create the desired predictions for each stock.\n",
    "        'predictions' is Pandas Series with stock as index and predictions as values\n",
    "        We first call the holder for all the instrument features for all stocks as\n",
    "            lookbackInstrumentFeatures = instrumentManager.getLookbackInstrumentFeatures()\n",
    "        Then call the dataframe for a feature using its feature_key as\n",
    "            ms5Data = lookbackInstrumentFeatures.getFeatureDf('ms_5')\n",
    "        This returns a dataFrame for that feature for ALL stocks for all times upto lookback time\n",
    "        Now you can call just the last data point for ALL stocks as\n",
    "            ms5 = ms5Data.iloc[-1]\n",
    "        You can call last datapoint for one stock 'ABC' as\n",
    "            value_for_abs = ms5['ABC']\n",
    "\n",
    "        Output of the prediction function is used by the toolbox to make further trading decisions and evaluate your score.\n",
    "        '''\n",
    "\n",
    "        self.updateCount() # uncomment if you want a counter\n",
    "\n",
    "        # holder for all the instrument features for all instruments\n",
    "        lookbackInstrumentFeatures = instrumentManager.getLookbackInstrumentFeatures()\n",
    "        \n",
    "        def hurst_f(input_ts, lags_to_test=20):  \n",
    "            # interpretation of return value\n",
    "            # hurst < 0.5 - input_ts is mean reverting\n",
    "            # hurst = 0.5 - input_ts is effectively random/geometric brownian motion\n",
    "            # hurst > 0.5 - input_ts is trending\n",
    "            tau = []\n",
    "            lagvec = []  \n",
    "            #  Step through the different lags  \n",
    "            for lag in range(2, lags_to_test):  \n",
    "                #  produce price difference with lag  \n",
    "                pp = np.subtract(input_ts[lag:].values, input_ts[:-lag].values)  \n",
    "                #  Write the different lags into a vector  \n",
    "                lagvec.append(lag)  \n",
    "                #  Calculate the variance of the differnce vector  \n",
    "                tau.append(np.sqrt(np.std(pp)))  \n",
    "            #  linear fit to double-log graph (gives power)  \n",
    "            m = np.polyfit(np.log10(lagvec), np.log10(tau), 1)  \n",
    "            # calculate hurst  \n",
    "            hurst = m[0]*2\n",
    "            print(hurst)\n",
    "            return hurst  \n",
    "\n",
    "        # dataframe for a historical instrument feature (ma_90 in this case). The index is the timestamps\n",
    "        # of upto lookback data points. The columns of this dataframe are the stock symbols/instrumentIds.\n",
    "        mom10Data = lookbackInstrumentFeatures.getFeatureDf('mom_10')\n",
    "        mom30Data = lookbackInstrumentFeatures.getFeatureDf('mom_30')\n",
    "        ma90Data = lookbackInstrumentFeatures.getFeatureDf('ma_90')\n",
    "        \n",
    "        # Here we are making predictions on the basis of Hurst exponent if enough data is available, otherwise\n",
    "        # we simply get out of our position\n",
    "        if len(ma90Data.index)>20:\n",
    "            mom30 = mom30Data.iloc[-1]\n",
    "            mom10 = mom10Data.iloc[-1]\n",
    "            ma90 = ma90Data.iloc[-1]\n",
    "            \n",
    "            # Calculate Hurst Exponent\n",
    "            hurst = ma90Data.apply(hurst_f, axis=0)\n",
    "            # Go long if Hurst > 0.5 and both long term and short term momentum are positive\n",
    "            predictions[(hurst > 0.5) & (mom30 > 0) & (mom10 > 0)] = 1 \n",
    "            # Go short if Hurst > 0.5 and both long term and short term momentum are negative\n",
    "            predictions[(hurst > 0.5) & (mom30 <= 0) & (mom10 <= 0)] = 0 \n",
    "            \n",
    "            # Get out of position if Hurst > 0.5 and long term momentum is positive while short term is negative\n",
    "            predictions[(hurst > 0.5) & (mom30 > 0) & (mom10 <= 0)] = 0.5\n",
    "            # Get out of position if Hurst > 0.5 and long term momentum is negative while short term is positive\n",
    "            predictions[(hurst > 0.5) & (mom30 <= 0) & (mom10 > 0)] = 0.5\n",
    "            \n",
    "            # Get out of position if Hurst < 0.5\n",
    "            predictions[hurst <= 0.5] = 0.5        \n",
    "        else:\n",
    "            # If no sufficient data then don't take any positions\n",
    "            predictions.values[:] = 0.5\n",
    "        return predictions\n",
    "\n",
    "    def updateCount(self):\n",
    "        self.count = self.count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "cBjN6umUxz0Q"
   },
   "source": [
    "### Initialize everything we've created so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "rdMrou5Ixz0R"
   },
   "outputs": [],
   "source": [
    "tf = MyTradingFunctions()\n",
    "tsParams = MomentumTradingParams(tf)\n",
    "tradingSystem = TradingSystem(tsParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "1TzTJUV0xz0S"
   },
   "source": [
    "### Start Trading ...\n",
    "You'll see your pnl as the backtesting runs. If you want more detailed results, two folders: `runLogs` and `tb_logs` are generated in the same directory as this script. You'll find the csv's for results inside `runLogs` and tensorboard log inside `tb_logs` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "YObCTYDBxz0S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = tradingSystem.startTrading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "u5fMnmRwxz0T"
   },
   "source": [
    "### Further reading on Hurst Exponents\n",
    "\n",
    "[Hurst Exponent and Trading Signals\n",
    "Derived from Market Time Series](https://www.scitepress.org/papers/2018/66670/66670.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "DD63T4VTxz0U"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "CTJDQrXvxz0U"
   },
   "source": [
    "# Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "mL8hi-s2xz0V"
   },
   "source": [
    "Why? Young Datapoints have more weight than older Datapoints\n",
    "https://towardsdatascience.com/time-series-in-python-exponential-smoothing-and-arima-processes-2c67f2a52788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "lzQ-HThWxz0V"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "HIT9EUWDxz0V"
   },
   "source": [
    "# Ornstein-Uhlenbeck Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "7KnPtWNYxz0W"
   },
   "source": [
    "https://hudsonthames.org/optimal-stopping-in-pairs-trading-ornstein-uhlenbeck-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "0SVvyzJ9xz0Y"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "bINTsjk0xz0Y"
   },
   "source": [
    "# Fourier Analysis: wavelet transformation (Haar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ZFnGsU5yxz0Y"
   },
   "source": [
    "\n",
    "<blockquote>\n",
    "    <p>The Fourier Transform takes its name from the French mathematician Jean-Baptiste Joseph Fourier. In 1807 he found that arbitrary functions could be written as a summation of sines and cosines. <br>\n",
    "The Fourier Transform makes it possible to decompose the original time signal into sinusoids. Each sinusoid has an associated amplitude, phase, and frequency. This is illustrated in the Figurebelow.</p>\n",
    "  \n",
    "</blockquote>\n",
    "<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "GVW_yLHvxz0Z"
   },
   "source": [
    "<a ><img src=\"https://community.sw.siemens.com/servlet/rtaImage?eid=ka54O000000PJMU&feoid=00N4O000006LZn5&refid=0EM4O00000113Qp\" Width=\"800\" align=\"center\"> </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "aULpl50Wxz0Z"
   },
   "source": [
    "### Fourier vs Wavelet \n",
    "\n",
    "*The difference between a Sine-wave and a Wavelet: The sine-wave is infinitely long and the Wavelet is localized in time.*\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a ><img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0165027000002508-gr1.gif\" Width=\"500\" align=\"center\"> </a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "For Stock Markets the latter is fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "v055Enp8xz0Z"
   },
   "source": [
    "Wavelets are mathematical functions that decompose data into different frequency components, after which each component is studied with a resolution matched to its scale, where a scale denotes a time horizon. Wavelet filtering is closely related to the volatile and timevarying characteristics of the real-world time series and is not limited by the stationarity assumption. The wavelet transform decomposes a process into different scales, making it useful in distinguishing seasonality, revealing structural breaks and volatility clusters, and identifying local and global dynamic properties of a process at specific timescales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "9j9Tnngixz0Z"
   },
   "source": [
    "Wavelet theory is applied for data preprocessing, since the representation of a wavelet can deal with the non-stationarity involved in the economic and financial time series. The key property of wavelets for economic analysis is decomposition by time scale. Economic and financial systems contain variables that operate on various time scales simultaneously; thus, the relations between variables may differ across time scales. One of the benefits of the wavelet approach is that it is flexible in handling highly irregular data series.\n",
    "A wavelet not only decomposes the data in terms of times and frequency, but also significantly reduces the processing time. Let $n$ denote the time series size, then the wavelet decomposition used in this study can be determined in $O(n)$ time.\n",
    "Wavelets theory is based on Fourier analysis, which represents any function as the sum of the sine and cosine functions. A wavelet $\\psi(t)$ is simply a function of time $t$ that obeys a basic rule, known as the wavelet admissibility condition:\n",
    "\n",
    "$$\n",
    "C_{\\psi}=\\int_{0}^{\\infty} \\frac{|\\psi(f)|}{f} d f<\\infty\n",
    "$$\n",
    "\n",
    "where $\\psi(f)$ is the Fourier transform and a function of frequency $f$, of$\\psi(t)$\n",
    "\n",
    "The wavelet transform (WT) is a mathematical tool that can be applied to numerous applications, such as image analysis and signal processing. It was introduced to solve problems associated with the Fourier transform as they occur. This occurrence can take place when dealing with non-stationary signals, or when dealing with signals that are localized in time, space, or frequency. Depending on the normalization rules, there are two types of wavelets within a given function/family. Father wavelets describe the smooth and low-frequency parts of a signal, and mother wavelets describe the detailed and high-frequency components. In the following equations, (2a) represents the father wavelet and (2b) represents the mother wavelet, with $j=1,...,J$ in the $J$-level wavelet decomposition:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\\phi_{j, k}=2^{-j / 2} \\phi\\left(t-2^{j} k / 2^{j}\\right) \\\\ \\psi_{j, k}=2^{-j / 2} \\psi\\left(t-2^{j} k / 2^{j}\\right)\\end{array}\n",
    "$$\n",
    "\n",
    "where $J$ denotes the maximum scale sustainable by the number of data points and the two types of wavelets stated above, namely father wavelets and mother wavelets, and satisfies:\n",
    "\n",
    "$$\n",
    "\\int \\phi(t) d t=1 \\text { and } \\int \\psi(t) d t=0\n",
    "$$\n",
    "\n",
    "Time series data, i.e., function $f(t)$, is an input represented by wavelet analysis, and can be built up as a sequence of projections onto father and mother wavelets indexed by both ${k}, k = {0, 1, 2,...}$ and by ${s}=2^j, {j=1, 2, 3,...J}$. Analyzing real discretely sampled data requires creating a lattice for making calculations. Mathematically, it is convenient to use a dyadic expansion, as shown in equation (3). The expansion coefficients are given by the projections:\n",
    "\n",
    "$$\n",
    "\\begin{aligned} s_{J, k} &=\\int \\phi_{J, k} f(t) d t \\\\ d_{j, k} &=\\int \\psi_{j, k} f(t) d t(j=1,2, \\ldots, J) \\end{aligned}\n",
    "$$\n",
    "\n",
    "The orthogonal wavelet series approximation to $f(t)$ is defined by:\n",
    "\n",
    "$$\n",
    "\\begin{aligned} f(t)=& \\sum_{k} s_{J, k} \\phi_{J, k}(t)+\\sum_{k} d_{J, k} \\psi_{J, k}(t)+\\sum_{k} d_{J-1, k} \\psi_{J-1, k}(t) \\\\ &+\\cdots+\\sum_{k} d_{1, k} \\psi_{1, k}(t) \\end{aligned}\n",
    "$$\n",
    "\n",
    "Another brief form can also be represented:\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}f(t)=S_{J}(t)+D_{J}(t)+D_{J-1}(t)+\\cdots+D_{1}(t) \\\\ S_{J}(t)=\\sum_{k} s_{J, k} \\phi_{J, k}(t) \\\\ D_{J}(t)=\\sum_{k} d_{J, k} \\psi_{J, k}(t)\\end{array}\n",
    "$$\n",
    "\n",
    "The WT is used to calculate the coefficient of the wavelet series approximation in Eq. (5) for a discrete signal $f_1, f_2,...,f_n$ with finite extent. The WT maps the vector $f=(f_1, f_2,...,f_n)$ to a vector of n wavelet coefficients $w=(w_1, w_2,...,w_n)$, which contains both the smoothing coefficient $s_J,k$ and the detail coefficients $d_j,k,j=1,2,...,J$. The symbol $s_j,k$ describes the underlying smooth behavior of the signal at coarse scale $2^J$ , while $d_j,k$ describes the coarse scale deviations from the smooth behavior, and $d_j−1,k ,. . .,d1,k$ provides progressively finer scale deviations from the smooth behavior.\n",
    "When $n$ is divisible by $2^J, d_1,k$ contains $n/2$ observations at the finest scale $2^1 = 2$, and $n/4$ observations in $d_2,k$ at the second finest scale, $2^1 = 2$. Likewise, each of $d_j,k$ and $s_j,k$ contain $n/2^J$ observations, where:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "n=n / 2+n / 4+\\cdots+n / 2^{J-1}+n / 2^{J}\n",
    "$$\n",
    "\n",
    "Let $f(t)$ denote the original data, $S_1$, represents an approximation signal, and $D_1$ is a detailed signal. This study defines the multi-resolution decomposition of a signal by specifying: $S_J$ is the coarsest scale and $S_J−1 = SJ + DJ$ . Generally, $S_j−1 = S_j + D_j$ where ${S_J , S_J−1 ,. . .,S_1 }$ is a sequence of multi-resolution approximations of the function $f(t)$, with ever increasing levels of refinement. The corresponding multi-resolution decomposition of $f(t)$ is given by ${S_J, D_J, D_J−1,. . .D_j,. . .,D_1}$.\n",
    "The sequence of terms $S_J, D_J, D_J−1,...D_j,...,D_1$ represents a set of orthogonal signal components that represent the signal at resolutions $1$ to $J$. Each $D_J−k$ provides the orthogonal increment to the\n",
    "$J_−k$ representation of the function $f(t)$ at the scale (or resolution) $2^J−k$ .\n",
    "When the data pattern is very rough, the wavelet process is repeatedly applied. The aim of preprocessing is to minimize the Root Mean Squared Error (RMSE) between the signal before and after transformation. The noise in the original data can thus be removed. Importantly, the adaptive noise in the training pattern may reduce the risk of overfitting in training phase. Thus, we adopt WT twice for the preprocessing of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "tvGL_YsYxz0Z"
   },
   "source": [
    "in Python:\n",
    "```js\n",
    "\n",
    "#!pip install pywavelets\n",
    "import pywt\n",
    "\n",
    "cA, cD = pywt.dwt(data, \"haar\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "edjYv-v0xz0a"
   },
   "source": [
    "<blockquote>\n",
    "    <p>Math needs to be reduced - Practical part needs more details</p>\n",
    "  \n",
    "</blockquote>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Zz-h0Ng_xz0a"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "kiXH3hV0xz0b"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "d2sb5c_Yxz0b"
   },
   "source": [
    "# Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "qGSoGHA2xz0b"
   },
   "source": [
    "length of the in-sample training window to 750 days (approximately three years) and the length of the subsequent out-of-sample trading window to 250 days (approximately one year). We move the training-trading set forward by 250 days in a sliding-window approach, resulting in 23 non-overlapping batches to loop over our entire data set from 1990 until 2015.\n",
    "\n",
    "We construct a classification instead of a regression problem, as the literature\n",
    "suggests that the former performs better than the latter in predicting financial market data\n",
    "(Leung et al., 2000; Enke and Thawornwong, 2005). \n",
    "However, please note that we forecast\n",
    "a probability Ps for each stock s to outperform the cross-sectional median in period t + 1, t+1\n",
    "which we then post-process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "xqs4WNkSxz0c"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Uwy6ahz7xz0c"
   },
   "source": [
    "# Deep Neural Networks (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "aSmSG-J-xz0c"
   },
   "source": [
    "This brief description of DNNs follows Candel et al. (2016); Dixon et al. (2015). A deep neural network consists of an input layer, one or more hidden layers, and an output layer, forming the topology of the net. The input layer matches the feature space, so that there are as many input neurons as predictors. The output layer is either a classification or regression layer to match the output space. All layers are composed of neurons, the basic units of such a model. In the classical feedforward architecture, each neuron in the previous layer l is fully connected with all neurons in the subsequent layer l + 1 via directed edges, each representing a certain weight. Also, each neuron in a non-output layer of the net has a bias unit, serving as its activation threshold. As such, each neuron receives a weighted combination α of the nl outputs of the neurons in the previous layer l as input,\n",
    "\n",
    "$$\n",
    "\\alpha=\\sum_{i=1}^{n_{l}} w_{i} x_{i}+b\n",
    "$$\n",
    "\n",
    "\n",
    "with wi denoting the weight of the output xi and b the bias. The weighted combination α of (2) is transformed via some activation function f, so that the output signal f (α) is relayed to the neurons in layer l + 1. Following Goodfellow et al. (2013), we use the maxout activation function $f: \\mathbb{R}^{2} \\rightarrow \\mathbb{R}$\n",
    "\n",
    "$$\n",
    "f\\left(\\alpha_{1}, \\alpha_{2}\\right)=\\max \\left(\\alpha_{1}, \\alpha_{2}\\right)\n",
    "$$\n",
    "\n",
    "receiving inputs from two separate channels with its own weights and biases. Our choice is motivated by the fact that maxout ”activation works particularly well with dropout” (Candel et al., 2016, p. 12) - a modern regularization technique.\n",
    "For the entire network, let W be the collection $W=\\bigcup_{l=1}^{L-1} W_{l}$, with Wl denoting the l=1\n",
    "weight matrix that connects layers $l$ and $l + 1$ for a network of $L$ layers. Analogously, let $B$ be the collection $B=\\bigcup_{l=1}^{L-1} b_{l}$, with $b_{l}$ denoting the column vector of biases for layer $l$. The collections $W$ and $B$ fully determine the output of the entire DNN. Learning is implemented\n",
    "by adapting these weights in order to minimize the error on the training data. In particular, the objective is to minimize some loss function $\\mathcal{L}(W, B \\mid j)$ for each training example j. Since we are dealing with a classification problem, the loss function is cross-entropy,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(W, B \\mid j)=-\\sum_{y \\in \\mathcal{O}}\\left(\\ln \\left(o_{y}^{(j)}\\right) t_{y}^{(j)}+\\ln \\left(1-o_{y}^{(j)}\\right)\\left(1-t_{y}^{(j)}\\right)\\right)\n",
    "$$\n",
    "\n",
    "with y representing the output units and $\\mathcal{O}$ the output layer. This loss function is min- imized by stochastic gradient descent, with the gradient of the loss function $\\nabla \\mathcal{L}(W, B \\mid j)$ being calculated via backpropagation. In the course of this optimization, we take advantage of two advanced methods via H2O. First, we use dropout - a modern form of regularization introduced by Srivastava et al. (2014). Thereby, each neuron suppresses its activation with a certain dropout probability during forward propagation for a given training example. As such, instead of one architecture, effectively $2^N$ architectures are trained, with $N$ denoting the number of training examples. The resulting network thus represents an ensemble of an exponentially large number of averaged models. This regularization method helps to avoid overfitting and improves generalization abilities. Second, we use an advanced optimization routine in H2O called ADADELTA (Candel et al., 2016; Zeiler, 2012), combining the advantages of momentum learning and rate annealing. The former aids in avoiding local minima and the latter helps in preventing ”optimum skipping” in the optimization landscape (Zeiler, 2012).\n",
    "”The design of an ANN is more of an art than a science” (Zhang et al., 1998, p. 42), and\n",
    "tuning parameters are often determined via computationally highly intensive hyperpareme-\n",
    "ter optimization routines and cross-validation. Instead, we opt for a pragmatic approach and\n",
    "fix the tuning parameters based on the literature. First, let us describe the topology of the\n",
    "net with the following code: I-H1-H2-H3-O. I denotes the number of input neurons, H1, H2,\n",
    "and H3 the number of hidden neurons in hidden layers 1, 2, 3, and O the number of output\n",
    "neurons. In this respect, we choose a 31-31-10-5-2 architecture. The input layer matches\n",
    "the input space with 31 features. Overfitting is a major issue: researchers have provided\n",
    "empirical rules to restrict the number of hidden nodes. Of course, none of theses heuristics\n",
    "works well for each and every problem. A popular rule to set the number of neurons in the\n",
    "first hidden layer of a feedforward network is to use as many neurons as there are inputs.\n",
    "We follow this recommendation in our application. Via the second and third hidden layer,\n",
    "we introduce a bottleneck, enforcing a reduction in dimensionality in line with Takeuchi and\n",
    "Lee (2013); Dixon et al. (2015). \n",
    "The output layer matches the binary output space. This\n",
    "configuration requires the estimation of 2746 parameters, so we have more than 136 training examples per parameter, yielding robust results. Second, we perform regularization. In particular, we use a hidden dropout ratio of 0.5, which ”seems to be close to optimal for a wide range of networks and tasks” (Srivastava et al., 2014, p. 1930) and an input dropout ratio of 0.1, again in line with the suggestions in Srivastava et al. (2014). Also, we perform slight L1 regularization with shrinkage parameter $\\lambda_{D N N}=0.00001$. Third, we train with 400 epochs, i.e., we pass 400 times over the training set, as in Huck (2009). For the sake of reproducibility, we set the seed to one, run all calculations on a single core to suppress hardware-based stochastics, and leave all potential further tuning parameters at their H2O default values.\n",
    "At this stage, we would like to point out that our network is still relatively small with only 31 inputs and 2746 parameters. Deep learning allows for large-scale models with thousands of features and millions of parameters, offering significant potential for further studies. How- ever, for starting to bridge the gap between academic and professional finance, our model is sufficient, computationally not too costly, and exhibits state-of-the-art features, i.e., dropout regularization, maxout activation, and ADADELTA optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "X1Doke1Bxz0c"
   },
   "source": [
    "## Introducing the Keras Sequential API\n",
    "\n",
    "**Learning Objectives**\n",
    "  1. Build a DNN model using the Keras Sequential API\n",
    "  1. Learn how to use feature columns in a Keras model\n",
    "  1. Learn how to train a model with Keras\n",
    "  1. Learn how to save/load, and deploy a Keras model on GCP\n",
    "  1. Learn how to deploy and make predictions with at Keras model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The [Keras sequential API](https://keras.io/models/sequential/) allows you to create Tensorflow models layer-by-layer. This is useful for building most kinds of machine learning models but it does not allow you to create models that share layers, re-use layers or have multiple inputs or outputs. \n",
    "\n",
    "In this lab, we'll see how to build a simple deep neural network model using the Keras sequential api and feature columns. Once we have trained our model, we will deploy it using AI Platform and see how to call our model for online prediciton.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "BVPM8kSFxz0d"
   },
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "pq2j5rKIxz0f"
   },
   "outputs": [],
   "source": [
    "# Ensure the right version of Tensorflow is installed.\n",
    "!pip freeze | grep tensorflow==2.1 || pip install tensorflow==2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "fmGF0q92xz0o"
   },
   "source": [
    "Please ignore any incompatibility warnings and errors and re-run the cell to view the installed tensorflow version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "n0jR3Wxgxz0p"
   },
   "source": [
    "Start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "22N4mfZkxz0p"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, DenseFeatures\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "print(tf.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "RbGw3ksOxz0q"
   },
   "source": [
    "### Load raw data \n",
    "\n",
    "We will use the taxifare dataset, using the CSV files that we created in the first notebook of this sequence. Those files have been saved into `../data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "qSw1ojSXxz0r"
   },
   "outputs": [],
   "source": [
    "!ls -l ../data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "F5ypJbg0xz0u"
   },
   "outputs": [],
   "source": [
    "!head ../data/taxi*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "TaTjLn1Gxz06"
   },
   "source": [
    "### Use tf.data to read the CSV files\n",
    "\n",
    "We wrote these functions for reading data from the csv files above in the [previous notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/labs/2_dataset_api.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ddS4s6a2xz07"
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = [\n",
    "    'fare_amount',\n",
    "    'pickup_datetime',\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'passenger_count',\n",
    "    'key'\n",
    "]\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], ['na'], [0.0], [0.0], [0.0], [0.0], [0.0], ['na']]\n",
    "UNWANTED_COLS = ['pickup_datetime', 'key']\n",
    "\n",
    "\n",
    "def features_and_labels(row_data):\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    features = row_data\n",
    "    \n",
    "    for unwanted_col in UNWANTED_COLS:\n",
    "        features.pop(unwanted_col)\n",
    "\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def create_dataset(pattern, batch_size=1, mode='eval'):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        pattern, batch_size, CSV_COLUMNS, DEFAULTS)\n",
    "\n",
    "    dataset = dataset.map(features_and_labels)\n",
    "\n",
    "    if mode == 'train':\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # take advantage of multi-threading; 1=AUTOTUNE\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "eo7xnQqaxz1A"
   },
   "source": [
    "### Build a simple keras DNN model\n",
    "\n",
    "We will use feature columns to connect our raw data to our keras DNN model. Feature columns make it easy to perform common types of feature engineering on your raw data. For example, you can one-hot encode categorical data, create feature crosses, embeddings and more. We'll cover these in more detail later in the course, but if you want to a sneak peak browse the official TensorFlow [feature columns guide](https://www.tensorflow.org/guide/feature_columns).\n",
    "\n",
    "In our case we won't do any feature engineering. However, we still need to create a list of feature columns to specify the numeric values which will be passed on to our model. To do this, we use `tf.feature_column.numeric_column()`\n",
    "\n",
    "We use a python dictionary comprehension to create the feature columns for our model, which is just an elegant alternative to a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "GNFqWrsoxz1B"
   },
   "outputs": [],
   "source": [
    "INPUT_COLS = [\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'passenger_count',\n",
    "]\n",
    "\n",
    "# Create input layer of feature columns\n",
    "# TODO 1\n",
    "feature_columns = {\n",
    "    colname: tf.feature_column.numeric_column(colname)\n",
    "    for colname in INPUT_COLS\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "IXRW_tFNxz1C"
   },
   "source": [
    "Next, we create the DNN model. The Sequential model is a linear stack of layers and when building a model using the Sequential API, you configure each layer of the model in turn. Once all the layers have been added, you compile the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "C6gjaavZxz1C"
   },
   "outputs": [],
   "source": [
    "# Build a keras DNN model using Sequential API\n",
    "# TODO 2a\n",
    "model = Sequential([\n",
    "    DenseFeatures(feature_columns=feature_columns.values()),\n",
    "    Dense(units=32, activation=\"relu\", name=\"h1\"),\n",
    "    Dense(units=8, activation=\"relu\", name=\"h2\"),\n",
    "    Dense(units=1, activation=\"linear\", name=\"output\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "EW4wTfoGxz1D"
   },
   "source": [
    "Next, to prepare the model for training, you must configure the learning process. This is done using the compile method. The compile method takes three arguments:\n",
    "\n",
    "* An optimizer. This could be the string identifier of an existing optimizer (such as `rmsprop` or `adagrad`), or an instance of the [Optimizer class](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers).\n",
    "* A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function from the [Losses class](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses) (such as categorical_crossentropy or mse), or it can be a custom objective function.\n",
    "* A list of metrics. For any machine learning problem you will want a set of metrics to evaluate your model. A metric could be the string identifier of an existing metric or a custom metric function.\n",
    "\n",
    "We will add an additional custom metric called `rmse` to our list of metrics which will return the root mean square error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "rE6Lw-Z8xz1D"
   },
   "outputs": [],
   "source": [
    "# TODO 2b\n",
    "# Create a custom evalution metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "# Compile the keras model\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "qkaj_PLZxz1E"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "To train your model, Keras provides three functions that can be used:\n",
    " 1. `.fit()` for training a model for a fixed number of epochs (iterations on a dataset).\n",
    " 2. `.fit_generator()` for training a model on data yielded batch-by-batch by a generator\n",
    " 3. `.train_on_batch()` runs a single gradient update on a single batch of data. \n",
    " \n",
    "The `.fit()` function works well for small datasets which can fit entirely in memory. However, for large datasets (or if you need to manipulate the training data on the fly via data augmentation, etc) you will need to use `.fit_generator()` instead. The `.train_on_batch()` method is for more fine-grained control over training and accepts only a single batch of data.\n",
    "\n",
    "The taxifare dataset we sampled is small enough to fit in memory, so can we could use `.fit` to train our model. Our `create_dataset` function above generates batches of training examples, so we could also use `.fit_generator`. In fact, when calling `.fit` the method inspects the data, and if it's a generator (as our dataset is) it will invoke automatically `.fit_generator` for training. \n",
    "\n",
    "We start by setting up some parameters for our training job and create the data generators for the training and validation data.\n",
    "\n",
    "We refer you the the blog post [ML Design Pattern #3: Virtual Epochs](https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730) for further details on why express the training in terms of `NUM_TRAIN_EXAMPLES` and `NUM_EVALS` and why, in this training code, the number of epochs is really equal to the number of evaluations we perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "PWZRAvDAxz1F"
   },
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 1000\n",
    "NUM_TRAIN_EXAMPLES = 10000 * 5  # training dataset will repeat, wrap around\n",
    "NUM_EVALS = 50  # how many times to evaluate\n",
    "NUM_EVAL_EXAMPLES = 10000  # enough to get a reasonable sample\n",
    "\n",
    "trainds = create_dataset(\n",
    "    pattern='../data/taxi-train*',\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    mode='train')\n",
    "\n",
    "evalds = create_dataset(\n",
    "    pattern='../data/taxi-valid*',\n",
    "    batch_size=1000,\n",
    "    mode='eval').take(NUM_EVAL_EXAMPLES//1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "pjDW1w-Bxz1G"
   },
   "source": [
    "There are various arguments you can set when calling the [.fit method](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit). Here `x` specifies the input data which in our case is a `tf.data` dataset returning a tuple of (inputs, targets). The `steps_per_epoch` parameter is used to mark the end of training for a single epoch. Here we are training for NUM_EVALS epochs. Lastly, for the `callback` argument we specify a Tensorboard callback so we can inspect Tensorboard after training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Nu3I7_t4xz1G"
   },
   "outputs": [],
   "source": [
    "%time \n",
    "# TODO 3\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (TRAIN_BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "LOGDIR = \"./taxi_trained\"\n",
    "history = model.fit(x=trainds,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=NUM_EVALS,\n",
    "                    validation_data=evalds,\n",
    "                    callbacks=[TensorBoard(LOGDIR)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "bUeqHXqjxz1I"
   },
   "source": [
    "### High-level model evaluation\n",
    "\n",
    "Once we've run data through the model, we can call `.summary()` on the model to get a high-level summary of our network. We can also plot the training and evaluation curves for the metrics we computed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XmX80QmHxz1J"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "jCtqZzwdxz1J"
   },
   "source": [
    "Running `.fit` (or `.fit_generator`) returns a History object which collects all the events recorded during training. Similar to Tensorboard, we can plot the training and validation curves for the model loss and rmse by accessing these elements of the History object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "LsYRum78xz1K"
   },
   "outputs": [],
   "source": [
    "RMSE_COLS = ['rmse', 'val_rmse']\n",
    "\n",
    "pd.DataFrame(history.history)[RMSE_COLS].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "1A-or1Ngxz1M"
   },
   "outputs": [],
   "source": [
    "LOSS_COLS = ['loss', 'val_loss']\n",
    "\n",
    "pd.DataFrame(history.history)[LOSS_COLS].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "xrVGzWToxz1O"
   },
   "source": [
    "### Making predictions with our model\n",
    "\n",
    "To make predictions with our trained model, we can call the [predict method](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict), passing to it a dictionary of values. The `steps` parameter determines the total number of steps before declaring the prediction round finished. Here since we have just one example, we set `steps=1` (setting `steps=None` would also work). Note, however, that if x is a `tf.data` dataset or a dataset iterator, and steps is set to None, predict will run until the input dataset is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "6CeAw0VQxz1O"
   },
   "outputs": [],
   "source": [
    "model.predict(x={\"pickup_longitude\": tf.convert_to_tensor([-73.982683]),\n",
    "                 \"pickup_latitude\": tf.convert_to_tensor([40.742104]),\n",
    "                 \"dropoff_longitude\": tf.convert_to_tensor([-73.983766]),\n",
    "                 \"dropoff_latitude\": tf.convert_to_tensor([40.755174]),\n",
    "                 \"passenger_count\": tf.convert_to_tensor([3.0])},\n",
    "              steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "b3rg-yE0xz1P"
   },
   "source": [
    "### Export and deploy our model\n",
    "\n",
    "Of course, making individual predictions is not realistic, because we can't expect client code to have a model object in memory. For others to use our trained model, we'll have to export our model to a file, and expect client code to instantiate the model from that exported file. \n",
    "\n",
    "We'll export the model to a TensorFlow SavedModel format. Once we have a model in this format, we have lots of ways to \"serve\" the model, from a web application, from JavaScript, from mobile applications, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "2T4evQ6Kxz1P"
   },
   "outputs": [],
   "source": [
    "# TODO 4a\n",
    "OUTPUT_DIR = \"./export/savedmodel\"\n",
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "EXPORT_PATH = os.path.join(OUTPUT_DIR,\n",
    "                           datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "tf.saved_model.save(model, EXPORT_PATH)  # with default serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OHFOrcXzxz1R"
   },
   "outputs": [],
   "source": [
    "# TODO 4b\n",
    "!saved_model_cli show \\\n",
    " --tag_set serve \\\n",
    " --signature_def serving_default \\\n",
    " --dir {EXPORT_PATH}\n",
    "!find {EXPORT_PATH}\n",
    "os.environ['EXPORT_PATH'] = EXPORT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "E3--pOFyxz1Z"
   },
   "source": [
    "### Deploy our model to AI Platform\n",
    "\n",
    "Finally, we will deploy our trained model to AI Platform and see how we can make online predicitons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "sWfjGakoxz1Z"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# TODO 5a\n",
    "\n",
    "PROJECT= # TODO: Change this to your PROJECT\n",
    "BUCKET=${PROJECT}\n",
    "REGION=us-east1\n",
    "MODEL_NAME=taxifare\n",
    "VERSION_NAME=dnn\n",
    "\n",
    "## Create GCS bucket if it doesn't exist already...\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "\n",
    "if [ -n \"$exists\" ]; then\n",
    "    echo -e \"Bucket exists, let's not recreate it.\"\n",
    "else\n",
    "    echo \"Creating a new GCS bucket.\"\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "    echo \"\\nHere are your current buckets:\"\n",
    "    gsutil ls\n",
    "fi\n",
    "\n",
    "if [[ $(gcloud ai-platform models list --format='value(name)' | grep $MODEL_NAME) ]]; then\n",
    "    echo \"$MODEL_NAME already exists\"\n",
    "else\n",
    "    echo \"Creating $MODEL_NAME\"\n",
    "    gcloud ai-platform models create --regions=$REGION $MODEL_NAME\n",
    "fi\n",
    "\n",
    "if [[ $(gcloud ai-platform versions list --model $MODEL_NAME --format='value(name)' | grep $VERSION_NAME) ]]; then\n",
    "    echo \"Deleting already existing $MODEL_NAME:$VERSION_NAME ... \"\n",
    "    echo yes | gcloud ai-platform versions delete --model=$MODEL_NAME $VERSION_NAME\n",
    "    echo \"Please run this cell again if you don't see a Creating message ... \"\n",
    "    sleep 2\n",
    "fi\n",
    "\n",
    "echo \"Creating $MODEL_NAME:$VERSION_NAME\"\n",
    "gcloud ai-platform versions create --model=$MODEL_NAME $VERSION_NAME \\\n",
    "       --framework=tensorflow --python-version=3.7 --runtime-version=2.1 \\\n",
    "       --origin=$EXPORT_PATH --staging-bucket=gs://$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "4Aqo75p0xz1a"
   },
   "outputs": [],
   "source": [
    "%%writefile input.json\n",
    "{\"pickup_longitude\": -73.982683, \"pickup_latitude\": 40.742104,\"dropoff_longitude\": -73.983766,\"dropoff_latitude\": 40.755174,\"passenger_count\": 3.0}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "l1xEKRIzxz1c"
   },
   "outputs": [],
   "source": [
    "# TODO 5b\n",
    "!gcloud ai-platform predict --model taxifare --json-instances input.json --version dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "b-hNyiNwxz1d"
   },
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ru9wSw5vxz1d"
   },
   "outputs": [],
   "source": [
    "# Introducing the Keras Sequential API\n",
    "\n",
    "**Learning Objectives**\n",
    "  1. Build a DNN model using the Keras Sequential API\n",
    "  1. Learn how to use feature columns in a Keras model\n",
    "  1. Learn how to train a model with Keras\n",
    "  1. Learn how to save/load, and deploy a Keras model on GCP\n",
    "  1. Learn how to deploy and make predictions with at Keras model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The [Keras sequential API](https://keras.io/models/sequential/) allows you to create Tensorflow models layer-by-layer. This is useful for building most kinds of machine learning models but it does not allow you to create models that share layers, re-use layers or have multiple inputs or outputs. \n",
    "\n",
    "In this lab, we'll see how to build a simple deep neural network model using the Keras sequential api and feature columns. Once we have trained our model, we will deploy it using AI Platform and see how to call our model for online prediciton.\n",
    "\n",
    "\n",
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst\n",
    "\n",
    "# Ensure the right version of Tensorflow is installed.\n",
    "!pip freeze | grep tensorflow==2.1 || pip install tensorflow==2.1\n",
    "\n",
    "Please ignore any incompatibility warnings and errors and re-run the cell to view the installed tensorflow version.\n",
    "\n",
    "\n",
    "Start by importing the necessary libraries for this lab.\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, DenseFeatures\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "print(tf.__version__)\n",
    "%matplotlib inline\n",
    "\n",
    "## Load raw data \n",
    "\n",
    "We will use the taxifare dataset, using the CSV files that we created in the first notebook of this sequence. Those files have been saved into `../data`.\n",
    "\n",
    "!ls -l ../data/*.csv\n",
    "\n",
    "!head ../data/taxi*.csv\n",
    "\n",
    "## Use tf.data to read the CSV files\n",
    "\n",
    "We wrote these functions for reading data from the csv files above in the [previous notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/labs/2_dataset_api.ipynb).\n",
    "\n",
    "CSV_COLUMNS = [\n",
    "    'fare_amount',\n",
    "    'pickup_datetime',\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'passenger_count',\n",
    "    'key'\n",
    "]\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], ['na'], [0.0], [0.0], [0.0], [0.0], [0.0], ['na']]\n",
    "UNWANTED_COLS = ['pickup_datetime', 'key']\n",
    "\n",
    "\n",
    "def features_and_labels(row_data):\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    features = row_data\n",
    "    \n",
    "    for unwanted_col in UNWANTED_COLS:\n",
    "        features.pop(unwanted_col)\n",
    "\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def create_dataset(pattern, batch_size=1, mode='eval'):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        pattern, batch_size, CSV_COLUMNS, DEFAULTS)\n",
    "\n",
    "    dataset = dataset.map(features_and_labels)\n",
    "\n",
    "    if mode == 'train':\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # take advantage of multi-threading; 1=AUTOTUNE\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "## Build a simple keras DNN model\n",
    "\n",
    "We will use feature columns to connect our raw data to our keras DNN model. Feature columns make it easy to perform common types of feature engineering on your raw data. For example, you can one-hot encode categorical data, create feature crosses, embeddings and more. We'll cover these in more detail later in the course, but if you want to a sneak peak browse the official TensorFlow [feature columns guide](https://www.tensorflow.org/guide/feature_columns).\n",
    "\n",
    "In our case we won't do any feature engineering. However, we still need to create a list of feature columns to specify the numeric values which will be passed on to our model. To do this, we use `tf.feature_column.numeric_column()`\n",
    "\n",
    "We use a python dictionary comprehension to create the feature columns for our model, which is just an elegant alternative to a for loop.\n",
    "\n",
    "INPUT_COLS = [\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'passenger_count',\n",
    "]\n",
    "\n",
    "# Create input layer of feature columns\n",
    "# TODO 1\n",
    "feature_columns = {\n",
    "    colname: tf.feature_column.numeric_column(colname)\n",
    "    for colname in INPUT_COLS\n",
    "    }\n",
    "\n",
    "Next, we create the DNN model. The Sequential model is a linear stack of layers and when building a model using the Sequential API, you configure each layer of the model in turn. Once all the layers have been added, you compile the model. \n",
    "\n",
    "# Build a keras DNN model using Sequential API\n",
    "# TODO 2a\n",
    "model = Sequential([\n",
    "    DenseFeatures(feature_columns=feature_columns.values()),\n",
    "    Dense(units=32, activation=\"relu\", name=\"h1\"),\n",
    "    Dense(units=8, activation=\"relu\", name=\"h2\"),\n",
    "    Dense(units=1, activation=\"linear\", name=\"output\")\n",
    "    ])\n",
    "\n",
    "Next, to prepare the model for training, you must configure the learning process. This is done using the compile method. The compile method takes three arguments:\n",
    "\n",
    "* An optimizer. This could be the string identifier of an existing optimizer (such as `rmsprop` or `adagrad`), or an instance of the [Optimizer class](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers).\n",
    "* A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function from the [Losses class](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses) (such as categorical_crossentropy or mse), or it can be a custom objective function.\n",
    "* A list of metrics. For any machine learning problem you will want a set of metrics to evaluate your model. A metric could be the string identifier of an existing metric or a custom metric function.\n",
    "\n",
    "We will add an additional custom metric called `rmse` to our list of metrics which will return the root mean square error. \n",
    "\n",
    "# TODO 2b\n",
    "# Create a custom evalution metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "# Compile the keras model\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])\n",
    "\n",
    "## Train the model\n",
    "\n",
    "To train your model, Keras provides three functions that can be used:\n",
    " 1. `.fit()` for training a model for a fixed number of epochs (iterations on a dataset).\n",
    " 2. `.fit_generator()` for training a model on data yielded batch-by-batch by a generator\n",
    " 3. `.train_on_batch()` runs a single gradient update on a single batch of data. \n",
    " \n",
    "The `.fit()` function works well for small datasets which can fit entirely in memory. However, for large datasets (or if you need to manipulate the training data on the fly via data augmentation, etc) you will need to use `.fit_generator()` instead. The `.train_on_batch()` method is for more fine-grained control over training and accepts only a single batch of data.\n",
    "\n",
    "The taxifare dataset we sampled is small enough to fit in memory, so can we could use `.fit` to train our model. Our `create_dataset` function above generates batches of training examples, so we could also use `.fit_generator`. In fact, when calling `.fit` the method inspects the data, and if it's a generator (as our dataset is) it will invoke automatically `.fit_generator` for training. \n",
    "\n",
    "We start by setting up some parameters for our training job and create the data generators for the training and validation data.\n",
    "\n",
    "We refer you the the blog post [ML Design Pattern #3: Virtual Epochs](https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730) for further details on why express the training in terms of `NUM_TRAIN_EXAMPLES` and `NUM_EVALS` and why, in this training code, the number of epochs is really equal to the number of evaluations we perform.\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1000\n",
    "NUM_TRAIN_EXAMPLES = 10000 * 5  # training dataset will repeat, wrap around\n",
    "NUM_EVALS = 50  # how many times to evaluate\n",
    "NUM_EVAL_EXAMPLES = 10000  # enough to get a reasonable sample\n",
    "\n",
    "trainds = create_dataset(\n",
    "    pattern='../data/taxi-train*',\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    mode='train')\n",
    "\n",
    "evalds = create_dataset(\n",
    "    pattern='../data/taxi-valid*',\n",
    "    batch_size=1000,\n",
    "    mode='eval').take(NUM_EVAL_EXAMPLES//1000)\n",
    "\n",
    "There are various arguments you can set when calling the [.fit method](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit). Here `x` specifies the input data which in our case is a `tf.data` dataset returning a tuple of (inputs, targets). The `steps_per_epoch` parameter is used to mark the end of training for a single epoch. Here we are training for NUM_EVALS epochs. Lastly, for the `callback` argument we specify a Tensorboard callback so we can inspect Tensorboard after training. \n",
    "\n",
    "%time \n",
    "# TODO 3\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (TRAIN_BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "LOGDIR = \"./taxi_trained\"\n",
    "history = model.fit(x=trainds,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=NUM_EVALS,\n",
    "                    validation_data=evalds,\n",
    "                    callbacks=[TensorBoard(LOGDIR)])\n",
    "\n",
    "### High-level model evaluation\n",
    "\n",
    "Once we've run data through the model, we can call `.summary()` on the model to get a high-level summary of our network. We can also plot the training and evaluation curves for the metrics we computed above. \n",
    "\n",
    "model.summary()\n",
    "\n",
    "Running `.fit` (or `.fit_generator`) returns a History object which collects all the events recorded during training. Similar to Tensorboard, we can plot the training and validation curves for the model loss and rmse by accessing these elements of the History object.\n",
    "\n",
    "RMSE_COLS = ['rmse', 'val_rmse']\n",
    "\n",
    "pd.DataFrame(history.history)[RMSE_COLS].plot()\n",
    "\n",
    "LOSS_COLS = ['loss', 'val_loss']\n",
    "\n",
    "pd.DataFrame(history.history)[LOSS_COLS].plot()\n",
    "\n",
    "# Making predictions with our model\n",
    "\n",
    "To make predictions with our trained model, we can call the [predict method](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict), passing to it a dictionary of values. The `steps` parameter determines the total number of steps before declaring the prediction round finished. Here since we have just one example, we set `steps=1` (setting `steps=None` would also work). Note, however, that if x is a `tf.data` dataset or a dataset iterator, and steps is set to None, predict will run until the input dataset is exhausted.\n",
    "\n",
    "model.predict(x={\"pickup_longitude\": tf.convert_to_tensor([-73.982683]),\n",
    "                 \"pickup_latitude\": tf.convert_to_tensor([40.742104]),\n",
    "                 \"dropoff_longitude\": tf.convert_to_tensor([-73.983766]),\n",
    "                 \"dropoff_latitude\": tf.convert_to_tensor([40.755174]),\n",
    "                 \"passenger_count\": tf.convert_to_tensor([3.0])},\n",
    "              steps=1)\n",
    "\n",
    "# Export and deploy our model\n",
    "\n",
    "Of course, making individual predictions is not realistic, because we can't expect client code to have a model object in memory. For others to use our trained model, we'll have to export our model to a file, and expect client code to instantiate the model from that exported file. \n",
    "\n",
    "We'll export the model to a TensorFlow SavedModel format. Once we have a model in this format, we have lots of ways to \"serve\" the model, from a web application, from JavaScript, from mobile applications, etc.\n",
    "\n",
    "# TODO 4a\n",
    "OUTPUT_DIR = \"./export/savedmodel\"\n",
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "EXPORT_PATH = os.path.join(OUTPUT_DIR,\n",
    "                           datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "tf.saved_model.save(model, EXPORT_PATH)  # with default serving function\n",
    "\n",
    "# TODO 4b\n",
    "!saved_model_cli show \\\n",
    " --tag_set serve \\\n",
    " --signature_def serving_default \\\n",
    " --dir {EXPORT_PATH}\n",
    "!find {EXPORT_PATH}\n",
    "os.environ['EXPORT_PATH'] = EXPORT_PATH\n",
    "\n",
    "### Deploy our model to AI Platform\n",
    "\n",
    "Finally, we will deploy our trained model to AI Platform and see how we can make online predicitons. \n",
    "\n",
    "%%bash\n",
    "\n",
    "# TODO 5a\n",
    "\n",
    "PROJECT= # TODO: Change this to your PROJECT\n",
    "BUCKET=${PROJECT}\n",
    "REGION=us-east1\n",
    "MODEL_NAME=taxifare\n",
    "VERSION_NAME=dnn\n",
    "\n",
    "## Create GCS bucket if it doesn't exist already...\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "\n",
    "if [ -n \"$exists\" ]; then\n",
    "    echo -e \"Bucket exists, let's not recreate it.\"\n",
    "else\n",
    "    echo \"Creating a new GCS bucket.\"\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "    echo \"\\nHere are your current buckets:\"\n",
    "    gsutil ls\n",
    "fi\n",
    "\n",
    "if [[ $(gcloud ai-platform models list --format='value(name)' | grep $MODEL_NAME) ]]; then\n",
    "    echo \"$MODEL_NAME already exists\"\n",
    "else\n",
    "    echo \"Creating $MODEL_NAME\"\n",
    "    gcloud ai-platform models create --regions=$REGION $MODEL_NAME\n",
    "fi\n",
    "\n",
    "if [[ $(gcloud ai-platform versions list --model $MODEL_NAME --format='value(name)' | grep $VERSION_NAME) ]]; then\n",
    "    echo \"Deleting already existing $MODEL_NAME:$VERSION_NAME ... \"\n",
    "    echo yes | gcloud ai-platform versions delete --model=$MODEL_NAME $VERSION_NAME\n",
    "    echo \"Please run this cell again if you don't see a Creating message ... \"\n",
    "    sleep 2\n",
    "fi\n",
    "\n",
    "echo \"Creating $MODEL_NAME:$VERSION_NAME\"\n",
    "gcloud ai-platform versions create --model=$MODEL_NAME $VERSION_NAME \\\n",
    "       --framework=tensorflow --python-version=3.7 --runtime-version=2.1 \\\n",
    "       --origin=$EXPORT_PATH --staging-bucket=gs://$BUCKET\n",
    "\n",
    "%%writefile input.json\n",
    "{\"pickup_longitude\": -73.982683, \"pickup_latitude\": 40.742104,\"dropoff_longitude\": -73.983766,\"dropoff_latitude\": 40.755174,\"passenger_count\": 3.0}  \n",
    "\n",
    "# TODO 5b\n",
    "!gcloud ai-platform predict --model taxifare --json-instances input.json --version dnn\n",
    "\n",
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "uYKgLLYjxz1f"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "BWwvGf0Yxz1f"
   },
   "source": [
    "## Introducing the Keras Functional API\n",
    "\n",
    "**Learning Objectives**\n",
    "  1. Understand embeddings and how to create them with the feature column API\n",
    "  1. Understand Deep and Wide models and when to use them\n",
    "  1. Understand the Keras functional API and how to build a deep and wide model with it\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the last notebook, we learned about the Keras Sequential API. The [Keras Functional API](https://www.tensorflow.org/guide/keras#functional_api) provides an alternate way of building models which is more flexible. With the Functional API, we can build models with more complex topologies, multiple input or output layers, shared layers or non-sequential data flows (e.g. residual layers).\n",
    "\n",
    "In this notebook we'll use what we learned about feature columns to build a Wide & Deep model. Recall, that the idea behind Wide & Deep models is to join the two methods of learning through memorization and generalization by making a wide linear model and a deep learning model to accommodate both. You can have a look at the original research paper here: [Wide & Deep Learning for Recommender Systems](https://arxiv.org/abs/1606.07792).\n",
    "\n",
    "<img src='assets/wide_deep.png' width='80%'>\n",
    "<sup>(image: https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)</sup>\n",
    "\n",
    "The Wide part of the model is associated with the memory element. In this case, we train a linear model with a wide set of crossed features and learn the correlation of this related data with the assigned label. The Deep part of the model is associated with the generalization element where we use embedding vectors for features. The best embeddings are then learned through the training process. While both of these methods can work well alone, Wide & Deep models excel by combining these techniques together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "2waYpWtxxz1f"
   },
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "wSE6vPjjxz1h"
   },
   "outputs": [],
   "source": [
    "# Ensure the right version of Tensorflow is installed.\n",
    "!pip freeze | grep tensorflow==2.1 || pip install tensorflow==2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "dOTlIwX_xz1k"
   },
   "source": [
    "Start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "bfcP7o_Cxz1k"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow import feature_column as fc\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, DenseFeatures, concatenate)\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "n2tzkqLnxz1l"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "ksObYEsLxz1m"
   },
   "source": [
    "### Load raw data \n",
    "\n",
    "We will use the taxifare dataset, using the CSV files that we created in the first notebook of this sequence. Those files have been saved into `../data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Lr7Xcs6uxz1n"
   },
   "outputs": [],
   "source": [
    "!ls -l ../data/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "sQnXTieaxz1o"
   },
   "source": [
    "### Use tf.data to read the CSV files\n",
    "\n",
    "We wrote these functions for reading data from the csv files above in the [previous notebook](2_dataset_api.ipynb). For this lab we will also include some additional engineered features in our model. In particular, we will compute the difference in latitude and longitude, as well as the Euclidean distance between the pick-up and drop-off locations. We can accomplish this by adding these new features to the features dictionary with the function `add_engineered_features` below. \n",
    "\n",
    "Note that we include a call to this function when collecting our features dict and labels in the `features_and_labels` function below as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "h4ATPYAFxz1o"
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = [\n",
    "    'fare_amount',\n",
    "    'pickup_datetime',\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'passenger_count',\n",
    "    'key'\n",
    "]\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], ['na'], [0.0], [0.0], [0.0], [0.0], [0.0], ['na']]\n",
    "UNWANTED_COLS = ['pickup_datetime', 'key']\n",
    "\n",
    "\n",
    "def features_and_labels(row_data):\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    features = row_data\n",
    "        \n",
    "    for unwanted_col in UNWANTED_COLS:\n",
    "        features.pop(unwanted_col)\n",
    "\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def create_dataset(pattern, batch_size=1, mode='eval'):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        pattern, batch_size, CSV_COLUMNS, DEFAULTS)\n",
    "\n",
    "    dataset = dataset.map(features_and_labels)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # take advantage of multi-threading; 1=AUTOTUNE\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "3VVPMgkuxz1p"
   },
   "source": [
    "### Feature columns for Wide and Deep model\n",
    "\n",
    "For the Wide columns, we will create feature columns of crossed features. To do this, we'll create a collection of Tensorflow feature columns to pass to the `tf.feature_column.crossed_column` constructor. The Deep columns will consist of numeric columns and the embedding columns we want to create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "tMyqqs4Vxz1p"
   },
   "outputs": [],
   "source": [
    "# TODO 1\n",
    "\n",
    "# 1. Bucketize latitudes and longitudes\n",
    "NBUCKETS = 16\n",
    "latbuckets = np.linspace(start=38.0, stop=42.0, num=NBUCKETS).tolist()\n",
    "lonbuckets = np.linspace(start=-76.0, stop=-72.0, num=NBUCKETS).tolist()\n",
    "\n",
    "fc_bucketized_plat = fc.bucketized_column(\n",
    "    source_column=fc.numeric_column(\"pickup_longitude\"), boundaries=lonbuckets)\n",
    "fc_bucketized_plon = fc.bucketized_column(\n",
    "    source_column=fc.numeric_column(\"pickup_latitude\"), boundaries=latbuckets)\n",
    "fc_bucketized_dlat = fc.bucketized_column(\n",
    "    source_column=fc.numeric_column(\"dropoff_longitude\"), boundaries=lonbuckets)\n",
    "fc_bucketized_dlon = fc.bucketized_column(\n",
    "    source_column=fc.numeric_column(\"dropoff_latitude\"), boundaries=latbuckets)\n",
    "\n",
    "# 2. Cross features for locations\n",
    "fc_crossed_dloc = fc.crossed_column(\n",
    "    [fc_bucketized_dlat, fc_bucketized_dlon],\n",
    "    hash_bucket_size=NBUCKETS * NBUCKETS)\n",
    "fc_crossed_ploc = fc.crossed_column(\n",
    "    [fc_bucketized_plat, fc_bucketized_plon],\n",
    "    hash_bucket_size=NBUCKETS * NBUCKETS)\n",
    "fc_crossed_pd_pair = fc.crossed_column(\n",
    "    [fc_crossed_dloc, fc_crossed_ploc],\n",
    "    hash_bucket_size=NBUCKETS**4)\n",
    "\n",
    "# 3. Create embedding columns for the crossed columns\n",
    "fc_pd_pair = fc.embedding_column(categorical_column=fc_crossed_pd_pair, dimension=3)\n",
    "fc_dloc = fc.embedding_column(categorical_column=fc_crossed_dloc, dimension=3)\n",
    "fc_ploc = fc.embedding_column(categorical_column=fc_crossed_ploc, dimension=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "vfue-UQaxz1q"
   },
   "source": [
    "### Gather list of feature columns\n",
    "\n",
    "Next we gather the list of wide and deep feature columns we'll pass to our Wide & Deep model in Tensorflow. Recall, wide columns are sparse, have linear relationship with the output while continuous columns are deep, have a complex relationship with the output. We will use our previously bucketized columns to collect crossed feature columns and sparse feature columns for our wide columns, and embedding feature columns and numeric features columns for the deep columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OlA1I8Nxxz1q"
   },
   "outputs": [],
   "source": [
    "# TODO 2\n",
    "wide_columns = [\n",
    "    # One-hot encoded feature crosses\n",
    "    fc.indicator_column(fc_crossed_dloc),\n",
    "    fc.indicator_column(fc_crossed_ploc),\n",
    "    fc.indicator_column(fc_crossed_pd_pair)\n",
    "]\n",
    "\n",
    "deep_columns = [\n",
    "    # Embedding_column to \"group\" together ...\n",
    "    fc.embedding_column(fc_crossed_pd_pair, dimension=10),\n",
    "\n",
    "    # Numeric columns\n",
    "    fc.numeric_column(\"pickup_latitude\"),\n",
    "    fc.numeric_column(\"pickup_longitude\"),\n",
    "    fc.numeric_column(\"dropoff_longitude\"),\n",
    "    fc.numeric_column(\"dropoff_latitude\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "rLWpCiKHxz1r"
   },
   "source": [
    "### Build a Wide and Deep model in Keras\n",
    "\n",
    "To build a wide-and-deep network, we connect the sparse (i.e. wide) features directly to the output node, but pass the dense (i.e. deep) features through a set of fully connected layers. Here’s that model architecture looks using the Functional API.\n",
    "\n",
    "First, we'll create our input columns using [tf.keras.layers.Input](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Ov5l-yyexz1r"
   },
   "outputs": [],
   "source": [
    "INPUT_COLS = [\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'passenger_count'\n",
    "]\n",
    "\n",
    "inputs = {colname : Input(name=colname, shape=(), dtype='float32')\n",
    "          for colname in INPUT_COLS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Z9OiAOEbxz1s"
   },
   "source": [
    "Then, we'll define our custom RMSE evaluation metric and build our wide and deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "FFdQo-E2xz1s"
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "# TODO 3\n",
    "def build_model(dnn_hidden_units):\n",
    "    # Create the deep part of model\n",
    "    deep = DenseFeatures(deep_columns, name='deep_inputs')(inputs)\n",
    "    for num_nodes in dnn_hidden_units:\n",
    "        deep = Dense(num_nodes, activation='relu')(deep) \n",
    "\n",
    "    # Create the wide part of model\n",
    "    wide = DenseFeatures(wide_columns, name='wide_inputs')(inputs)\n",
    "\n",
    "    # Combine deep and wide parts of the model\n",
    "    combined = concatenate(inputs=[deep, wide], name='combined')\n",
    "\n",
    "    # Map the combined outputs into a single prediction value\n",
    "    output = Dense(units=1, activation=None, name='prediction')(combined)\n",
    "    \n",
    "    # Finalize the model\n",
    "    model = Model(inputs=list(inputs.values()), outputs=output)\n",
    "\n",
    "    # Compile the keras model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "_1G6DFGkxz1t"
   },
   "source": [
    "Next, we can call the `build_model` to create the model. Here we'll have two hidden layers, each with 10 neurons, for the deep part of our model. We can also use `plot_model` to see a diagram of the model we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "pDx4GeNXxz1t"
   },
   "outputs": [],
   "source": [
    "HIDDEN_UNITS = [10,10]\n",
    "\n",
    "model = build_model(dnn_hidden_units=HIDDEN_UNITS)\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "dOrn5Dibxz1u"
   },
   "source": [
    "Next, we'll set up our training variables, create our datasets for training and validation, and train our model.\n",
    "\n",
    "(We refer you the the blog post [ML Design Pattern #3: Virtual Epochs](https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730) for further details on why express the training in terms of `NUM_TRAIN_EXAMPLES` and `NUM_EVALS` and why, in this training code, the number of epochs is really equal to the number of evaluations we perform.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Xi7aExJQxz1u"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "NUM_TRAIN_EXAMPLES = 10000 * 5  # training dataset will repeat, wrap around\n",
    "NUM_EVALS = 50  # how many times to evaluate\n",
    "NUM_EVAL_EXAMPLES = 10000  # enough to get a reasonable sample\n",
    "\n",
    "trainds = create_dataset(\n",
    "    pattern='../data/taxi-train*',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode='train')\n",
    "\n",
    "evalds = create_dataset(\n",
    "    pattern='../data/taxi-valid*',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode='eval').take(NUM_EVAL_EXAMPLES//1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "NZ9KklGwxz1v"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "OUTDIR = \"./taxi_trained\"\n",
    "shutil.rmtree(path=OUTDIR, ignore_errors=True) # start fresh each time\n",
    "\n",
    "history = model.fit(x=trainds,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=NUM_EVALS,\n",
    "                    validation_data=evalds,\n",
    "                    callbacks=[TensorBoard(OUTDIR)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "cJvJyid3xz1x"
   },
   "source": [
    "Just as before, we can examine the history to see how the RMSE changes through training on the train set and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "OsDNA-gPxz1x"
   },
   "outputs": [],
   "source": [
    "RMSE_COLS = ['rmse', 'val_rmse']\n",
    "\n",
    "pd.DataFrame(history.history)[RMSE_COLS].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "sEsFMpVOxz1y"
   },
   "source": [
    "Copyright 2019 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "arCkxOTexz1y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "cjg93IVUxz1z"
   },
   "source": [
    "# Gradient-Boosted-Trees (GBT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "n78kdHDpxz10"
   },
   "source": [
    "Boosting is introduced with the seminal paper of Schapire (1990), describing a method for ”converting a weak learning algorithm into one that achieves arbitrarily high accuracy” (Schapire, 1990, p. 197). This method is formalized in the algorithm ”AdaBoost” of Freund and Schapire (1997), originally applied to classification problems. Boosting works by sequentially applying weak learners to repeatedly re-weighted versions of the training data (Hastie et al., 2009). After each boosting iteration, misclassified examples have their weights increased, and correctly classified examples their weights decreased. Hence, each successive classifier focuses on examples that have been hard to classify in the previous steps. After a number of iterations $M_{GBT}$ , the predictions of the series of weak classifiers are combined by a weighted majority vote into a final prediction. Stochastic gradient boosting is a variation introduced by Friedman (2002), where we sample - without replacement - a subset of the training data upon each iteration to fit the base learner. We use a slightly different approach and select $m_{GBT}$ features at random from the p features upon every split. This subsampling procedure increases computational efficiency, generally improves performance, and decorrelates the trees. We use H2O’s implementation of AdaBoost, deploying shallow decision trees as weak learners. For further details, see Click et al. (2016). We have four parameters to set: The number of trees or boosting iterations $M_{GBT}$ , the depth of the tree $J_{GBT}$ , the learning rate $\\lambda_{GBT}$ , and the subset of features to use at each split, i.e., $m_{GBT}$ . Boosting may potentially overfit, if $M_{GBT}$ is too large, so we fix the number of iterations to 100 - a very conservative value compared to examples provided in the standard literature, as in Hastie et al. (2009). Boosting relies on weak learners, i.e., shallow trees, which generally result in the highest performance (Click et al., 2016). As stumps with only one split allow for no variable interaction effects, we settle for a value of $J_{GBT} = 3$, allowing for two-way interactions. Learning rate and number of trees are in an inverse relationship given constant error rates. Hastie et al. (2009) suggest learning rates smaller than 0.1. Taking into account the low number of trees, we settle for the upper end of the spectrum and fix $\\lambda_{GBT}$ at 0.1. For $m_{GBT}$ , we use 15, i.e., half of the available feature space - a share motivated by Friedman (2002). All other tuning parameters are at their default values and the seed is fixed to one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "_ARD1b-Dxz10"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "3-wv1UlFxz10"
   },
   "source": [
    "# Random Forests (RAF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Q4ogwy_9xz10"
   },
   "source": [
    "In the case of boosting, we successively fit shallow decision trees, each taking into account the classification error of the previous trees to build a strong ensemble of weak learners. In contrast, random forests consist of many deep but decorrelated trees built on different samples of the data. They have been introduced by Breiman (2001) and feature high popularity as they are simpler to deploy than boosting. The algorithm to grow a random forest is relatively simple. For each of the $B_{RAF}$ trees in the random forest, we first draw a random subset from the original training data. Then, we grow a modified decision tree to this sample, whereby we select $m_{RAF}$ features at random from the p features upon every split. We grow the tree to the maximum depth of $J_{RAF}$ . The final output is an ensemble of $B_{RAF}$ random forest trees, so that classification can be performed via majority vote. Subsampling sub- stantially reduces variance of (low bias) trees and the random feature selection decorrelates them. We have three tuning parameters, i.e., the number of trees $B_{RAF}$ , their maximum depth $J_{RAF}$ , and the number of features to randomly select $m_{RAF}$ . Random forests are not prone to overfit, so we can choose a high $B_{RAF}$ of 1000 trees. We fix the maximum depth $J_{RAF}$ at 20, a default value in machine learning allowing for substantial higher order inter- actions (H2O, 2016). Regarding the feature subsampling, we typically choose $m_{RAF}=\\lfloor\\sqrt{p}\\rfloor$ (James et al., 2014). Again, the seed is set to one and all further parameters at their default values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "uLzkw-35xz11"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "yvh0vDzhxz11"
   },
   "source": [
    "# Reinforcement Learning (RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "s9X0aBTLxz11"
   },
   "source": [
    "## Early Reinforcement Learning\n",
    "\n",
    "With the advances of modern computing power, the study of Reinforcement Learning is having a heyday. Machines are now able to learn complex tasks once thought to be solely in the domain of humans, from controlling the [heating and cooling in massive data centers](https://www.technologyreview.com/s/611902/google-just-gave-control-over-data-center-cooling-to-an-ai/) to beating [grandmasters at Starcraft](https://storage.googleapis.com/deepmind-media/research/alphastar/AlphaStar_unformatted.pdf). As magnificent as it may seem today, it had humble roots many decades ago. Seeing how far it's come, it's a wonder to see how far it will go!\n",
    "\n",
    "Let's take a step back in time to see how these early algorithms developed. Many of these algorithms make sense given the context of when they were created. Challenge yourself and see if you can come up with the same strategies given the right problem. Ok! Time to cozy up for a story.\n",
    "\n",
    "<img src=\"images/hero.jpg\" width=\"488\" height=\"172\">\n",
    "\n",
    "This is the hero of our story, the gumdrop emoji. It was enjoying a cool winter day building a snowman when suddenly, it slipped and fell on a frozen lake of death.\n",
    "\n",
    "\n",
    "<img src=\"images/lake.jpg\" width=\"900\" height=\"680\">\n",
    "\n",
    "The lake can be thought of as a 4 x 4 grid where the gumdrop can move left (0), down (1), right (2) and up (3). Unfortunately, this frozen lake of death has holes of death where if the gumdrop enters that square, it will fall in and meet an untimely demise. To make matters worse, the lake is surrounded by icy boulders that if the gumdrop attempts to climb, will have it slip back into its original position. Thankfully, at the bottom right of the lake is a safe ramp that leads to a nice warm cup of hot cocoa.\n",
    "\n",
    "## Set Up\n",
    "\n",
    "We can try and save the gumdrop ourselves! This is a common game people begin their Reinforcement Learning journey with, and is included in the OpenAI's python package [Gym](https://gym.openai.com/) and is aptly named [FrozenLake-v0](https://gym.openai.com/envs/FrozenLake-v0/) ([code](https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py)). No time to waste, let's get the environment up and running. Run the below to install the needed libraries if they are not installed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "_45q3lkBxz11"
   },
   "outputs": [],
   "source": [
    "# Ensure the right version of Tensorflow is installed.\n",
    "!pip install tensorflow==2.1 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "XqZP23kjxz12"
   },
   "source": [
    "**NOTE**: In the output of the above cell you may ignore any WARNINGS or ERRORS related to the following:  \"witwidget\", \"pyarrow\", \"tensorflow-model-analysis\", \"tensorflow-data-validation\" etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "j0blqOeGxz12"
   },
   "source": [
    "If you get any related errors mentioned above please rerun the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "cq8LUylwxz13"
   },
   "outputs": [],
   "source": [
    "!pip install gym==0.12.5 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "xOZqph18xz14"
   },
   "source": [
    "There are [four methods from Gym](http://gym.openai.com/docs/) that are going to be useful to us in order to save the gumdrop.\n",
    "* `make` allows us to build the environment or game that we can pass actions to\n",
    "* `reset` will reset an environment to it's starting configuration and return the state of the player\n",
    "* `render` displays the environment for human eyes\n",
    "* `step` takes an action and returns the player's next state.\n",
    "\n",
    "Let's make, reset, and render the game. The output is an ANSI string with the following characters:\n",
    "* `S` for starting point\n",
    "* `F` for frozen\n",
    "* `H` for hole\n",
    "* `G` for goal\n",
    "* A red square indicates the current position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "SLGzpNg0xz14"
   },
   "source": [
    "**Note**: Restart the kernel if the above libraries needed to be installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "2zxuOxkTxz14"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "env = gym.make('FrozenLake-v0', is_slippery=False)\n",
    "state = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ww5_Qnf3xz15"
   },
   "source": [
    "If we print the state we'll get `0`. This is telling us which square we're in. Each square is labeled from `0` to `15` from left to right, top to bottom, like this:\n",
    "\n",
    "| | | | |\n",
    "|-|-|-|-|\n",
    "|0|1|2|3|\n",
    "|4|5|6|7|\n",
    "|8|9|10|11|\n",
    "|12|13|14|15|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ccWYaSF7xz15"
   },
   "outputs": [],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Kp9h6aHCxz17"
   },
   "source": [
    "We can make a simple print function to let us know whether it's game won, game over, or game on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "pdhDapYuxz17"
   },
   "outputs": [],
   "source": [
    "def print_state(state, done):\n",
    "    statement = \"Still Alive!\"\n",
    "    if done:\n",
    "        statement = \"Cocoa Time!\" if state == 15 else \"Game Over!\" \n",
    "    print(state, \"-\", statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "1wx-T3gRxz18"
   },
   "source": [
    "We can control the gumdrop ourselves with the `step` method. Run the below cell over and over again trying to move from the starting position to the goal. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "75PGFC5rxz18"
   },
   "outputs": [],
   "source": [
    "#0 left\n",
    "#1 down\n",
    "#2 right\n",
    "#3 up\n",
    "\n",
    "# Uncomment to reset the game\n",
    "#env.reset()\n",
    "action = 2  # Change me, please!\n",
    "state, _, done, _ = env.step(action)\n",
    "env.render()\n",
    "print_state(state, done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "1uNH4Wo1xz19"
   },
   "source": [
    "Were you able to reach the hot chocolate? If so, great job! There are multiple paths through the maze. One solution is `[1, 1, 2, 2, 1, 2]`. Let's loop through our actions in order to get used to interacting with the environment programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "BpQGOJRvxz19"
   },
   "outputs": [],
   "source": [
    "def play_game(actions):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    while not done and step < len(actions):\n",
    "        action = actions[step]\n",
    "        state, _, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        step += 1\n",
    "        print_state(state, done)\n",
    "        \n",
    "actions = [1, 1, 2, 2, 1, 2]  # Replace with your favorite path.\n",
    "play_game(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ELwzKGgbxz2E"
   },
   "source": [
    "Nice, so we know how to get through the maze, but how do we teach that to the gumdrop? It's just some bytes in an android phone. It doesn't have our human insight.\n",
    "\n",
    "We could give it our list of actions directly, but then it would be copying us and not really learning. This was a tricky one to the mathematicians and computer scientists originally trying to solve this problem. How do we teach a machine to do this without human insight?\n",
    "\n",
    "## Value Iteration\n",
    "\n",
    "Let's turn the clock back on our time machines to 1957 to meet Mr. [Richard Bellman](https://en.wikipedia.org/wiki/Richard_E._Bellman). Bellman started his academic career in mathematics, but due to World War II, left his postgraduate studies at John Hopkins to teach electronics as part of the war effort (as chronicled by J. J. O'Connor and E. F. Robertson [here](https://www-history.mcs.st-andrews.ac.uk/Biographies/Bellman.html)). When the war was over, and it came time for him to focus on his next area of research, he became fascinated with [Dynamic Programming](https://en.wikipedia.org/wiki/Dynamic_programming): the idea of breaking a problem down into sub-problems and using recursion to solve the larger problem.\n",
    "\n",
    "Eventually, his research landed him on [Markov Decision Processes](https://en.wikipedia.org/wiki/Markov_decision_process). These processes are a graphical way of representing how to make a decision based on a current state. States are connected to other states with positive and negative rewards that can be picked up along the way.\n",
    "\n",
    "Sound familiar at all? Perhaps our Frozen Lake?\n",
    "\n",
    "In the lake case, each cell is a state. The `H`s and the `G` are a special type of state called a \"Terminal State\", meaning they can be entered, but they have no leaving connections. What of rewards? Let's say the value of losing our life is the negative opposite of getting to the goal and staying alive. Thus, we can assign the reward of entering a death hole as -1, and the reward of escaping as +1.\n",
    "\n",
    "Bellman's first breakthrough with this type of problem is now known as Value Iteration ([his original paper](http://www.iumj.indiana.edu/IUMJ/FULLTEXT/1957/6/56038)). He introduced a variable, gamma (γ), to represent discounted future rewards. He also introduced a function of policy (π) that takes a state (s), and outputs corresponding suggested action (a). The goal is to find the value of a state (V), given the rewards that occur when following an action in a particular state (R).\n",
    "\n",
    "Gamma, the discount, is the key ingredient here. If my time steps were in days, and my gamma was .9, `$100` would be worth `$100` to me today, `$90` tomorrow, `$81` the day after, and so on. Putting this all together, we get the Bellman Equation\n",
    "\n",
    "<img src=\"images/bellman_equation.jpg\" width=\"500\">\n",
    "\n",
    "source: [Wikipedia](https://en.wikipedia.org/wiki/Bellman_equation)\n",
    "\n",
    "In other words, the value of our current state, `current_values`, is equal to the discount times the value of the next state, `next_values`, given the policy the agent will follow. For now, we'll have our agent assume a greedy policy: it will move towards the state with the highest calculated value. If you're wondering what P is, don't worry, we'll get to that later.\n",
    "\n",
    "Let's program it out and see it in action! We'll set up an array representing the lake with -1 as the holes, and 1 as the goal. Then, we'll set up an array of zeros to start our iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "jWSImgULxz2F"
   },
   "outputs": [],
   "source": [
    "LAKE = np.array([[0,  0,  0,  0],\n",
    "                 [0, -1,  0, -1],\n",
    "                 [0,  0,  0, -1],\n",
    "                 [-1, 0,  0,  1]])\n",
    "LAKE_WIDTH = len(LAKE[0])\n",
    "LAKE_HEIGHT = len(LAKE)\n",
    "\n",
    "DISCOUNT = .9  # Change me to be a value between 0 and 1.\n",
    "current_values = np.zeros_like(LAKE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "coA5RD7oxz2G"
   },
   "source": [
    "The Gym environment class has a handy property for finding the number of states in an environment called `observation_space`. In our case, there a 16 integer states, so it will label it as \"Discrete\". Similarly, `action_space` will tell us how many actions are available to the agent.\n",
    "\n",
    "Let's take advantage of these to make our code portable between different lakes sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "HOwV_khcxz2G"
   },
   "outputs": [],
   "source": [
    "print(\"env.observation_space -\", env.observation_space)\n",
    "print(\"env.observation_space.n -\", env.observation_space.n)\n",
    "print(\"env.action_space -\", env.action_space)\n",
    "print(\"env.action_space.n -\", env.action_space.n)\n",
    "\n",
    "STATE_SPACE = env.observation_space.n\n",
    "ACTION_SPACE = env.action_space.n\n",
    "STATE_RANGE = range(STATE_SPACE)\n",
    "ACTION_RANGE = range(ACTION_SPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "IFCCky8bxz2H"
   },
   "source": [
    "We'll need some sort of function to figure out what the best neighboring cell is. The below function take's a cell of the lake, and looks at the current value mapping (to be called with `current_values`, and see's what the value of the adjacent state is corresponding to the given `action`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Gmtub6UWxz2H"
   },
   "outputs": [],
   "source": [
    "def get_neighbor_value(state_x, state_y, values, action):\n",
    "    \"\"\"Returns the value of a state's neighbor.\n",
    "    \n",
    "    Args:\n",
    "        state_x (int): The state's horizontal position, 0 is the lake's left.\n",
    "        state_y (int): The state's vertical position, 0 is the lake's top.\n",
    "        values (float array): The current iteration's state values.\n",
    "        policy (int): Which action to check the value for.\n",
    "        \n",
    "    Returns:\n",
    "        The corresponding action's value.\n",
    "    \"\"\"\n",
    "    left = [state_y, state_x-1]\n",
    "    down = [state_y+1, state_x]\n",
    "    right = [state_y, state_x+1]\n",
    "    up = [state_y-1, state_x]\n",
    "    actions = [left, down, right, up]\n",
    "\n",
    "    direction = actions[action]\n",
    "    check_x = direction[1]\n",
    "    check_y = direction[0]\n",
    "        \n",
    "    is_boulder = check_y < 0 or check_y >= LAKE_HEIGHT \\\n",
    "        or check_x < 0 or check_x >= LAKE_WIDTH\n",
    "    \n",
    "    value = values[state_y, state_x]\n",
    "    if not is_boulder:\n",
    "        value = values[check_y, check_x]\n",
    "        \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "pLM2Qeeixz2I"
   },
   "source": [
    "But this doesn't find the best action, and the gumdrop is going to need that if it wants to greedily get off the lake. The `get_max_neighbor` function we've defined below takes a number corresponding to a cell as `state_number` and the same value mapping as `get_neighbor_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "5P7kq_Cxxz2I"
   },
   "outputs": [],
   "source": [
    "def get_state_coordinates(state_number):\n",
    "    state_x = state_number % LAKE_WIDTH\n",
    "    state_y = state_number // LAKE_HEIGHT\n",
    "    return state_x, state_y\n",
    "\n",
    "def get_max_neighbor(state_number, values):\n",
    "    \"\"\"Finds the maximum valued neighbor for a given state.\n",
    "    \n",
    "    Args:\n",
    "        state_number (int): the state to find the max neighbor for\n",
    "        state_values (float array): the respective value of each state for\n",
    "            each cell of the lake.\n",
    "    \n",
    "    Returns:\n",
    "        max_value (float): the value of the maximum neighbor.\n",
    "        policy (int): the action to take to move towards the maximum neighbor.\n",
    "    \"\"\"\n",
    "    state_x, state_y = get_state_coordinates(state_number)\n",
    "    \n",
    "    # No policy or best value yet\n",
    "    best_policy = -1\n",
    "    max_value = -np.inf\n",
    "\n",
    "    # If the cell has something other than 0, it's a terminal state.\n",
    "    if LAKE[state_y, state_x]:\n",
    "        return LAKE[state_y, state_x], best_policy\n",
    "    \n",
    "    for action in ACTION_RANGE:\n",
    "        neighbor_value = get_neighbor_value(state_x, state_y, values, action)\n",
    "        if neighbor_value > max_value:\n",
    "            max_value = neighbor_value\n",
    "            best_policy = action\n",
    "        \n",
    "    return max_value, best_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "7EsggZGSxz2J"
   },
   "source": [
    "Now, let's write our value iteration code. We'll write a function that comes out one step of the iteration by checking each state and finding its maximum neighbor. The values will be reshaped so that it's in the form of the lake, but the policy will stay as a list of ints. This way, when Gym returns a state, all we need to do is look at the corresponding index in the policy list to tell our agent where to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "xaf9Kjp9xz2J"
   },
   "outputs": [],
   "source": [
    "def iterate_value(current_values):\n",
    "    \"\"\"Finds the future state values for an array of current states.\n",
    "    \n",
    "    Args:\n",
    "        current_values (int array): the value of current states.\n",
    "\n",
    "    Returns:\n",
    "        next_values (int array): The value of states based on future states.\n",
    "        next_policies (int array): The recommended action to take in a state.\n",
    "    \"\"\"\n",
    "    next_values = []\n",
    "    next_policies = []\n",
    "\n",
    "    for state in STATE_RANGE:\n",
    "        value, policy = get_max_neighbor(state, current_values)\n",
    "        next_values.append(value)\n",
    "        next_policies.append(policy)\n",
    "    \n",
    "    next_values = np.array(next_values).reshape((LAKE_HEIGHT, LAKE_WIDTH))\n",
    "    return next_values, next_policies\n",
    "\n",
    "next_values, next_policies = iterate_value(current_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "6LC_FzNYxz2J"
   },
   "source": [
    "This is what our values look like after one step. Right now, it just looks like the lake. That's because we started with an array of zeros for `current_values`, and the terminal states of the lake were loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "hxRdZMR3xz2K"
   },
   "outputs": [],
   "source": [
    "next_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "NJ3sVQf-xz2L"
   },
   "source": [
    "And this is what our policy looks like reshaped into the form of the lake. The `-1`'s are terminal states. Right now, the agent will move left in any non-terminal state, because it sees all of those states as equal. Remember, if the gumdrop is along the leftmost side of the lake, and tries to move left, it will slip on a boulder and return to the same position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "fAHbDoHDxz2L"
   },
   "outputs": [],
   "source": [
    "np.array(next_policies).reshape((LAKE_HEIGHT ,LAKE_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Vmj3wXcnxz2T"
   },
   "source": [
    "There's one last step to apply the Bellman Equation, the `discount`! We'll multiply our next states by the `discount` and set that to our `current_values`. One loop done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "QK3w2yFUxz2T"
   },
   "outputs": [],
   "source": [
    "current_values = DISCOUNT * next_values\n",
    "current_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "j_VyzDEQxz2U"
   },
   "source": [
    "Run the below cell over and over again to see how our values change with each iteration. It should be complete after six iterations when the values no longer change. The policy will also change as the values are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XuqIUTakxz2U"
   },
   "outputs": [],
   "source": [
    "next_values, next_policies = iterate_value(current_values)\n",
    "print(\"Value\")\n",
    "print(next_values)\n",
    "print(\"Policy\")\n",
    "print(np.array(next_policies).reshape((4,4)))\n",
    "current_values = DISCOUNT * next_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "1IfmEBGcxz2k"
   },
   "source": [
    "Have a completed policy? Let's see it in action! We'll update our `play_game` function to instead take our list of policies. That way, we can start in a random position and still get to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Z2B5f56Uxz2k"
   },
   "outputs": [],
   "source": [
    "def play_game(policy):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = policy[state]  # This line is new.\n",
    "        state, _, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        step += 1\n",
    "        print_state(state, done)\n",
    "\n",
    "play_game(next_policies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "qATPQY4xxz2l"
   },
   "source": [
    "Phew! Good job, team! The gumdrop made it out alive. So what became of our gumdrop hero? Well, the next day, it was making another snowman and fell onto an even more slippery and deadly lake. Doh! Turns out this story is part of a trilogy. Feel free to move onto the next section after your own sip of cocoa, coffee, tea, or poison of choice.\n",
    "\n",
    "## Policy Iteration\n",
    "\n",
    "You may have noticed that the first lake was built with the parameter `is_slippery=False`. This time, we're going to switch it to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "EwGobK_Fxz2l"
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0', is_slippery=True)\n",
    "state = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "VY_9SRv4xz2o"
   },
   "source": [
    "Hmm, looks the same as before. Let's try applying our old policy and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "DPLaJNsTxz2o"
   },
   "outputs": [],
   "source": [
    "play_game(next_policies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "LJH7imLDxz2p"
   },
   "source": [
    "Was there a game over? There's a small chance that the gumdrop made it to the end, but it's much more likely that it accidentally slipped and fell into a hole. Oh no! We can try repeatedly testing the above code cell over and over again, but it might take a while. In fact, this is a similar roadblock Bellman and his colleagues faced.\n",
    "\n",
    "How efficient is Value Iteration? On our modern machines, this algorithm ran fairly quickly, but back in 1960, that wasn't the case. Let's say our lake is a long straight line like this:\n",
    "\n",
    "| | | | | | | |\n",
    "|-|-|-|-|-|-|-|\n",
    "|S|F|F|F|F|F|H|\n",
    "\n",
    "This is the worst case scenario for value iteration. In each iteration, we look at every state (s) and each action per state (a), so one step of value iteration is O(s*a). In the case of our lake line, each iteration only updates one cell. In other words, the value iteration step needs to be run `s` times. In total, that's O(s<sup>2</sup>a).\n",
    "\n",
    "Back in 1960, that was computationally heavy, and so [Ronald Howard](https://en.wikipedia.org/wiki/Ronald_A._Howard) developed an alteration of Value Iteration that mildly sacrificed mathematical accuracy for speed.\n",
    "\n",
    "Here's the strategy: it was observed that the optimal policy often converged before value iteration was complete. To take advantage of this, we'll start with random policy. When we iterate over our values, we'll use this policy instead of trying to find the maximum neighbor. This has been coded out in `find_future_values` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "AguzfRRkxz2p"
   },
   "outputs": [],
   "source": [
    "def find_future_values(current_values, current_policies):\n",
    "    \"\"\"Finds the next set of future values based on the current policy.\"\"\"\n",
    "    next_values = []\n",
    "\n",
    "    for state in STATE_RANGE:\n",
    "        current_policy = current_policies[state]\n",
    "        state_x, state_y = get_state_coordinates(state)\n",
    "\n",
    "        # If the cell has something other than 0, it's a terminal state.\n",
    "        value = LAKE[state_y, state_x]\n",
    "        if not value:\n",
    "            value = get_neighbor_value(\n",
    "                state_x, state_y, current_values, current_policy)\n",
    "        next_values.append(value)\n",
    "\n",
    "    return np.array(next_values).reshape((LAKE_HEIGHT, LAKE_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "BGQNK8vpxz2q"
   },
   "source": [
    "After we've calculated our new values, then we'll update the policy (and not the values) based on the maximum neighbor. If there's no change in the policy, then we're done. The below is very similar to our `get_max_neighbor` function. Can you see the differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "b0obay9nxz2q"
   },
   "outputs": [],
   "source": [
    "def find_best_policy(next_values):\n",
    "    \"\"\"Finds the best policy given a value mapping.\"\"\"\n",
    "    next_policies = []\n",
    "    for state in STATE_RANGE:\n",
    "        state_x, state_y = get_state_coordinates(state)\n",
    "\n",
    "        # No policy or best value yet\n",
    "        max_value = -np.inf\n",
    "        best_policy = -1\n",
    "\n",
    "        if not LAKE[state_y, state_x]:\n",
    "            for policy in ACTION_RANGE:\n",
    "                neighbor_value = get_neighbor_value(\n",
    "                    state_x, state_y, next_values, policy)\n",
    "                if neighbor_value > max_value:\n",
    "                    max_value = neighbor_value\n",
    "                    best_policy = policy\n",
    "                \n",
    "        next_policies.append(best_policy)\n",
    "    return next_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "p2ZysYTKxz2s"
   },
   "source": [
    "To complete the Policy Iteration algorithm, we'll combine the two functions above. Conceptually, we'll be alternating between updating our value function and updating our policy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "6Hy9ldM4xz2s"
   },
   "outputs": [],
   "source": [
    "def iterate_policy(current_values, current_policies):\n",
    "    \"\"\"Finds the future state values for an array of current states.\n",
    "    \n",
    "    Args:\n",
    "        current_values (int array): the value of current states.\n",
    "        current_policies (int array): a list where each cell is the recommended\n",
    "            action for the state matching its index.\n",
    "\n",
    "    Returns:\n",
    "        next_values (int array): The value of states based on future states.\n",
    "        next_policies (int array): The recommended action to take in a state.\n",
    "    \"\"\"\n",
    "    next_values = find_future_values(current_values, current_policies)\n",
    "    next_policies = find_best_policy(next_values)\n",
    "    return next_values, next_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "5wnrSSScxz2t"
   },
   "source": [
    "Next, let's modify the `get_neighbor_value` function to now include the slippery ice. Remember the `P` in the Bellman Equation above? It stands for the probability of ending up in a new state given the current state and action taken. That is, we'll take a weighted sum of the values of all possible states based on our chances to be in those states.\n",
    "\n",
    "How does the physics of the slippery ice work? For this lake, whenever the gumdrop tries to move in a particular direction, there are three possible positions that it could end up with. It could move where it was intending to go, but it could also end up to the left or right of the direction it was facing. For instance, if it wanted to move right, it could end up on the square above or below it! This is depicted below, with the yellow squares being potential positions after attempting to move right.\n",
    "\n",
    "<img src=\"images/slipping.jpg\" width=\"360\" height=\"270\">\n",
    "\n",
    "Each of these has an equal probability chance of happening. So since there are three outcomes, they each have about a 33% chance to happen. What happens if we slip in the direction of a boulder? No problem, we'll just end up not moving anywhere. Let's make a function to find what our possible locations could be given a policy and state coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Jo8m3-CWxz2u"
   },
   "outputs": [],
   "source": [
    "def get_locations(state_x, state_y, policy):\n",
    "    left = [state_y, state_x-1]\n",
    "    down = [state_y+1, state_x]\n",
    "    right = [state_y, state_x+1]\n",
    "    up = [state_y-1, state_x]\n",
    "    directions = [left, down, right, up]\n",
    "    num_actions = len(directions)\n",
    "\n",
    "    gumdrop_right = (policy - 1) % num_actions\n",
    "    gumdrop_left = (policy + 1) % num_actions\n",
    "    locations = [gumdrop_left, policy, gumdrop_right]\n",
    "    return [directions[location] for location in locations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "9Lrn-fhgxz2w"
   },
   "source": [
    "Then, we can add it to `get_neighbor_value` to find the weighted value of all the possible states the gumdrop can end up in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "abhct-GDxz2w"
   },
   "outputs": [],
   "source": [
    "def get_neighbor_value(state_x, state_y, values, policy):\n",
    "    \"\"\"Returns the value of a state's neighbor.\n",
    "    \n",
    "    Args:\n",
    "        state_x (int): The state's horizontal position, 0 is the lake's left.\n",
    "        state_y (int): The state's vertical position, 0 is the lake's top.\n",
    "        values (float array): The current iteration's state values.\n",
    "        policy (int): Which action to check the value for.\n",
    "        \n",
    "    Returns:\n",
    "        The corresponding action's value.\n",
    "    \"\"\"\n",
    "    locations = get_locations(state_x, state_y, policy)\n",
    "    location_chance = 1.0 / len(locations)\n",
    "    total_value = 0\n",
    "\n",
    "    for location in locations:\n",
    "        check_x = location[1]\n",
    "        check_y = location[0]\n",
    "\n",
    "        is_boulder = check_y < 0 or check_y >= LAKE_HEIGHT \\\n",
    "            or check_x < 0 or check_x >= LAKE_WIDTH\n",
    "    \n",
    "        value = values[state_y, state_x]\n",
    "        if not is_boulder:\n",
    "            value = values[check_y, check_x]\n",
    "        total_value += location_chance * value\n",
    "\n",
    "    return total_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "PLYKmNBkxz2z"
   },
   "source": [
    "For Policy Iteration, we'll start off with a random policy if only because the Gumdrop doesn't know any better yet. We'll reset our current values while we're at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "V4BNAPlOxz2z"
   },
   "outputs": [],
   "source": [
    "current_values = np.zeros_like(LAKE)\n",
    "policies = np.random.choice(ACTION_RANGE, size=STATE_SPACE)\n",
    "np.array(policies).reshape((4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "4nr-8ktbxz21"
   },
   "source": [
    "As before with Value Iteration, run the cell below multiple until the policy no longer changes. It should only take 2-3 clicks compared to Value Iteration's 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "fKEjZtiIxz21"
   },
   "outputs": [],
   "source": [
    "next_values, policies = iterate_policy(current_values, policies)\n",
    "print(\"Value\")\n",
    "print(next_values)\n",
    "print(\"Policy\")\n",
    "print(np.array(policies).reshape((4,4)))\n",
    "current_values = DISCOUNT * next_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Rs5zUUEMxz22"
   },
   "source": [
    "Hmm, does this work? Let's see! Run the cell below to watch the gumdrop slip its way to victory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "yxZOlJNCxz22"
   },
   "outputs": [],
   "source": [
    "play_game(policies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "RQs7w8ZMxz23"
   },
   "source": [
    "So what was the learned strategy here? The gumdrop learned to hug the left wall of boulders until it was down far enough to make a break for the exit. Instead of heading directly for it though, it took advantage of actions that did not have a hole of death in them. Patience is a virtue!\n",
    "\n",
    "We promised this story was a trilogy, and yes, the next day, the gumdrop fell upon a frozen lake yet again.\n",
    "\n",
    "## Q Learning\n",
    "Value Iteration and Policy Iteration are great techniques, but what if we don't know how big the lake is? With real world problems, not knowing how many potential states are can be a definite possibility.\n",
    "\n",
    "Enter [Chris Watkins](http://www.cs.rhul.ac.uk/~chrisw/). Inspired by how animals learn with delayed rewards, he came up with the idea of [Q Learning](http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf) as an evolution of [Richard Sutton's](https://en.wikipedia.org/wiki/Richard_S._Sutton) [Temporal Difference Learning](https://en.wikipedia.org/wiki/Temporal_difference_learning). Watkins noticed that animals learn from positive and negative rewards, and that they often make mistakes in order to optimize a skill.\n",
    "\n",
    "From this emerged the idea of a Q table. In the lake case, it would look something like this.\n",
    "\n",
    "| |Left|Down|Right|Up|\n",
    "|-|-|-|-|-|\n",
    "|0| | | | |\n",
    "|1| | | | |\n",
    "|...| | | | |\n",
    "\n",
    "Here's the strategy: our agent will explore the environment. As the agent observes new states, we'll add more rows to our table. Whenever it moves from one state to the next, we'll update the cell corresponding to the old state based on the Bellman Equation. The agent doesn't need to know what the probabilities are between transitions. It'll learn the value of these as it experiments.\n",
    "\n",
    "For Q learning, this works by looking at the row that corresponds to the agent's current state. Then, we'll select the action with the highest value. There are multiple ways to initialize the Q-table, but for us, we'll start with all zeros. In that case, when selecting the best action, we'll randomly select between tied max values. If we don't, the agent will favor certain actions which will limit its exploration.\n",
    "\n",
    "To be able to handle an unknown number of states, we'll initialize our q_table as one row to represent our initial state. Then, we'll make a dictionary to map new states to rows in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Xy-_fvv5xz23"
   },
   "outputs": [],
   "source": [
    "new_row = np.zeros((1, env.action_space.n))\n",
    "q_table = np.copy(new_row)\n",
    "q_map = {0: 0}\n",
    "\n",
    "def print_q(q_table, q_map):\n",
    "    print(\"mapping\")\n",
    "    print(q_map)\n",
    "    print(\"q_table\")\n",
    "    print(q_table)\n",
    "\n",
    "print_q(q_table, q_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Pso68OsLxz24"
   },
   "source": [
    "Our new `get_action` function will help us read the `q_table` and find the best action.\n",
    "\n",
    "First, we'll give the agent the ability to act randomly as opposed to choosing the best known action. This gives it the ability to explore and find new situations. This is done with a random chance to act randomly. So random!\n",
    "\n",
    "When the Gumdrop chooses not to act randomly, it will instead act based on the best action recorded in the `q_table`. Numpy's [argwhere](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html) is used to find the indexes with the maximum value in the q-table row corresponding to our current state. Since numpy is often used with higher dimensional data, each index is returned as a list of ints. Our indexes are really one dimensional since we're just looking within a single row, so we'll use [np.squeeze](https://docs.scipy.org/doc/numpy/reference/generated/numpy.squeeze.html) to remove the extra brackets. To randomly select from the indexes, we'll use [np.random.choice](https://docs.scipy.org/doc/numpy-1.14.1/reference/generated/numpy.random.choice.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "IE_bbwHHxz24"
   },
   "outputs": [],
   "source": [
    "def get_action(q_map, q_table, state_row, random_rate):\n",
    "    \"\"\"Find max-valued actions and randomly select from them.\"\"\"\n",
    "    if random.random() < random_rate:\n",
    "        return random.randint(0, ACTION_SPACE-1)\n",
    "\n",
    "    action_values = q_table[state_row]\n",
    "    max_indexes = np.argwhere(action_values == action_values.max())\n",
    "    max_indexes = np.squeeze(max_indexes, axis=-1)\n",
    "    action = np.random.choice(max_indexes)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "MOvuV9TAxz25"
   },
   "source": [
    "Here, we'll define how the `q_table` gets updated. We'll apply the Bellman Equation as before, but since there is so much luck involved between slipping and random actions, we'll update our `q_table` as a weighted average between the `old_value` we're updating and the `future_value` based on the best action in the next state. That way, there's a little bit of memory between old and new experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "TjrS4Zvuxz25"
   },
   "outputs": [],
   "source": [
    "def update_q(q_table, new_state_row, reward, old_value):\n",
    "    \"\"\"Returns an updated Q-value based on the Bellman Equation.\"\"\"\n",
    "    learning_rate = .1  # Change to be between 0 and 1.\n",
    "    future_value = reward + DISCOUNT * np.max(q_table[new_state_row])\n",
    "    return old_value + learning_rate * (future_value - old_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "qiIp40n-xz26"
   },
   "source": [
    "We'll update our `play_game` function to take our table and mapping, and at the end, we'll return any updates to them. Once we observe new states, we'll check our mapping and add then to the table if space isn't allocated for them already.\n",
    "\n",
    "Finally, for every `state` - `action` - `new-state` transition, we'll update the cell in `q_table` that corresponds to the `state` and `action` with the Bellman Equation.\n",
    "\n",
    "There's a little secret to solving this lake problem, and that's to have a small negative reward when moving between states. Otherwise, the gumdrop will become too afraid of slipping in a death hole to explore out of what is thought to be safe positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "wNHpycwDxz26"
   },
   "outputs": [],
   "source": [
    "def play_game(q_table, q_map, random_rate, render=False):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        state_row = q_map[state]\n",
    "        action = get_action(q_map, q_table, state_row, random_rate)\n",
    "        new_state, _, done, _ = env.step(action)\n",
    "\n",
    "        #Add new state to table and mapping if it isn't there already.\n",
    "        if new_state not in q_map:\n",
    "            q_map[new_state] = len(q_table)\n",
    "            q_table = np.append(q_table, new_row, axis=0)\n",
    "        new_state_row = q_map[new_state]\n",
    "\n",
    "        reward = -.01  #Encourage exploration.\n",
    "        if done:\n",
    "            reward = 1 if new_state == 15 else -1\n",
    "        current_q = q_table[state_row, action]\n",
    "        q_table[state_row, action] = update_q(\n",
    "            q_table, new_state_row, reward, current_q)\n",
    "\n",
    "        step += 1\n",
    "        if render:\n",
    "            env.render()\n",
    "            print_state(new_state, done)\n",
    "        state = new_state\n",
    "        \n",
    "    return q_table, q_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "9FNtPA42xz27"
   },
   "source": [
    "Ok, time to shine, gumdrop emoji! Let's do one simulation and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "fTU77U3Bxz27"
   },
   "outputs": [],
   "source": [
    "# Run to refresh the q_table.\n",
    "random_rate = 1\n",
    "q_table = np.copy(new_row)\n",
    "q_map = {0: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "2JtNilzQxz28"
   },
   "outputs": [],
   "source": [
    "q_table, q_map = play_game(q_table, q_map, random_rate, render=True)\n",
    "print_q(q_table, q_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "U0hsI9Wpxz29"
   },
   "source": [
    "Unless the gumdrop was incredibly lucky, chances were, it fell in some death water. Q-learning is markedly different from Value Iteration or Policy Iteration in that it attempts to simulate how an animal learns in unknown situations. Since the layout of the lake is unknown to the Gumdrop, it doesn't know which states are death holes, and which ones are safe. Because of this, it's going to make many mistakes before it can start making successes.\n",
    "\n",
    "Feel free to run the above cell multiple times to see how the gumdrop steps through trial and error. When you're ready, run the below cell to have the gumdrop play 1000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "_lrxCVx1xz29"
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    q_table, q_map = play_game(q_table, q_map, random_rate)\n",
    "    random_rate = random_rate * .99\n",
    "print_q(q_table, q_map)\n",
    "random_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "tbMENL88xz2-"
   },
   "source": [
    "Cats have nine lives, our Gumdrop lived a thousand! Moment of truth. Can it get out of the lake now that it matters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "WmbRS11Txz2-"
   },
   "outputs": [],
   "source": [
    "q_table, q_map = play_game(q_table, q_map, 0, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "ncCSvhUMxz2-"
   },
   "source": [
    "Third time's the charm!\n",
    "\n",
    "Each of these techniques has its pros and cons. For instance, while Value Iteration is the mathematically correct solution, it's not as time efficient at Policy Iteration or as flexible as Q-Learning.\n",
    "\n",
    "| |Value Iteration|Policy Iteration|Q Tables|\n",
    "|-|-|-|-|\n",
    "|Avoids locally optimal routes|✓|x|x|\n",
    "|On-policy (greedy)|✓|✓|x|\n",
    "|Model Free|x|x|✓|\n",
    "|Most time efficient|x|✓|x|\n",
    "\n",
    "Congratulations on making it through to the end. Now if you ever fall on a Frozen Lake, you'll have many different ways to calculate your survival. The gumdrop thank you!\n",
    "\n",
    "<img src=\"images/end.jpg\" width=\"178\" height=\"234\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "KPVBHxlPxz2_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "zE9NJRRoxz2_"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "bugOLU7vxz2_"
   },
   "source": [
    "# Thresholds for Entry and Exit of Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "-3tx5cQSxz3A"
   },
   "source": [
    "Manage Profit with Exit Orders\n",
    "To manage profit means preservation of capital. The main goal is to capture as much profit as possible. There are several different methods to achieve this. Here is a brief explanation of the more popular order types you can use.\n",
    "\n",
    "1. Auction: An Auction order is entered into the electronic trading system during the pre-market opening period for execution at the Calculated Opening Price (COP). \n",
    "\n",
    "1. Discretionary: An Discretionary order is a limit order submitted with a hidden, specified ‘discretionary’ amount off the limit price which may be used to increase the price range over which the limit order is eligible to execute. The market sees only the limit price.\n",
    "\n",
    "1. Market: A Market order is an order to buy or sell at the market bid or offer price. \n",
    "\n",
    "1. Market If Touched: A Market If Touched (MIT) is an order to buy (or sell) a contract below (or above) the market. Its purpose is to take advantage of sudden or unexpected changes in share or other prices and provides investors with a trigger price to set an order in motion.\n",
    "\n",
    "1. Pegged To Market: A pegged-to-market order is designed to maintain a purchase price relative to the national best offer (NBO) or a sale price relative to the national best bid (NBB). Depending on the width of the quote, this order may be passive or aggressive.\n",
    "\n",
    "1. Pegged To Stock: A Pegged to Stock order continually adjusts the option order price by the product of a signed user-define delta and the change of the option’s underlying stock price. The delta is entered as an absolute and assumed to be positive for calls and negative for puts. A buy or sell call order price is determined by adding the delta times a change in an underlying stock price to a specified starting price for the call. \n",
    "\n",
    "1. Pegged To Primary: Relative (a.k.a. Pegged-to-Primary) orders provide a means for traders to seek a more aggressive price than the National Best Bid and Offer (NBBO). By acting as liquidity providers, and placing more aggressive bids and offers than the current best bids and offers, traders increase their odds of filling their order. Quotes are automatically adjusted as the markets move, to remain aggressive. For a buy order, your bid is pegged to the NBB by a more aggressive offset, and if the NBB moves up, your bid will also move up. If the NBB moves down, there will be no adjustment because your bid will become even more aggressive and execute. For sales, your offer is pegged to the NBO by a more aggressive offset, and if the NBO moves down, your offer will also move down. If the NBO moves up, there will be no adjustment because your offer will become more aggressive and execute.\n",
    "\n",
    "1. Sweep To Fill: Sweep-to-fill orders are useful when a trader values speed of execution over price. A sweep-to-fill order identifies the best price and the exact quantity offered/available at that price, and transmits the corresponding portion of your order for immediate execution.\n",
    "\n",
    "1. Limit Order: A Limit order is an order to buy or sell at a specified price or better. The Limit order ensures that if the order fills, it will not fill at a price less favorable than your limit price, but it does not guarantee a fill.\n",
    "\n",
    "1. Box Top: A Box Top order executes as a market order at the current best price. If the order is only partially filled, the remainder is submitted as a limit order with the limit price equal to the price at which the filled portion of the order executed.\n",
    "\n",
    "1. Limit If Touched: A Limit if Touched is an order to buy (or sell) a contract at a specified price or better, below (or above) the market. This order is held in the system until the trigger price is touched. An LIT order is similar to a stop limit order, except that an LIT sell order is placed above the current market price, and a stop limit sell order is placed below.\n",
    "\n",
    "1. Limit On Close: A Limit-on-close (LOC) order will be submitted at the close and will execute if the closing price is at or better than the submitted limit price.\n",
    "\n",
    "1. Limit On Open: A Limit-on-Open (LOO) order combines a limit order with the OPG time in force to create an order that is submitted at the market’s open, and that will only execute at the specified limit price or better. Orders are filled in accordance with specific exchange rules.\n",
    "\n",
    "1. Passive Relative: Passive Relative orders provide a means for traders to seek a less aggressive price than the National Best Bid and Offer (NBBO) while keeping the order pegged to the best bid (for a buy) or ask (for a sell). The order price is automatically adjusted as the markets move to keep the order less aggressive. For a buy order, your order price is pegged to the NBB by a less aggressive offset, and if the NBB moves up, your bid will also move up. If the NBB moves down, there will be no adjustment because your bid will become aggressive and execute. For a sell order, your price is pegged to the NBO by a less aggressive offset, and if the NBO moves down, your offer will also move down. If the NBO moves up, there will be no adjustment because your offer will become aggressive and execute. In addition to the offset, you can define an absolute cap, which works like a limit price, and will prevent your order from being executed above or below a specified level. The Passive Relative order is similar to the Relative/Pegged-to-Primary order, except that the Passive relative subtracts the offset from the bid and the Relative adds the offset to the bid.\n",
    "\n",
    "1. Stop: A Stop order is an instruction to submit a buy or sell market order if and when the user-specified stop trigger price is attained or penetrated. A Stop order is not guaranteed a specific execution price and may execute significantly away from its stop price. A Sell Stop order is always placed below the current market price and is typically used to limit a loss or protect a profit on a long stock position. A Buy Stop order is always placed above the current market price. It is typically used to limit a loss or help protect a profit on a short sale.\n",
    "\n",
    "1. Stop Limit: A Stop-Limit order is an instruction to submit a buy or sell limit order when the user-specified stop trigger price is attained or penetrated. The order has two basic components: the stop price and the limit price. When a trade has occurred at or through the stop price, the order becomes executable and enters the market as a limit order, which is an order to buy or sell at a specified price or better.\n",
    "\n",
    "1. Trailing Stop: A sell trailing stop order sets the stop price at a fixed amount below the market price with an attached “trailing” amount. As the market price rises, the stop price rises by the trail amount, but if the stock price falls, the stop loss price doesn’t change, and a market order is submitted when the stop price is hit. This technique is designed to allow an investor to specify a limit on the maximum possible loss, without setting a limit on the maximum possible gain. “Buy” trailing stop orders are the mirror image of sell trailing stop orders, and are most appropriate for use in falling markets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "m8hRxQvvxz3A"
   },
   "source": [
    "--- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "gLzUmsujxz3A"
   },
   "source": [
    "## The Capital Asset Pricing Model and Arbitrage Pricing Theory\n",
    "\n",
    "\n",
    "\n",
    "The Capital Asset Pricing Model (CAPM) is a classic measure of the cost of capital. It is used often in finance to evaluate the price of assets and to assess the impact of the risk premium from the market at large. In this lecture, we discuss the CAPM the more general Arbitrage Pricing Theory (APT) to form a basis for evaluating the risk associated with various factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "id": "3pVJ1qbfxz3A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels import regression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "t88fomDyxz3B"
   },
   "source": [
    "## Idiosyncratic and Systematic Risk\n",
    "\n",
    "In general, portfolios and assets can face two types of risk: idiosyncratic and systematic risk. **Idiosyncratic risk** refers to risks that are firm-specific and can be diversified away, such as a management change or a faulty production, while **systematic risk** is market-wide and affects all market participants. An example could be a slowing of the economy or a change in the interest rate. Because all firms are exposed to systematic risk, it cannot be diversified away.\n",
    "\n",
    "## Risk Premia\n",
    "\n",
    "As the number of assets in a portfolio increases, many of the idiosyncratic risks cancel out and are diversified away. This is the key reason why we want to avoid [position concentration risk](https://www.quantopian.com/lectures/position-concentration-risk). As your portfolio grows larger and makes more independent bets through diversification, the variance of the portfolio declines until only the systematic risk remains. As we cannot remove systematic risk, investors must be given a risk premium above the rate of risk-free return to compensate them for the risk they take on by investing in this portfolio. The individual firm-level risks in this portfolio do not have associated premia as this would create arbitrage opportunities. Shareholders could collect the risk premium while diversifying away the risk associated with them. That would mean additional profit without any additional exposure. This is the definition of an arbitrage opportunity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "JW48z-n8xz3B"
   },
   "source": [
    "From this reasoning we can conclude that the premium on an asset should have no relation to its idiosyncratic risk, but should instead rely solely on the level of systematic risk it carries. In order to accurately compute the risk premium of an asset, and consequently our expected return, we need to find a measure of systematic risk. If we have that, then we can theoretically define the return of an asset in the following way:\n",
    "\n",
    "$$E[\\mbox{Return}] = \\mbox{Risk-Free Rate of Return} + \\mbox{Risk Premium}$$\n",
    "\n",
    "One way to do this is to estimate how changes in the excess return of an asset are related to changes in the excess return of the market. Expressing this as a linear regression gives us the relationship as the change in expected return of an asset for each 1% change in the return of the market portfolio.\n",
    "\n",
    "In theory, this market portfolio should have no diversifiable risk left and would therefore only fluctuate with systematic shocks. In practice, we use a market index such as the S&P500 as a proxy for the market portfolio. The beta that we get from regressing an asset's returns on the returns of the market will be our measure of systematic risk. This beta represents the sensitivity of an asset's return stream to market-wide shocks.\n",
    "\n",
    "Given this beta, the risk premium of asset $i$ is defined as:\n",
    "\n",
    "$$\\mbox{Risk Premium of Asset}_i = \\beta (\\mbox{Market Risk Premium})$$\n",
    "\n",
    "We call this simplistic model the Capital Asset Pricing Model (CAPM).\n",
    "\n",
    "## Capital Asset Pricing Theory\n",
    "\n",
    "We can express the CAPM more clearly like so:\n",
    "\n",
    "$$E[R_i] = R_F + \\beta(E[R_M] - R_F)$$\n",
    "\n",
    "where $R_i$ is the return of asset $i$, $R_F$ is the risk-free rate, and $R_M$ is the return of the market. The CAPM is one of the most basic measures of the cost of capital. It determines the minimum return required to entice investors to hold a certain asset.\n",
    "\n",
    "To put it another way, CAPM says that the return of an asset should be the risk-free rate, which is what we would demand to account for inflation and the time value of money, as well as something extra to compensate us for the amount of systematic risk we are exposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "YL0INW-8xz3B"
   },
   "outputs": [],
   "source": [
    "start_date = '2014-01-01'\n",
    "end_date = '2014-12-31'\n",
    "\n",
    "# choose stock\n",
    "R = get_pricing('AAPL', fields='price', start_date=start_date, end_date=end_date).pct_change()[1:]\n",
    "\n",
    "# risk-free proxy\n",
    "R_F = get_pricing('BIL', fields='price', start_date=start_date, end_date=end_date).pct_change()[1:]\n",
    "\n",
    "# find it's beta against market\n",
    "M = get_pricing('SPY', start_date=start_date, end_date=end_date, fields='price').pct_change()[1:]\n",
    "\n",
    "AAPL_results = regression.linear_model.OLS(R-R_F, sm.add_constant(M)).fit()\n",
    "AAPL_beta = AAPL_results.params[1]\n",
    "\n",
    "M.plot()\n",
    "R.plot()\n",
    "R_F.plot()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Daily Percent Return')\n",
    "plt.legend();\n",
    "\n",
    "AAPL_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "KQs9yvYoxz3C"
   },
   "source": [
    "We can then use our calculated beta exposure to make predictions of returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "7ED0PvWdxz3C"
   },
   "outputs": [],
   "source": [
    "predictions = R_F + AAPL_beta*(M - R_F) # CAPM equation\n",
    "\n",
    "predictions.plot()\n",
    "R.plot(color='Y')\n",
    "plt.legend(['Prediction', 'Actual Return'])\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Daily Percent Return');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "w1Yz1Zr8xz3D"
   },
   "source": [
    "## CAPM Assumptions\n",
    "\n",
    "In our derivation of the CAPM, we made two main assumptions:\n",
    "* We assumed that investors are able to trade without delay or cost and that everyone is able to borrow or lend money at the risk free rate.\n",
    "* We assumed that all investors are \"mean-variance optimizers\". What this essentially means is that they would only demand portfolios that have the highest return attainable for a given level of risk. These portfolios are all found along the **efficient frontier**.\n",
    "\n",
    "The following is a programmatic derivation of the efficient frontier for portfolios of four assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "id": "v8b4KA8Rxz3D"
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "import cvxopt as opt\n",
    "from cvxopt import blas, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "Xy-lmylexz3E"
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Turn off progress printing \n",
    "solvers.options['show_progress'] = False\n",
    "\n",
    "# Number of assets\n",
    "n_assets = 4\n",
    "\n",
    "# Number of observations\n",
    "n_obs = 2000\n",
    "\n",
    "## Generating random returns for our 4 securities\n",
    "return_vec = np.random.randn(n_assets, n_obs)\n",
    "\n",
    "def rand_weights(n):\n",
    "    ''' \n",
    "    Produces n random weights that sum to 1 \n",
    "    '''\n",
    "    k = np.random.rand(n)\n",
    "    return k / sum(k)\n",
    "\n",
    "def random_portfolio(returns):\n",
    "    ''' \n",
    "    Returns the mean and standard deviation of returns for a random portfolio\n",
    "    '''\n",
    "\n",
    "    p = np.asmatrix(np.mean(returns, axis=1))\n",
    "    w = np.asmatrix(rand_weights(returns.shape[0]))\n",
    "    C = np.asmatrix(np.cov(returns))\n",
    "    \n",
    "    mu = w * p.T\n",
    "    sigma = np.sqrt(w * C * w.T)\n",
    "    \n",
    "    # This recursion reduces outliers to keep plots pretty\n",
    "    if sigma > 2:\n",
    "        return random_portfolio(returns)\n",
    "    return mu, sigma\n",
    "\n",
    "def optimal_portfolios(returns):\n",
    "    n = len(returns)\n",
    "    returns = np.asmatrix(returns)\n",
    "    \n",
    "    N = 100000\n",
    "    \n",
    "    # Creating a list of returns to optimize the risk for\n",
    "    mus = [100**(5.0 * t/N - 1.0) for t in range(N)]\n",
    "    \n",
    "    # Convert to cvxopt matrices\n",
    "    S = opt.matrix(np.cov(returns))\n",
    "    pbar = opt.matrix(np.mean(returns, axis=1))\n",
    "    \n",
    "    # Create constraint matrices\n",
    "    G = -opt.matrix(np.eye(n))   # negative n x n identity matrix\n",
    "    h = opt.matrix(0.0, (n ,1))\n",
    "    A = opt.matrix(1.0, (1, n))\n",
    "    b = opt.matrix(1.0)\n",
    "    \n",
    "    # Calculate efficient frontier weights using quadratic programming\n",
    "    portfolios = [solvers.qp(mu*S, -pbar, G, h, A, b)['x'] \n",
    "                  for mu in mus]\n",
    "    \n",
    "    ## Calculate the risk and returns of the frontier\n",
    "    returns = [blas.dot(pbar, x) for x in portfolios]\n",
    "    risks = [np.sqrt(blas.dot(x, S*x)) for x in portfolios]\n",
    "    \n",
    "    return returns, risks\n",
    "\n",
    "n_portfolios = 50000\n",
    "\n",
    "means, stds = np.column_stack([random_portfolio(return_vec) for x in range(n_portfolios)])\n",
    "\n",
    "returns, risks = optimal_portfolios(return_vec)\n",
    "\n",
    "plt.plot(stds, means, 'o', markersize=2, color='navy')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Return')\n",
    "plt.title('Mean and Standard Deviation of Returns of Randomly Generated Portfolios');\n",
    "\n",
    "plt.plot(risks, returns, '-', markersize=3, color='red');\n",
    "plt.legend(['Portfolios', 'Efficient Frontier']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "_ZCIJFUZxz3F"
   },
   "source": [
    "Each blue dot represents a different portfolio, while the red line skimming the outside of the cloud is the efficient frontier. The efficient frontier contains all portfolios that are the best for a given level of risk.\n",
    "\n",
    "The optimal, or most efficient, portfolio on this line is found by maximizing the Sharpe ratio, the ratio of excess return and volatility. We use this to determine the portfolio with the best risk-to-reward tradeoff.\n",
    "\n",
    "The line that represents the different combinations of a risk-free asset with a portfolio of risky assets is known as the Capital Allocations Line (CAL). The slope of the CAL is the Sharpe ratio. To maximize the Sharpe ratio, we need to find the steepest CAL, which coincides with the CAL that is tangential to the efficient frontier. This is why the efficient portfolio is sometimes referred to as the tangent portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "IZkMjr4axz3F"
   },
   "outputs": [],
   "source": [
    "def maximize_sharpe_ratio(return_vec, risk_free_rate):\n",
    "    \"\"\"\n",
    "    Finds the CAPM optimal portfolio from the efficient frontier \n",
    "    by optimizing the Sharpe ratio.\n",
    "    \"\"\"\n",
    "    \n",
    "    def find_sharpe(weights):\n",
    "        \n",
    "        means = [np.mean(asset) for asset in return_vec]\n",
    "        \n",
    "        numerator = sum(weights[m]*means[m] for m in range(len(means))) - risk_free_rate\n",
    "        \n",
    "        weight = np.array(weights)\n",
    "        \n",
    "        denominator = np.sqrt(weights.T.dot(np.corrcoef(return_vec).dot(weights)))\n",
    "        \n",
    "        return numerator/denominator\n",
    "    \n",
    "    guess = np.ones(len(return_vec)) / len(return_vec)\n",
    "    \n",
    "    def objective(weights):\n",
    "        return -find_sharpe(weights)\n",
    "    \n",
    "    # Set up equality constrained\n",
    "    cons = {'type':'eq', 'fun': lambda x: np.sum(np.abs(x)) - 1} \n",
    "\n",
    "    # Set up bounds for individual weights\n",
    "    bnds = [(0, 1)] * len(return_vec)\n",
    "    \n",
    "    results = optimize.minimize(objective, guess,\n",
    "                            constraints=cons, bounds=bnds, \n",
    "                            method='SLSQP', options={'disp': False})\n",
    "    \n",
    "    return results\n",
    "\n",
    "risk_free_rate = np.mean(R_F)\n",
    "\n",
    "results = maximize_sharpe_ratio(return_vec, risk_free_rate)\n",
    "\n",
    "# Applying the optimal weights to each assset to get build portfolio\n",
    "optimal_mean = sum(results.x[i]*np.mean(return_vec[i]) for i in range(len(results.x)))\n",
    "\n",
    "optimal_std = np.sqrt(results.x.T.dot(np.corrcoef(return_vec).dot(results.x)))\n",
    "\n",
    "# Plot of all possible portfolios\n",
    "plt.plot(stds, means, 'o', markersize=2, color='navy')\n",
    "plt.ylabel('Return')\n",
    "plt.xlabel('Risk')\n",
    "\n",
    "# Line from the risk-free rate to the optimal portfolio\n",
    "eqn_of_the_line = lambda x : ( (optimal_mean-risk_free_rate) / optimal_std ) * x + risk_free_rate    \n",
    "\n",
    "xrange = np.linspace(0., 1., num=11)\n",
    "\n",
    "plt.plot(xrange, [eqn_of_the_line(x) for x in xrange], color='red', linestyle='-', linewidth=2)\n",
    "\n",
    "# Our optimal portfolio\n",
    "plt.plot([optimal_std], [optimal_mean], marker='o', markersize=12, color=\"navy\")\n",
    "\n",
    "plt.legend(['Portfolios', 'Capital Allocation Line', 'Optimal Portfolio']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "XjulFrK8xz3G"
   },
   "source": [
    "We can look at the returns and risk of the individual assets compared to the optimal portfolio we found to easily showcase the power of diversification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "XwC5ZOGSxz3G"
   },
   "outputs": [],
   "source": [
    "for a in range(len(return_vec)): \n",
    "    print \"Return and Risk of Asset\", a, \":\", np.mean(return_vec[a]), \",\",np.std(return_vec[a])   \n",
    "    \n",
    "print \"Return and Risk of Optimal Portfolio\", optimal_mean, optimal_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "XThgZY-wxz3H"
   },
   "source": [
    "## Capital Market Line is CAL through market portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Khmhap9xxz3H"
   },
   "source": [
    "Our optimal portfolio has a decently high return as well as less risk than any individual asset, as expected. Theoeretically, all investors should demand this optimal, tangent portfolio. If we accumulate the portfolios of all investors, we end up with the market portfolio, since all shares must be held by someone. This means that the tangency portfolio is the market portfolio, essentially saying that demand must equal supply.\n",
    "\n",
    "When a risk-free asset is added to the portfolio, the Capital Asset Line turns into the Capital Market Line (CML). According to the CAPM, any stock or portfolio that lies to the right of CML would contain diversifiable risk and is therefore not efficient.\n",
    "\n",
    "The mapping of each security's beta to its expected return results in the Security Markets Line. The difference between a security's return and the expected return as predicted by CAPM is known as the alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ckZZeM9Mxz3H"
   },
   "outputs": [],
   "source": [
    "risk_free_rate = np.mean(R_F)\n",
    "\n",
    "# We have two coordinates that we use to map the SML: (0, risk-free rate) and (1, market return)\n",
    "\n",
    "eqn_of_the_line = lambda x : ( (np.mean(M)-risk_free_rate) / 1.0) * x + risk_free_rate        \n",
    "xrange = np.linspace(0., 2.5, num=2)\n",
    "plt.plot(xrange, [eqn_of_the_line(x) for x in xrange], color='red', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.plot([1], [np.mean(M)], marker='o', color='navy', markersize=10)\n",
    "plt.annotate('Market', xy=(1, np.mean(M)), xytext=(0.9, np.mean(M)+0.00004))\n",
    "\n",
    "# Next, we will compare to see whether stocks in more cyclical industries have higher betas\n",
    "# Of course, a more thorough analysis is required to rigorously answer this question\n",
    "\n",
    "# Non-Cyclical Industry Stocks\n",
    "non_cyclical = ['PG', 'DUK', 'PFE']\n",
    "non_cyclical_returns = get_pricing(\n",
    "    non_cyclical,\n",
    "    fields='price',\n",
    "    start_date=start_date,\n",
    "    end_date=end_date\n",
    ").pct_change()[1:]\n",
    "non_cyclical_returns.columns = map(lambda x: x.symbol, non_cyclical_returns.columns)\n",
    "\n",
    "non_cyclical_betas = [\n",
    "    regression.linear_model.OLS(\n",
    "        non_cyclical_returns[asset],\n",
    "        sm.add_constant(M)\n",
    "    ).fit().params[1]\n",
    "     for asset in non_cyclical\n",
    "]\n",
    "\n",
    "for asset, beta in zip(non_cyclical, non_cyclical_betas):\n",
    "    plt.plot([beta], [np.mean(non_cyclical_returns[asset])], marker='o', color='g', markersize=10)\n",
    "    plt.annotate(\n",
    "        asset,\n",
    "        xy=(beta, np.mean(non_cyclical_returns[asset])),\n",
    "        xytext=(beta + 0.015, np.mean(non_cyclical_returns[asset]) + 0.000025)\n",
    "    )\n",
    "\n",
    "# Cyclical Industry Stocks\n",
    "cyclical = ['RIO', 'SPG', 'ING']\n",
    "cyclical_returns = get_pricing(\n",
    "    cyclical,\n",
    "    fields='price',\n",
    "    start_date=start_date,\n",
    "    end_date=end_date\n",
    ").pct_change()[1:]\n",
    "cyclical_returns.columns = map(lambda x: x.symbol, cyclical_returns.columns)\n",
    "\n",
    "cyclical_betas = [\n",
    "    regression.linear_model.OLS(\n",
    "        cyclical_returns[asset],\n",
    "        sm.add_constant(M)\n",
    "    ).fit().params[1]\n",
    "     for asset in cyclical\n",
    "]\n",
    "\n",
    "for asset, beta in zip(cyclical, cyclical_betas):\n",
    "    plt.plot([beta], [np.mean(cyclical_returns[asset])], marker='o', color='y', markersize=10)\n",
    "    plt.annotate(\n",
    "        asset,\n",
    "        xy=(beta, np.mean(cyclical_returns[asset])),\n",
    "        xytext=(beta + 0.015, np.mean(cyclical_returns[asset]) + 0.000025)\n",
    "    )\n",
    "\n",
    "# drawing the alpha, which is the difference between expected return and the actual return\n",
    "plt.plot(\n",
    "    [cyclical_betas[2], cyclical_betas[2]],\n",
    "    [np.mean(cyclical_returns.iloc[:, 2]), eqn_of_the_line(cyclical_betas[2])],\n",
    "    color='grey'\n",
    ")\n",
    "plt.annotate(\n",
    "    'Alpha',\n",
    "    xy=(\n",
    "        cyclical_betas[2] + 0.05,\n",
    "        (eqn_of_the_line(cyclical_betas[2])-np.mean(cyclical_returns.iloc[:,2]))/2+np.mean(cyclical_returns.iloc[:,2])\n",
    "    ),\n",
    "    xytext=(\n",
    "        cyclical_betas[2] + 0.05,\n",
    "        (eqn_of_the_line(cyclical_betas[2])-np.mean(cyclical_returns.iloc[:,2]))/2+np.mean(cyclical_returns.iloc[:,2])\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Beta\")\n",
    "plt.ylabel(\"Return\")\n",
    "\n",
    "plt.legend(['Security Market Line']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "6k9UqVdWxz3I"
   },
   "source": [
    "For more details on the CAPM, check out the [wikipedia page](https://en.wikipedia.org/wiki/Capital_asset_pricing_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "tzqnLUsRxz3I"
   },
   "source": [
    "## Arbitrage Pricing Theory\n",
    "\n",
    "The CAPM, while widely used and studied, has many drawbacks. With strict, limiting assumptions, it does not hold up well in empirical tests. Arbitrage Pricing Theory (APT) aims to generalize the CAPM model, as assets may be exposed to classes of risks other than the market risk and investors may care about things other than just the mean and variance.\n",
    "\n",
    "APT is a major asset pricing theory that relies on expressing the returns using a linear factor model:\n",
    "\n",
    "$$R_i = a_i + b_{i1} F_1 + b_{i2} F_2 + \\ldots + b_{iK} F_K + \\epsilon_i$$\n",
    "\n",
    "A factor is a return stream that is determined completely by some characteristic. For example, the CAPM has only one factor, market return. If we have modelled our rate of return as above, then the expected returns should take the form of:\n",
    "\n",
    "$$ E(R_i) = R_F + b_{i1} \\lambda_1 + b_{i2} \\lambda_2 + \\ldots + b_{iK} \\lambda_K $$\n",
    "\n",
    "where $R_F$ is the risk-free rate, and $\\lambda_j$ is the risk premium - the return in excess of the risk-free rate - for factor $j$. This premium arises because investors require higher returns to compensate them for incurring higher risk.\n",
    "\n",
    "We'll compute the risk premia for our factors with Fama-Macbeth regression. However, there are various ways to compute each $\\lambda_j$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "id": "o2C-qRE3xz3I"
   },
   "source": [
    "### Arbitrage\n",
    "\n",
    "Now that we have a reasonably general way to compute expected return, we can discuss arbitrage more technically. There are generally many, many securities in our universe. If we use different ones to compute the $\\{\\lambda_i\\}$, will our results be consistent? If our results are inconsistent, there is an *arbitrage opportunity* (in expectation), an operation that earns a profit without incurring risk and with no net investment of money. In this case, we mean that there is a risk-free operation with *expected* positive return that requires no net investment. It occurs when expectations of returns are inconsistent, i.e. risk is not priced consistently across securities.\n",
    "\n",
    "Say that there is an asset with expected rate of return 0.2 for the next year and a $\\beta$ of 1.2 with the market, while the market is expected to have a rate of return of 0.1, and the risk-free rate on 1-year bonds is 0.05. Then the APT model tells us that the expected rate of return on the asset should be\n",
    "\n",
    "$$ R_F + \\beta \\lambda = 0.05 + 1.2 (0.1 - 0.05) = 0.11$$\n",
    "\n",
    "This does not agree with the prediction that the asset will have a rate of return of 0.2. So, if we buy \\$100 of our asset, short \\$120 of the market, and buy \\$20 of bonds, we will have invested no net money and are not exposed to any systematic risk (we are market-neutral), but we expect to earn $0.2(100) - 0.1(120) + 0.05(20) = 9$ dollars at the end of the year.\n",
    "\n",
    "The APT assumes that these opportunities will be taken advantage of until prices shift and the arbitrage opportunities disappear. That is, it assumes that there are arbitrageurs who have sufficient amounts of patience and capital. This provides a justification for the use of empirical factor models in pricing securities: if the model was inconsistent, there would be an arbitrage opportunity, and so the prices would adjust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "xbAwfUr0xz3J"
   },
   "source": [
    "## Goes Both Ways\n",
    "\n",
    "Accurately knowing $E(R_i)$ is incredibly difficult, but this model tells us what the expected returns should be if the market is free of arbitrage. This lays the groundwork for strategies based on factor model ranking systems. If you have a model for the expected return of an asset, then you can rank those assets based on their expected performance and use this information to make trades. This creation of a ranking scheme is the hallmark of a [long-short equity strategy](https://www.quantopian.com/lectures/long-short-equity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "QK2kV0Phxz3J"
   },
   "source": [
    "## Testing Arbitrage Pricing Theory\n",
    "\n",
    "Most empirical tests of the APT are done in two steps: estimating the betas of individual factors, then comparing it to actual prices to see how predictions fared.\n",
    "\n",
    "Here we will use the return streams from long-short equity strategies built from various microeconomic indicators as our factors. Then, we will use the Fama-Macbeth regression method to estimate our risk premia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "id": "zntvgMBAxz3J"
   },
   "outputs": [],
   "source": [
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.pipeline.data import Fundamentals\n",
    "from quantopian.pipeline.factors import Returns, Latest\n",
    "from quantopian.pipeline.filters import Q1500US\n",
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline.classifiers.fundamentals import Sector\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "BZfFXp74xz3K"
   },
   "source": [
    "Now we use pipeline to get all of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "O9gPMrzexz3K",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    \n",
    "    pipe = Pipeline()\n",
    "\n",
    "    # Add our factors to the pipeline\n",
    "    purchase_of_biz = Latest([Fundamentals.purchase_of_business])\n",
    "    pipe.add(purchase_of_biz, 'purchase_of_business')\n",
    "    \n",
    "    RD = Latest([Fundamentals.research_and_development])\n",
    "    pipe.add(RD, 'RD')\n",
    "    \n",
    "    operating_cash_flow = Latest([Fundamentals.operating_cash_flow])\n",
    "    pipe.add(operating_cash_flow, 'operating_cash_flow')\n",
    "    \n",
    "    # Create factor rankings and add to pipeline\n",
    "    purchase_of_biz_rank = purchase_of_biz.rank()\n",
    "    RD_rank = RD.rank()\n",
    "    operating_cash_flow_rank = operating_cash_flow.rank()\n",
    "\n",
    "    pipe.add(purchase_of_biz_rank, 'purchase_of_biz_rank')\n",
    "    pipe.add(RD_rank, 'RD_rank')\n",
    "    pipe.add(operating_cash_flow_rank, 'operating_cash_flow_rank')\n",
    "    \n",
    "    most_biz_bought = purchase_of_biz_rank.top(1000)\n",
    "    least_biz_bought = purchase_of_biz_rank.bottom(1000)\n",
    "    \n",
    "    most_RD = RD_rank.top(1000)\n",
    "    least_RD = RD_rank.bottom(1000)\n",
    "    \n",
    "    most_cash = operating_cash_flow_rank.top(1000)\n",
    "    least_cash = operating_cash_flow_rank.bottom(1000)\n",
    "    \n",
    "    pipe.add(most_biz_bought, 'most_biz_bought')\n",
    "    pipe.add(least_biz_bought, 'least_biz_bought')\n",
    "    \n",
    "    pipe.add(most_RD, 'most_RD')\n",
    "    pipe.add(least_RD, 'least_RD')\n",
    "    \n",
    "    pipe.add(most_cash, 'most_cash')\n",
    "    pipe.add(least_cash, 'least_cash')\n",
    "    \n",
    "    # We also get daily returns\n",
    "    returns = Returns(window_length=2)\n",
    "    \n",
    "    # and sector types\n",
    "    sectors = Sector()\n",
    "\n",
    "    pipe.add(returns, \"Returns\")\n",
    "    \n",
    "    # We will focus on technology stocks in the Q1500\n",
    "    pipe.set_screen(\n",
    "        (Q1500US() & sectors.eq(311)) & \n",
    "        most_biz_bought | least_biz_bought | \n",
    "        most_RD | least_RD |\n",
    "        most_cash | least_cash\n",
    "    )\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "pipe = make_pipeline()\n",
    "results = run_pipeline(pipe, start_date, end_date)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "itl5-fSqxz3L"
   },
   "source": [
    "To get our factor return streams, we rank equities based on their purchases of businesses, their R&D spending, and their cash flow. Then, for each indicator, we go long the assets in the top percentile and short the ones in the bottom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "id": "87wxhKhnxz3L"
   },
   "outputs": [],
   "source": [
    "most_biz_bought = results[results.most_biz_bought]['Returns'].groupby(level=0).mean()\n",
    "least_biz_bought = results[results.least_biz_bought]['Returns'].groupby(level=0).mean()\n",
    "\n",
    "most_RD = results[results.most_RD]['Returns'].groupby(level=0).mean()\n",
    "least_RD = results[results.least_RD]['Returns'].groupby(level=0).mean()\n",
    "\n",
    "most_cash = results[results.most_cash]['Returns'].groupby(level=0).mean()\n",
    "least_cash = results[results.least_cash]['Returns'].groupby(level=0).mean()\n",
    "\n",
    "# Calculating our factor return streams\n",
    "biz_purchase_portfolio = most_biz_bought - least_biz_bought\n",
    "RD_portfolio = most_RD - least_RD\n",
    "cash_flow_portfolio = most_cash - least_cash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "DDrRWX9hxz3M"
   },
   "source": [
    "Finally, we'll put everything together in our Fama-Macbeth regressions. This occurs in two steps.\n",
    "\n",
    "First, for each asset we regress its returns on each factor return stream:\n",
    "\n",
    "$$R_{1, t} = \\alpha_1 + \\beta_{1, F_1}F_{1, t} + \\beta_{1, F_2}F_{2, t} + \\dots + \\beta_{1, F_m}F_{m, t} + \\epsilon_{1, t} \\\\\n",
    "R_{2, t} = \\alpha_2 + \\beta_{2, F_1}F_{1, t} + \\beta_{2, F_2}F_{2, t} + \\dots + \\beta_{2, F_m}F_{m, t} + \\epsilon_{2, t} \\\\\n",
    "\\vdots \\\\\n",
    "R_{n, t} = \\alpha_n + \\beta_{n, F_1}F_{1, t} + \\beta_{n, F_2}F_{2, t} + \\dots + \\beta_{n, F_m}F_{m, t} + \\epsilon_{n, t}$$\n",
    "\n",
    "Second, we take the beta estimates from the first step and use those as our exogenous variables in an estimate of the mean return of each asset. This step is the calculation of our risk premia, $\\{\\gamma_K\\}$.\n",
    "\n",
    "$$E(R_i) = \\gamma_0 + \\gamma_1 \\hat{\\beta}_{i, F_1} + \\gamma_2 \\hat{\\beta}_{i, F_2} + \\dots + \\gamma_m \\hat{\\beta}_{i, F_m} + \\epsilon_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "WYEkjfn9xz3M",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# putting all of our data from pipeline into a DataFrame for convenience\n",
    "# we'll have to first do some data manipulating since our factor return streams are date specific,\n",
    "# but our asset returns are both date and asset specific\n",
    "\n",
    "data = results[['Returns']].set_index(results.index)\n",
    "asset_list_sizes = [group[1].size for group in data.groupby(level=0)]\n",
    "\n",
    "purchase_of_biz_column = [\n",
    "    [biz_purchase_portfolio.loc[group[0]]] * size\n",
    "     for group, size in zip(data.groupby(level=0), asset_list_sizes)\n",
    "]\n",
    "data['Purchase of Business'] = list(itertools.chain(*purchase_of_biz_column))\n",
    "\n",
    "RD_column = [\n",
    "    [RD_portfolio.loc[group[0]]] * size\n",
    "     for group, size in zip(data.groupby(level=0), asset_list_sizes)\n",
    "]\n",
    "data['RD'] = list(itertools.chain(*RD_column))\n",
    "\n",
    "cash_flow_column = [\n",
    "    [cash_flow_portfolio.loc[group[0]]] * size\n",
    "     for group, size in zip(data.groupby(level=0), asset_list_sizes)\n",
    "]\n",
    "data['Operating Cash Flow'] = list(itertools.chain(*cash_flow_column))\n",
    "\n",
    "data = sm.add_constant(data.dropna())\n",
    "\n",
    "# Our list of assets from pipeline\n",
    "assets = data.index.levels[1].unique()\n",
    "\n",
    "X = [data.xs(asset, level=1)['Returns'] for asset in assets] \n",
    "Y = [\n",
    "    data.xs(asset, level=1)[['Purchase of Business', 'RD', 'Operating Cash Flow', 'const']]\n",
    "     for asset in assets\n",
    "]\n",
    "\n",
    "# First regression step: estimating the betas\n",
    "reg_results = [\n",
    "    regression.linear_model.OLS(x-risk_free_rate, y).fit().params\n",
    "     for x, y in zip(X, Y) if not(x.empty or y.empty)\n",
    "]\n",
    "indices = [asset for x, y, asset in zip(X, Y, assets) if not(x.empty or y.empty)]\n",
    "\n",
    "betas = pd.DataFrame(reg_results, index=indices)\n",
    "betas = sm.add_constant(betas.drop('const', axis=1))\n",
    "\n",
    "R = data['Returns'].mean(axis=0, level=1)\n",
    "\n",
    "# Second regression step: estimating the risk premia\n",
    "final_results = regression.linear_model.OLS(R - risk_free_rate, betas).fit()\n",
    "\n",
    "final_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "id": "-cA3SZYzxz3N"
   },
   "source": [
    "It is imperative that we not just use our model estimates at face value. A scan through the accompanying statistics can be highly insightful about the efficacy of our estimated model. For example, notice that although our individual factors are significant, we have a very low $R^2$. What this may suggest is that there is a real link between our factors and the returns of our assets, but that there still remains a lot of unexplained noise!\n",
    "\n",
    "For a more in-depth look at choosing factors, check out the [factor analysis lecture](https://www.quantopian.com/lectures/factor-analysis)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "jaO95xU4xz3N"
   },
   "outputs": [],
   "source": [
    "# smoke test for multicollinearity\n",
    "print data[['Purchase of Business', 'RD', 'Operating Cash Flow']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "aRIR0LCPxz3O"
   },
   "source": [
    "Now that we have estimates for our risk premia we can combine these with our beta estimates from our original regression to estimate asset returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "2O_j0FMDxz3O"
   },
   "outputs": [],
   "source": [
    "# this is our actual model!\n",
    "expected_return = risk_free_rate \\\n",
    "    + betas['Purchase of Business']*final_results.params[1] \\\n",
    "    + betas['RD']*final_results.params[2] \\\n",
    "    + betas['Operating Cash Flow']*final_results.params[3]\n",
    "\n",
    "year_of_returns = get_pricing(\n",
    "    expected_return.index,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    fields='close_price'\n",
    ").pct_change()[1:]\n",
    "\n",
    "plt.plot(year_of_returns[expected_return.index[1]], color='purple')\n",
    "plt.plot(pd.DataFrame({'Expected Return': expected_return.iloc[0]}, index=year_of_returns.index), color='red')\n",
    "plt.legend(['AAPL Returns', 'APT Prediction']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "FlKZfbGTxz3P",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare AAPL prediction of CAPM vs. our APT model\n",
    "M_annual_return = get_pricing('SPY', start_date=start_date, end_date=end_date, fields='price').pct_change()[1:]\n",
    "\n",
    "# We'll take the market beta we calculated from the beginning of the lecture\n",
    "CAPM_AAPL_prediction = risk_free_rate + AAPL_beta*(M_annual_return.mean() - risk_free_rate)\n",
    "\n",
    "# Let's take a closer look\n",
    "year_of_returns = year_of_returns[:25]\n",
    "\n",
    "plt.plot(year_of_returns[expected_return.index[1]], color='purple')\n",
    "plt.plot(pd.DataFrame({'Expected Return': expected_return.iloc[0]}, index=year_of_returns.index), color='red')\n",
    "plt.plot(pd.DataFrame({'Expected Return': year_of_returns.mean()[0]}, index=year_of_returns.index), color='navy')\n",
    "plt.plot(pd.DataFrame({'Expected Return': CAPM_AAPL_prediction}, index=year_of_returns.index), color='green')\n",
    "plt.legend(['AAPL Returns', 'APT Prediction', 'AAPL Average Returns', 'CAPM Prediction']);\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "0OOOA2Gdxz3Q"
   },
   "source": [
    "Finally, as a rough comparison between APT and CAPM, we'll look at the returns from Long-Short strategies constructed using each model as the ranking scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "CNkZQFAgxz3Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "market_betas = [\n",
    "    regression.linear_model.OLS(x[1:], sm.add_constant(M_annual_return)).fit().params[1]\n",
    "     for x in X if (x[1:].size == M_annual_return.size)\n",
    "]\n",
    "indices = [asset for x, asset in zip(X, assets) if (x[1:].size == M_annual_return.size)]\n",
    "\n",
    "market_return = pd.DataFrame({'Market': M_annual_return.mean()}, index = indices)\n",
    "\n",
    "CAPM_predictions = risk_free_rate + market_betas*(market_return['Market'] - risk_free_rate)\n",
    "CAPM_predictions.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "CAPM_portfolio = [CAPM_predictions.head(5).index, CAPM_predictions.tail(5).index]\n",
    "CAPM_long = get_pricing(\n",
    "    CAPM_portfolio[0],\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    fields='price'\n",
    ").pct_change()[1:].mean(axis=1)\n",
    "CAPM_short = get_pricing(\n",
    "    CAPM_portfolio[1],\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    fields='price'\n",
    ").pct_change()[1:].mean(axis=1)\n",
    "\n",
    "CAPM_returns = CAPM_long - CAPM_short\n",
    "\n",
    "expected_return.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "APT_portfolio = [expected_return.head(5).index, expected_return.tail(5).index]\n",
    "APT_long = get_pricing(\n",
    "    APT_portfolio[0],\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    fields='price'\n",
    ").pct_change()[1:].mean(axis=1)\n",
    "APT_short = get_pricing(\n",
    "    APT_portfolio[1],\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    fields='price'\n",
    ").pct_change()[1:].mean(axis=1)\n",
    "\n",
    "APT_returns = APT_long - APT_short\n",
    "\n",
    "plt.plot(CAPM_returns)\n",
    "plt.plot(APT_returns)\n",
    "plt.plot(pd.DataFrame({'Mean Return': CAPM_returns.mean()}, index=CAPM_returns.index))\n",
    "plt.plot(pd.DataFrame({'Mean Return': APT_returns.mean()}, index=APT_returns.index))\n",
    "plt.legend(['CAPM Portfolio', 'APT Portfolio', 'CAPM Mean', 'APT Mean'])\n",
    "\n",
    "print \"Returns after a year: APT versus CAPM\"\n",
    "print ((APT_returns[-1]/APT_returns[0]) - 1) - ((CAPM_returns[-1]/CAPM_returns[0])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "3u5n6jdLxz3R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "PExrR6Y2xz3S"
   },
   "source": [
    "# Position Sizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "XJmYMFX6xz3S"
   },
   "source": [
    "*probability forecast of a stock to outperform the general market -->  The highest probabilities are converted into long and the lowest probabilities into short positionsin proportion to Confidence*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "QskGxoa6xz3S"
   },
   "source": [
    "The trading size determines our bet size and represents a crucial component of our trading system. Sizing rules have huge impact on our overall portfolio performance. However, efficient position sizing is difficult. One of the problems with effective position sizing arises from fat-tailed distributions that can severely impact our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "FC9wvSaDxz3S"
   },
   "source": [
    "The trading size determines our bet size and represents a crucial component of our trading system. Sizing rules have huge impact on our overall portfolio performance. However, efficient position sizing is difficult. One of the problems with effective position sizing arises from fat-tailed distributions that can severely impact our results.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<blockquote>\n",
    "    <p>If you want to make an impression at a board meeting employ the figure of speech now sweeping the economic world: “But what about the fat tail?” This is another way of asking “How come all you geniuses didn’t realize the risk you were running?” Embarrassed witnesses and recently fired C.E.O.’s explain that the distribution of values and risks long beloved by managers, credit-rating agencies and securities analysts turned out to be not so normal after all.</p>\n",
    "    <footer> William Safire. Fat Tail.  <cite>The New York Times Magazine</cite></footer>\n",
    "</blockquote>\n",
    "<br><br>\n",
    "\n",
    "Another problem is the lack of statistical robustness of many measures when applied to position sizing. It is important to be aware that position sizing can break or make a trading system.\n",
    "\n",
    "Next we discuss four different position sizing models that you can implement in your strategy:\n",
    "\n",
    "1. Kelly Method\n",
    "1. Volatility Method\n",
    "1. Martingale\n",
    "1. Anti-Martingale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "pu1mK4HDxz3S"
   },
   "source": [
    "## Leverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "DcoxEu22xz3S"
   },
   "source": [
    "## What is leverage?\n",
    "\n",
    "Leverage is borrowing money, then investing that money into some trading strategy so as to effectively multiply your initial capital base by some amount.\n",
    "\n",
    "### More Specifically\n",
    "\n",
    "Leverage is reinvesting debt to gain a greater return on an investment. We include debt in our asset portfolio as a financial instrument that pays one large cash flow upfront (the loan) and gradually pays negative cash flows out over time. The size of these negative cash flows is determined by the interest rate on our debt. The large upfront cashflow allows us to supplement our capital base. In this way we use our capital and our leverage together to purchase the assets necessary to execute our trading strategy.\n",
    "\n",
    "### Why would you do this?\n",
    "\n",
    "If you are confident in a strategy and believe it to be low risk, you can put more money than you currently have into that strategy in an effort to multiply your returns. You of course have to have confidence that the returns on your strategy will exceed the interest rate on your debt.\n",
    "\n",
    "#### Risk Adjusted Returns\n",
    "\n",
    "We'll talk about this more later, but risk adjusted return is expressed in the Sharpe Ratio (excess returns/risk). A strategy with a high Sharpe Ratio may not have good absolute returns, say $2\\%$ annually, but if the Sharpe Ratio is high the risk will also be correspondingly low. Multiplying the capital base multiplies both the risk and returns of the strategy, keeping the Sharpe Ratio the same. See lower in the notebook for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "1U-6vccfxz3S"
   },
   "source": [
    "## How do I use leverage?\n",
    "\n",
    "In the context of algorithmic trading we are specifically interested in margin and trading on margin. Trading on margin is a type of leverage as it involves taking out a loan from your broker and adding it to your capital base in order to increase the returns of your trading strategy. Since you are borrowing money to invest, you ideally only trade on margin when the returns of your strategy are greater than the interest that you pay on that debt. At many points in the execution of a trading strategy, you may attempt to make trades that would exceed your current capital. At this point, the broker checks if you are authorized to trade on margin (borrow money) and, if so, lends you the money necessary to execute the trade. Each person’s margin account will have different terms depending on their broker, size of account, risk of strategies, and other factors. \n",
    "\n",
    "If you have a profitable strategy, using leverage can prop up the amount of money that you make overall by padding the money that you are working with. The involvement of the broker is an important factor to consider when constructing algorithmic trading strategies because your trading strategy will borrow automatically as needed when you need more money to cover a position. You may want to limit how much leverage your strategy can take on so that you are not borrowing more than you are comfortable with.\n",
    "\n",
    "We measure the current leverage of a portfolio by examining the leverage ratio. The leverage ratio of an algorithm is calculated as the sum of your debt and your capital base divided by your capital base. We limit the amount of leverage that our strategy uses by limiting the leverage ratio.\n",
    "\n",
    "$$ \\text{Leverage Ratio} = \\frac{\\text{Debt} + \\text{Capital Base}}{\\text{Capital Base}}$$\n",
    "\n",
    "Let's look at a very simple example of how introducing leverage can affect a portfolio. Consider a single period model, consisting of today and tomorrow, in which we receive our returns tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "6Md5e0tcxz3T"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "GQguGcCdxz3T",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "capital_base = 100000\n",
    "r_p = 0.05 # Aggregate performance of assets in the portfolio\n",
    "r_no_lvg = capital_base * r_p\n",
    "print 'Portfolio returns without leverage: {0}'.format(r_no_lvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "8i-la9ajxz3U"
   },
   "source": [
    "This is what portfolio returns look like without leverage. Let's add some debt, leveraging the portfolio, and see how the returns change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "8gAoiujVxz3V"
   },
   "outputs": [],
   "source": [
    "debt = 100000\n",
    "\n",
    "r_lvg = (capital_base + debt) * r_p\n",
    "r_lvg_pct = r_lvg / capital_base\n",
    "# Returns are calculated over the initial capital base\n",
    "# Think of the debt as an asset purchased and added to the portfolio\n",
    "lvg_ratio = (debt + capital_base) / capital_base\n",
    "print 'Portfolio returns with leverage: {0}'.format(r_lvg)\n",
    "print 'Percentage returns with {1}x leverage: {0}'.format(r_lvg_pct, lvg_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "bA-NP5Ajxz3W"
   },
   "source": [
    "This is the ideal situation, that someone would lend you money without asking for anything in return. It results in double the effective additive returns of an unlevered strategy, which is just delightful. However, we know that in the real world there is no way that this would actually happen. Let's consider what happens when we add in the effects of an interest payment in our one-period model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "E5HGHl7Zxz3W"
   },
   "outputs": [],
   "source": [
    "capital_base = 100000\n",
    "debt = 50000\n",
    "i = 0.02\n",
    "r_p = 0.05\n",
    "\n",
    "int_pmt = i * debt\n",
    "r_lvg = (capital_base + debt) * r_p\n",
    "r_total = r_lvg - int_pmt\n",
    "r_pct_lvg = r_total / capital_base\n",
    "lvg_ratio = (capital_base + debt) / capital_base\n",
    "print 'Portfolio returns with leverage and interest: {0}'.format(r_total)\n",
    "print 'Percentage returns with {1}x leverage and {2}% interest: {0}'.format(r_pct_lvg, lvg_ratio, i * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "3b5RAntXxz3X"
   },
   "source": [
    "That makes a lot more sense. It would be unreasonable for us to assume that we can add someone else's money to our portfolio without some sort of repayment schedule. Our returns are not as high as they were in the levered portfolio with no interest, but we are still gaining a greater amount of wealth by using leverage, despite the interest rates. As long as we have a reliable strategy that can make sufficient returns to offset the cost of debt we will be able to benefit from levering a portfolio.\n",
    "\n",
    "Our additive returns have increased over our unlevered strategy, but overall we are gaining a lower percentage return. This is not entirely a bad thing, as with a larger amount of money to trade on we are able to add more overall value to our portfolio. However, if we are not careful with how we manage leverage, we could potentially end up spending all of our profits trying to pay off the interest that we accrued to make them in the first place.\n",
    "\n",
    "This single-period model is only a small piece of the story. Loans are rarely, if ever, paid off in one period. Payments are spread out over the life of a loan, ensuring that you do not simply get the money for free. In this context, to properly earn a profit using the leverage, we obviously have to be making more money than we are paying out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "pI-R823Jxz3X"
   },
   "source": [
    "## How do I get leverage?\n",
    "\n",
    "Naturally, borrowing money to do anything will incur interest payments and additional fees. When trading with leverage, or on margin, these loans will come from your broker. Many brokers are loathe to part with their cash without a good reason. Using leverage with high volatility strategies can be dangerous unless you have a high tolerance for risk. Even if you lose money, you still have to pay the broker!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "_sxrtDvwxz3X"
   },
   "source": [
    "## Leverage in an algorithm\n",
    "\n",
    "Handling leverage gets significantly more complicated when we are dealing with an algorithm. Every time an algorithm rebalances its portfolio or makes a trade, there is a possibility of affecting the leverage ratio. If there isn't enough cash on hand to cover its positions it will need to borrow more. In the same vein, it may be utilizing overall less cash for the next set of trades, decreasing the leverage ratio.\n",
    "\n",
    "This is a backtest from our template long-short algorithm attached to our [long-short equity lecture](https://www.quantopian.com/lectures/long-short-equity) over the year 2015 (Note that an upgrade to this template algorithm is coming soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ndRqTovRxz3X"
   },
   "outputs": [],
   "source": [
    "bt = get_backtest('57e297562a42c9103c11a920')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "vmVD8DQ4xz3Y",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recorded_vars = bt.recorded_vars\n",
    "leverage = recorded_vars['leverage']\n",
    "daily_performance = bt.daily_performance\n",
    "daily_returns = daily_performance['returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "eFN0qOsWxz3a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(leverage);\n",
    "plt.title(\"Leverage Ratio of a Trading Algorithm Over Time\")\n",
    "plt.xlabel('Date');\n",
    "plt.ylabel('Leverage Ratio');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "54CH3_r_xz3b"
   },
   "source": [
    "Here is the leverage ratio of this algorithm plotted over time. Notice how it jumps around quite frequently. The ratio is below $1$ when it is not using all of its base capital and it spikes above $1$ whenever it makes a trade on margin. The algorithm associated with this leverage ratio is a long-short equity algorithm based on a combination of fundamental factors. For an overview of how a long-short equity strategy works, please see the [lectures](https://www.quantopian.com/lectures/long-short-equity) page.\n",
    "\n",
    "A key feature of this sort of strategy is that it can trade hundreds, sometimes even thousands of equities at once. As such, we run the risk of incurring some fairly large rebalancing costs, depending on how frequently we rebalance. This algorithm specifically rebalances on a monthly basis. As we can see on the above graph of the leverage ratio, a lot of the largest changes occur aroud the start of each month.\n",
    "\n",
    "To see how the rebalancing structure and maximum leverage can affect the leverage ratio of the algorithm when it is executed, go into the the template and modify these parameters. Changing the type of algorithm will also drastically affect how it uses leverage. Feel free to experiment.\n",
    "\n",
    "Things to try:\n",
    "1. Change the timing of the rebalancing between daily, monthly, and weekly.\n",
    "2. Modify the amount of leverage that the portfolio is allowed to take on\n",
    "3. Restrict the universe that the algorithm trades within by applying more filters to your trading universe.\n",
    "4. Instead of making all portfolio weights equally-weighted, use a portfolio optimization scheme like [Markowitz or Mean Absolute Deviation](https://www.quantopian.com/posts/mad-portfolio-an-alternative-to-markowitz) portfolio optimization.\n",
    "\n",
    "\n",
    "Here are the associated returns of this algorithm. The volatility of these returns is important to take into account when examining the leverage of a strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "1fxi6-9rxz3b"
   },
   "outputs": [],
   "source": [
    "plt.plot(daily_returns);\n",
    "plt.xlabel('Date');\n",
    "plt.ylabel('Daily Returns');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "4c4aLuSFxz3d"
   },
   "outputs": [],
   "source": [
    "print \"Mean return: \", daily_returns.mean()\n",
    "print \"Volatility: \", daily_returns.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "8l2BT8bZxz3e"
   },
   "source": [
    "Using leverage can be dangerous when you are dealing with a more volatile strategy. Because you are trading with borrowed money, we are on the hook to return it. We have to make sure that the broker gets his money back before we get our profit. If we end up in a position where we get a margin call, we have to pony up more funds if we want to hold our positions. Monitoring your strategy's volatility and ensuring you are only taking on palatable amounts of debt are key aspects of determining the quality of your trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "eLkg44-Xxz3e"
   },
   "source": [
    "## Risk-Adjusted Returns\n",
    "\n",
    "Comparing returns of different investment opportunities without taking risk into account is meaningless. Some return streams may be higher than others, but this may be due to the risks taken on rather than any merit in the strategy itself. Taking on higher risk should in theory lead to higher returns, but then how do we judge the quality of these returns for the amount of risk we have to handle? This is where risk-adjusted returns and methods of risk-adjustment come into play. If we adjust several return streams for risk then we can consider them on equal footing, independent of the risk. This allows us to effectively compare and determine which return streams are the best for a given desired risk profile.`\n",
    "\n",
    "One of the most prominent risk-adjusted measures is the Sharpe Ratio, defined as follows.\n",
    "\n",
    "$$ \\text{Sharpe Ratio} = \\frac{r_p - r_f}{\\sigma_p} $$\n",
    "\n",
    "The Sharpe Ratio essentially normalizes the returns of a portfolio, giving us a metric that we can use as a measure of quality relative to other revenue streams. A higher Sharpe Ratio indicates that you are getting more return relative to the risk that your strategy is taking on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "3TevUPNkxz3e"
   },
   "source": [
    "#### Compare Strategies by Sharpe Ratio and then Lever as Needed\n",
    "\n",
    "In general you want to compare the Sharpe Ratio of two strategies you may be interested in. Pick the strategy with the better Sharpe Ratio and then use leverage to multiply the returns up to where you want them. Assuming constraints like capital capacity don't kick in, you can add more money through leverage and bring a $2\\%$ per year strategy up to a $10\\%$ per year strategy while maintaining the same Sharpe, or invest a fraction of your available capital to bring a $20\\%$ per year strategy's risk down to acceptable levels.\n",
    "\n",
    "#### Example\n",
    "\n",
    "We'll show a simple example using real numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "ysjoRGj2xz3e"
   },
   "outputs": [],
   "source": [
    "# Note these are all expected returns. You need to validate that\n",
    "# your strategy will continue to produce these returns and volatility using other methods.\n",
    "# Just measuring historically is a very poor predictor of future performance.\n",
    "# We'll for now assume you've already validated that you can expect to keep seeing numbers similar to these.\n",
    "\n",
    "strat_A_ann_return = 0.22\n",
    "strat_A_ann_vol = 0.15\n",
    "\n",
    "strat_B_ann_return = 0.05\n",
    "strat_B_ann_vol = 0.02\n",
    "\n",
    "# We'll assume a risk free rate of 0.02\n",
    "risk_free_rate = 0.02\n",
    "\n",
    "print 'Strategy A Sharpe: %s' % ((strat_A_ann_return - risk_free_rate) / strat_A_ann_vol)\n",
    "print 'Strategy B Sharpe: %s' % ((strat_B_ann_return - risk_free_rate) / strat_B_ann_vol)\n",
    "\n",
    "# Add in leverage to B\n",
    "\n",
    "leverage = 3\n",
    "# Expressed in returns\n",
    "\n",
    "print 'Strategy B Sharpe: %s' % (\n",
    "    (strat_B_ann_return * leverage - risk_free_rate * leverage) / (strat_B_ann_vol * leverage)\n",
    ")\n",
    "print 'Strategy B Levered Annual Returns: %s' % (\n",
    "    (strat_B_ann_return * leverage - risk_free_rate * leverage)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "qdQjBcBCxz3f"
   },
   "source": [
    "### Portfolio Re-Weighting\n",
    "\n",
    "Portfolio weighting can be considered an example of applying leverage to a strategy. If you assign more of your portfolio weight to a strategy, you have upped the capital amount and multiplied both the returns and volatility. Likewise, if you have a strategy that has high returns but high volatility, you can provide it less weight so that you divide the volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "suBCTA5Vxz3f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "by7-tbAGxz3g"
   },
   "source": [
    "--- \n",
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "LTEzfzJ9xzxj",
    "0fkmv52hxzxk",
    "ptYRGMrLxzxk",
    "CtSC004Uxzxu",
    "EoSaFjAvxzx6",
    "vwqAHz82xzyE",
    "pC5fPNIYxzyN",
    "4Kjzjpn_xzyO",
    "hHHjkGIvxzyO",
    "4Sad2tOLxzyR",
    "aeJ8e1-ZxzyS",
    "8p31g4vWxzyS",
    "gGBhOJXbxzyX",
    "85kWN06QxzyX",
    "kZshnfhKxzyY",
    "kLrTwm-Qxzyd",
    "NyHUSYS0xzye",
    "fpbblmwBxzyh",
    "Du06CzDHxzyl",
    "aI9N8Z01xzys",
    "BMT9_3Nfxzyx",
    "p3n0ut9GxzzB",
    "l7aiAdlVxzzP",
    "ea0Xd65QxzzU",
    "JVN7rGkMxzzU",
    "jm5oTP_NxzzV",
    "nPVI8pz7xzzV",
    "OqMXxynPxzzV",
    "JM_vXTkOxzzW",
    "NH8dmn_HxzzW",
    "htLxwBZJxzzj",
    "FQ8oa6ihxzzk",
    "eCYEgwk_xzzk",
    "8izErYhbxzzk",
    "kJX09lZvxzzm",
    "FbW79lFPxzzm",
    "c82pVI3Uxzzm",
    "khM4BzdUxzzp",
    "XG7ZOZhzxzzz",
    "N04m7dq1xzz0",
    "bZgSkCiwxzz1",
    "omVv-72Cxz0D",
    "qj_8Jf78xz0D",
    "jcKHFMKDxz0E",
    "auW7_g6Cxz0G",
    "o5kWmTC1xz0J",
    "4GCugxIkxz0J",
    "cBjN6umUxz0Q",
    "1TzTJUV0xz0S",
    "u5fMnmRwxz0T",
    "CTJDQrXvxz0U",
    "HIT9EUWDxz0V",
    "bINTsjk0xz0Y",
    "aULpl50Wxz0Z",
    "d2sb5c_Yxz0b",
    "Uwy6ahz7xz0c",
    "X1Doke1Bxz0c",
    "RbGw3ksOxz0q",
    "TaTjLn1Gxz06",
    "eo7xnQqaxz1A",
    "qkaj_PLZxz1E",
    "bUeqHXqjxz1I",
    "xrVGzWToxz1O",
    "b3rg-yE0xz1P",
    "E3--pOFyxz1Z",
    "BWwvGf0Yxz1f",
    "ksObYEsLxz1m",
    "sQnXTieaxz1o",
    "3VVPMgkuxz1p",
    "vfue-UQaxz1q",
    "rLWpCiKHxz1r",
    "cjg93IVUxz1z",
    "3-wv1UlFxz10",
    "yvh0vDzhxz11",
    "s9X0aBTLxz11",
    "ELwzKGgbxz2E",
    "qATPQY4xxz2l",
    "RQs7w8ZMxz23",
    "bugOLU7vxz2_",
    "gLzUmsujxz3A",
    "t88fomDyxz3B",
    "JW48z-n8xz3B",
    "w1Yz1Zr8xz3D",
    "XThgZY-wxz3H",
    "tzqnLUsRxz3I",
    "o2C-qRE3xz3I",
    "xbAwfUr0xz3J",
    "QK2kV0Phxz3J",
    "PExrR6Y2xz3S",
    "pu1mK4HDxz3S",
    "DcoxEu22xz3S",
    "1U-6vccfxz3S",
    "pI-R823Jxz3X",
    "_sxrtDvwxz3X",
    "eLkg44-Xxz3e",
    "3TevUPNkxz3e",
    "qdQjBcBCxz3f"
   ],
   "name": "Lecture2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
